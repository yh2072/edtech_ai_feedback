# Unpacking help-seeking process through multimodal learning analytics: A comparative study of ChatGPT vs Human expert

Angxuan Chen a, Mengtong Xiang a, Junyi Zhou a, Jiyou Jia a, Junjie Shang a, Xinyu Li b, Dragan Gašević b, Yizhou Fan a,b,*

a Department of Educational Technology, Graduate School of Education, Peking University, Beijing, 100087, China  b Faculty of Information, Monash University, Clayton, VIC, 3800, Australia

# ARTICLEINFO

# ABSTRACT

Keywords:  Data science applications in education  Human- computer interface  21st century abilities  Information literacy  Human- AI interaction

Help- seeking is an active learning strategy tied to self- regulated learning (SRL), where learners seek assistance when facing challenges. They may seek help from teachers, peers, intelligent tutor systems, and more recently, generative artificial intelligence (AI). However, there is limited empirical research on how learners' help- seeking process differs between generative AI and human experts. To address this, we conducted a lab experiment with 38 university students tasked with essay writing and revising. The students were randomly divided into two groups: one seeking help from ChatGPT (AI Group) and the other from an experienced teacher (HE Group). To examine their help- seeking processes, we used a combination of statistical testing and process mining methods, analyzing multimodal data (e.g., trace data, eye- tracking data, and conversational data). Our results indicated that the AI Group exhibited a nonlinear help- seeking process, such as skipping evaluation, differing significantly from the linear model observed in the HE Group which also aligned with classic help- seeking theory. Detailed analysis revealed that the AI Group asked more operational questions, showing pragmatic help- seeking activities, whereas the HE Group was more proactive in evaluating and processing received feedback. We discussed factors such as social pressure, metacognitive off- loading, and over- reliance on AI in these different help- seeking scenarios. More importantly, this study offers innovative insights and evidence, based on multimodal data, to better understand and scaffold learners learning with generative AI.

# 1. Introduction

Help- seeking has been understood as the process of seeking assistance from other individuals or sources to achieve desired learning goals. It is widely recognized as a crucial self- regulated learning (SRL) strategy (Karabenick & Berger, 2013). By seeking help, learners fill gaps in their understanding and acquire knowledge that might be challenging to obtain by themselves. They must identify what they do not understand, formulate questions, and interact with information sources (Antonietti et al., 2023). Therefore, effective help- seeking requires learners to actively engage in cognitive and meta- cognitive processes such as monitoring whether help is needed,

reflecting how to ask for help, and evaluating whether the help they received are meaningful (Aleven et al., 2003; Karabenick & Dembo, 2011). Despite the importance of help- seeking in learning, prior research indicates that learners do not always seek help appropriately (Aleven et al., 2006), leading to either help abuse or help avoidance (Aleven et al., 2016). Such findings underscore the necessity for further exploration of the actual help- seeking process to better support learners in seeking appropriate help (Önder & Akçapınar, 2023). While several previous studies have proposed theoretical model of learners' help- seeking processes (Nelson- Le Gall, 1981; Karabenick & Gonida, 2017), empirical evidence on what actually happens during learners' help- seeking process is limited, particularly regarding the sequence of help- seeking stages and activities of learners as the process unfolds. Given that help- seeking is a dynamic, complex process with interwoven behavioural and cognitive activities (Fan & Lin, 2023; Finney et al., 2018; Karabenick & Gonida, 2017), it is necessary to unpack the learner's help- seeking process from a sequential and temporal perspective.

At the same time, Generative Artificial Intelligence (GenAI) as a novel help source creates unprecedented opportunities for research in the field of help- seeking (Hou et al., 2024). Compared to traditional intelligent tutoring systems, GenAI such as ChatGPT exhibits significant levels of human- like intelligence and natural language interaction with learners (Jia et al., 2024), providing learners with a powerful tool from which valuable help can be obtained (Urban et al., 2024). Recent research has indicated that AI tools such as ChatGPT are useful sources for help- seeking (Bibi & Atta, 2024; Mogavi et al., 2024), especially in the context of language learning (Diasamidze & Tedoradze, 2024). Learners were found to be satisfied with its capacity to deliver accurate responses and human- like help dialog (Tossell et al., 2024). However, the help- seeking process with such an emerging technology remains understudied, and as a result, a series of concerns have been raised. For instance, some studies argued that using ChatGPT may foster poor learning habits, weaken metacognitive abilities, and even academic dishonesty (Exintaris et al., 2023; Mogavi et al., 2024). The controversy regarding ChatGPT and academic help- seeking often relies on theoretical conjecture and lacks empirical evidence. Conversely, other recent studies suggest that the way learners use ChatGPT reflects their critical thinking skills (Liu et al., 2024). Therefore, to assess whether ChatGPT benefits learners, researchers need to further investigate the detailed stages and activities of learners' help- seeking processes. The resulting insights should gain critical insights into whether and how learners develop their own learning ability through the help of GenAI.

In the present study, we employed a combination of statistical testing and process mining methods using multimodal data to unpack the help- seeking processes of learners in an essay revision task with different help sources, namely, ChatGPT and human expert. Specifically, we compared the distinct help- seeking stages and activities in the processes between learners who had access to these two sources. The aim of this paper is to investigate and discuss the differences in learners' help- seeking processes when using ChatGPT compared to a human expert in essay revision and to identify the characteristics exhibited during these processes. Our findings offer insights that can enhance the use of ChatGPT as a help source in the future educational contexts.

# 2. Background

# 2.1. Process model of help-seeking

Several studies have suggested that help- seeking is a self- regulated strategy that is beneficial for learning (Karabenick & Newman, 2009; Pintrich, 2004). Self- regulated learning (SRL) refers to an active and constructive process in which an individual is cognitively, motivationally, and behaviourally engaged in their own learning (Zimmerman, 2002). In general, SRL is assumed to be represented by the three phrases in Zimmerman's SRL model: (1) forethought, when the learners prepare themselves to learn; (2) performance, when the learners execute and implement learning behaviours; and (3) self- reflection, when the learners evaluate the learning results (Zimmerman, 2013). The process of help- seeking aligns with this cyclical framework of SRL. For instance, learners need to diagnose questions before asking help, selecting appropriate strategy when asking help and evaluating help content after receiving help. Therefore, successful help- seeking promotes SRL, allowing individuals to manage their own learning processes more effectively

Table 1 Help-seeking process model protocol (Nelson-Le Gall, 1981).  

<table><tr><td>Stage</td><td>Activities</td><td>Description</td></tr><tr><td>Awareness of Need for Help</td><td rowspan="2">monitoring of understanding monitoring of relative benefits and cost</td><td>To be aware of their own limitations or the complexity of the task at hand</td></tr><tr><td>Decision to Seek Help</td><td>To compare the benefits of help-seeking in goal attainment and cost of suffering a loss of perceived competence from others</td></tr><tr><td>Identification of Potential Help source</td><td>identifying and choosing potential help source</td><td>To identify and choose the potential help source who can provide needed resources and support</td></tr><tr><td rowspan="2">Employment of Strategies to Elicit Help</td><td>strategies of asking instrumental help</td><td>To ask for help indirectly, solicit information about the problem at hand or about the help source&#x27;s abilities to the problem, make statements about his or her own state of competence, and remind the help source of some obligation to guide and support</td></tr><tr><td>strategies of asking executive help</td><td>To ask for help directly, request specific actions or solutions from the help source, provide clear details about the task or problem, state the urgency or importance of the task, and emphasize the need for immediate and effective intervention</td></tr><tr><td rowspan="3">Reactions to Help-Seeking Attempt(s)</td><td>perceiving the received help externally</td><td>To positively or negatively evaluate the help source and the received help</td></tr><tr><td>perceiving the received help internally</td><td>To improve or decrease own self-esteem</td></tr><tr><td>showing behavioural responses</td><td>To terminate or prolong the relationship and reciprocation of help</td></tr></table>

(Karabenick & Gonida, 2017).

Under this understanding, several process models of the help- seeking have been proposed in the past literature (Karabenick & Gonida, 2017; Mercier & Frederiksen, 2008; Nelson- Le Gall, 1981). A commonly used and recognised model was put forward by (Nelson- Le Gall, 1981), which divided help- seeking process into five stages, each encompassing different activities (detailed in Table 1): (1) awareness of the need for help; (2) decision to seek help; (3) Identification of a potential help source; (4) employment of strategies to elicit help; and (5) reactions to help- seeking attempts. In this model, an ideal sequence of help- seeking would be as follows: learners face problems during learning and realise they need help from others. Next, learners must consider whom ask for help and how to request for help in a suitable way, which is influenced by learners' perception of the learning environment. After receiving help, learners should evaluate to what degree the help is useful. If it is helpless, they can refuse to accept help and request another. In addition, the quality of receiving help would also influences whether to seek help in the subsequent learning sessions. It should be emphasised that the stages and decisions may not occur in the exact order, and especially that learners may not always be conscious of the stages involved. To clarify the terms used in this study, we summarised the descriptions of different terms related to the help- seeking process model as shown in Table 2.

While previous models focused on help seeking in classrooms or other formal learning contexts, with human agency such as classmates, teachers or coaches representing the main sources of help, little attention has been paid to help- seeking process in the digital learning environment with intelligent agents like ChatGPT. Although intelligent tutors have been increasingly used to provide help for learners, there is a lack of consensus on the structure of help- seeking process (Martin- Arbos et al., 2021), especially the distinct features differ from traditional theoretical modes when asking help from intelligent tutors. For example, previous theoretical model often viewed help- seeking process as a logically linear sequence with stages occurring sequentially (Nelson- Le Gall, 1981; Mercier & Frederiksen, 2008).

However, recent studies argue that the order of these stages varied without an exact order (Karabenick & Gonida, 2017). In addition, few past studies so far explored the detailed activities within these stages, resulting in a knowledge gap concerning how learners acted during these processes (Adams et al., 2023; Önder & Akçapınar, 2023). Therefore, it is necessary to unpack help- seeking process within the digital learning environments in stages and activities level.

# 2.2. Factors influencing help-seeking process stages

The process of help- seeking is a multifaceted phenomenon influenced by various factors at different stages. In this section, we reviewed the critical factors influencing help- seeking process of past literature to enhance our understanding of this phenomenon.

The initial stage of the help- seeking process involves the learner's awareness of the need for help. Metacognitive monitoring accuracy plays a significant role in this stage. Nelson and Fyfe (2019) found that children confident in their incorrect answers had lower monitoring scores and were less likely to seek help in solving mathematics problems. Chu et al. (2018) also indicated that learners with appropriate metacognitive accuracy were more aware of their limits and thus more likely to ask for help. Conversely, learners with less metacognitive accuracy and insufficient background knowledge often remained unaware of their need for help.

In the decision to seek help stage, perceived benefits and costs are critical factors influencing learners' decision activities. Roussel et al. (2011) highlighted that the willingness to seek help is related to achievement goals. Specifically, the decision to seek academic help was associated with mastery- approach goals, while avoidant help- seeking activity was positively related to performance- avoidance goals but negatively related to mastery- approach goals. Their study showed perceived costs and benefits of help- seeking mediated the relationship between instrumental help- seeking and achievement goals.

During the identification of the potential help source stage, learners' choices of help sources are influenced by their perceptions of the benefits and drawbacks of different sources. Newman (2008) reported that learners often compare informal sources like peers with formal sources like teachers. Additionally, Broadbent and Lodge (2021) explored how learners perceived cognitive and emotional support from various help sources, indicating that these perceptions significantly affect their choices.

The employment of strategies to elicit help stage involves different approaches that learners use to seek assistance. Nelson- Le Gall (1981) introduced the dichotomy of executive help- seeking and instrumental help- seeking activities. Executive help- seeking, where learners ask for direct answers, is a negative predictor of learning performance (Fan & Lin, 2023). In contrast, instrumental help- seeking, where learners request hints or partial assistance, aligns with better learning outcomes. The advent of information technology has also transformed help- seeking strategies, with empirical studies examining activities like information searching and formal and informal queries (Cheng et al., 2013; Huang et al., 2024; Lin & Mubarok, 2021).

The final stage involves reactions to help- seeking attempts. Studies have shown that these reactions can vary based on external

Table 2 Definition and description of terms related to help-seeking.  

<table><tr><td>Terms</td><td>Description</td></tr><tr><td>Help-seeking process</td><td>The sequential process of seeking assistance from individuals or other sources to achieve a desired learning goal (Karabenick &amp;amp; Berger, 2013)</td></tr><tr><td>Help-seeking process model</td><td>The theoretical model that describes how the help-seeking process occurs and progresses (Mercier &amp;amp; Frederiksen, 2008)</td></tr><tr><td>Help-seeking stage</td><td>The theoretical stages that occur within the help-seeking process (Nelson-Le Gall, 1981)</td></tr><tr><td>Help-seeking activities</td><td>The cognitive and behavioural activities occur within different help-seeking stages (Nelson-Le Gall, 1981)</td></tr><tr><td>Help source</td><td>A place, person, or thing from which assistance can be obtained for someone seeking help (Makara &amp;amp; Karabenick, 2013)</td></tr></table>

perceptions, such as positive or negative evaluations (Huang et al., 2024), self- perceptions like self- esteem (Clegg et al., 2006), and behavioural responses (Nelson- Le Gall, 1981). These reactions can significantly influence the overall help- seeking process and subsequent learning experiences.

However, although independent investigations in the different stages offer insights into help- seeking, they do not fully reveal the theoretical dynamics and temporality of help- seeking proposed in the SRL literature. In particular, as SRL activities (e.g., monitoring, performance, self- reflection) emerge and develop dynamically during different stages of help- seeking, research should apply fine- grained data to demonstrate dynamic features of help- seeking stages (Adams et al., 2023). Currently, there are also increasing appeals that further investigation should focus more on the joint effects brought by the interconnected relations of different stages rather than merely focusing on one or two stages independently to understand learners' help- seeking (Yang & Stefaniak, 2023; Onder & Akcapinar, 2023). Especially, past studies lack of empirical studies on how those stages intertwined when learners seeking help from ChatGPT (Urban et al., 2024). Therefore, in this study, we aim to investigate the temporal and dynamic relationships shown in the theoretical model by analysing different stages, and raise our first research question:

RQ1. Are there differences in help- seeking stages when learners seek help from ChatGPT versus a human teacher?

# 2.3. Impact of help source: comparing human and AI

Past research has shown that help sources can play an important role in influencing learners' help- seeking activities during their help- seeking process. For example, in a social help- seeking context, learners require different social skills when asking for help from teachers compared to seeking assistance from friends or more knowledgeable classmates (Makara & Karabenick, 2013). Ordering and demanding may not be the most effective activities for obtaining help from teachers, but among peers in a group situation, these techniques may be quite effective (Webb & Mastergeorge, 2003). The social cost can be an important factor influencing how learners engage in different activities (Karabenick & Gonida, 2017). Seeking help may be perceived as a sign of incompetence in studying, leaving a negative impression on others (Leenknecht & Carless, 2023). Therefore, learners exhibit different help- seeking tendencies based on the source of help. They often view peers as more approachable and friendly sources for seeking help, which is characterised by incurring lower social cost. In contrast, learners typically consider seeking help from teachers as a costly choice, and therefore requires careful consideration (Davison et al., 2023). When learners perceive the social cost of seeking help as higher than the potential knowledge gain, they tend to engage in avoidant help- seeking activity, meaning they do not seek help even after recognising their problem (Karabenick & Dembo, 2011).

The rise of information technology has provided various help sources for learners. Studies found that online anonymous help- seeking environments eliminate students' perception of help- seeking as a threat (Broadbent & Lodge, 2021). Similarly, in interactive learning environments, students may feel less threatened when seeking help from systems compared to peers or teachers in the classroom (Karabenick & Gonida, 2017). However, when learners seeking help from AI technology such as intelligent tutoring system, studies has found learners' help- seeking activities tend to only focus on the help that provided copyable answer (Aleven et al., 2003, 2016). Nelson- Le Gall (1981) firstly introduced the dichotomy of executive and instrumental help- seeking. Executive help occurs when learners wish to have the tutors solve the task directly for them (such as asking "can you give me the answer?"), which was found a negative predictor of learning performance (Karabenick & Berger, 2013), while instrumental help refers to requesting only the amount of help according to learners' needs to complete the task on their own (such as "Can you give me some hints?"), which was found more effective than executive help for long term learning (Aleven et al., 2006). In the learning environment with intelligent tutoring system, some students were classified as executive help- seekers who tend to seek executive help merely to obtain the correct solution and complete tasks without learning (Nelson- Le Gall, 1981; Karabenick & Dembo, 2011). This phenomenon also highlights the differences between human and AI sources of help, as human tutors are more likely to encourage deeper understanding and independent problem- solving (Karabenick & Gonida, 2017), whereas AI systems may inadvertently facilitate superficial learning by providing direct answers (Aleven et al., 2016).

Currently, the emergence of ChatGPT has shown the potential as an intelligent help source that can influence learners' help- seeking activities in their help- seeking process (Eibi & Atta, 2024). On the one hand, learners find ChatGPT to be an immediate and natural way to interact, similar to talking to a teacher, but without the social cost of being considered incapable since it is not a real human (Urban et al., 2024). On the other hand, ChatGPT demonstrates a high level of knowledge, particularly in language- related tasks (Diasamidze & Tedoradze, 2024), which may influence learners' choice in choosing and accepting their response. For instance, ChatGPT produces essays that are sometimes evaluated as being of higher quality compared to those written by humans (Herbold et al., 2023), and capable in some aspects of accurately identifying the strengths and weaknesses of essays, offering some suggestions for improvement (Liu et al., 2024). Therefore, ChatGPT seems to have the potential to answer learners' questions and offer assistance in a way similar to human teacher, especially in language learning field. Additionally, currently ChatGPT provides a unique and natural manner of interaction in the online learning environment, and it can support different help- seeking activities such as ordering and demanding direct help, providing facilitating hints, or searching information and websites (Adams et al., 2023). Therefore, it is likely that learners may exhibit other different help- seeking activities when seeking help from ChatGPT compared to those when seeking help from human teacher.

However, although ChatGPT shows the potential to be a valuable help source, there is still a lack of empirical evidence about whether and how ChatGPT can influence learners' help- seeking activities. This limited understanding restricts our ability to effectively adopt ChatGPT's use in educational settings. Therefore, our study proposes the second research question:

RQ2. Are there differences in help- seeking activities when learners seek help from ChatGPT versus a human teacher?

# 3. Methods

# 3.1. Participants and experiment procedure

A cohort of 38 university learners, all of whom were Chinese native speakers and learners of English as a Second Language (ESL), voluntarily participated in the study  $(M_{age} = 22.7, SD = 3.66)$ . All participants provided active informed consent prior to data collection and received compensation for their participation. Participants were randomly allocated to different groups, resulting in 18 participants in the artificial intelligence group (AI Group) and 20 participants in the human expert group (HE Group).

The experiment was structured as a two- stage task, which required participants to firstly write an English essay draft and then, revise it with the help of either ChatGPT or a human expert. The whole procedure is displayed in Fig. 1. In Stage 1, all of the participants were asked to compose a 300- 400 word essay about the future of education after reading three topics of material pages we provided: artificial intelligence, differentiation in the classroom, and scaffolding of learning. The task instruction and the essay rubric were provided to aid participants in structuring their essays and evaluating their work effectively. After completing their drafts, participants were instructed to watch a training video, which introduced the revision task and different help source. Specifically, ChatGPT is the help source in AI Group, while the human expert is the help source in HE Group. In Stage 2, participants were allocated  $1\mathrm{h}$  to revise their essays with the assistance of different help sources:

The AI Group participants received assistance from ChatGPT 4.0, a large language model (LLM) engineered for interactive and natural dialog. We designed a plugin that utilises the ChatGPT 4.0 API and integrated it into the online learning platform used in our experiment. To ensure ChatGPT's responses remained relevant to the task, we combined reading materials, task requirements, the rubric, and participants' essay drafts in the prompts. This setup allowed participants to pose context- specific inquiries and receive pertinent response. The objective for the participants was to revise their essays utilising the help of ChatGPT, while incorporating the instructions and rubric to aim for higher scores.

The HE Group participants, on the other hand, were supported by a human expert. This human expert had extensive experience in English writing instruction. He was very familiar with the task content of this experiment, understood the common writing problems that students had and was competent enough to instruct them. In our platform, the human expert could observe participants' essays in real- time through an online tool. The essay revising stages were not simultaneous for each participant, which meant that the human expert could focus on instructing each student. Participants were afforded the opportunity to have instant and one- on- one chats with the human expert, thereby facilitating an interactive help- seeking process. Additionally, participants were also requested to follow the provided rubrics to assist them in seeking task- relevant help and achieving higher scores.

# 3.2. Learning environment and data collection

During the experiment, the participants used an online platform, which included reading materials, instrumental tools supporting self- regulated learning (also referred to as instrumentation tools in the literature Van Der Graaf et al., 2021), and a writing area. Fig. 2 illustrates the learning environment. In Stage 2, AI Group had access to tools for communicating with ChatGPT, whereas HE Group had tools for interacting with the human expert.

![](images/c9d3cc6b26873dcef314e99b5378382f909363db6f35e67e8b1695252978d41e.jpg)  
Fig. 1. Experiment procedure.

This experiment was conducted in a lab where participants were required to complete the task on a laboratory computer. As a result, multimodal data could be gathered in Stage 2 to record the learning behaviours of participants during revisions. Specifically, three types of data were collected:

1. Trace (log) data: Based on the online experimental platform, participants' mouse movements, tool clicks, page navigation, key strokes and other click stream data during Stage 2 were recorded. 
2. Eye-tracking data: Participants' eye movement coordinates on the screen were captured via a Tobii Nano Pro eye tracker, and screen videos were recorded. The final eye-tracking data allowed for identification of participants' regions of interest (ROI) within the recorded Stage 2 screen videos. 
3. Conversational data: Text-based conversational data between participants and their help sources (either ChatGPT or a human expert) was collected. These text data included messages from both the participants and the help source.

In this study, multimodal data were synchronised into a unified format of computer screen recording for our further operationalised coding, as shown in Fig. 3. The trace data, such as mouse movements, mouse clicks, and page navigation, can be observed in the screen recording. The eye- tracking data is also observable in the screen recording, with the ROI indicated by a red point showing learners focus. The conversational data can also be seen in the screen recording as the dialog box displaying the message input from learners. Therefore, our coding of the help- seeking process in our experiment was ultimately based on the unified screen recording format.

# 3.3. Coding process and framework

In order to investigate how learners seek help at a finer- grained level, we split the screen recording videos into multiple segments based on certain observable demarcation point events. Referring to the theoretical help- seeking process model (Nelson- Le Gall, 1981; Karabenick & Berger, 2013), we identified four demarcation point events in our experiment that can distinguish different stages in learners' help- seeking process:

1. Clicking the message box of the ChatGPT/Teacher Tool: This event indicated the transition from a learner's awareness of their need for help to the learner's strategies used to seek help. 
2. Clicking the send" button of the ChatGPT/Teacher Tool: This event indicates that, during the 'learner's strategies used to seek help' stage, the learner had sent their message to the ChatGPT/Teacher Tool and was waiting for a reply. 
3. Seeing the answer message from the ChatGPT/Teacher Tool: This event indicates the transition from learners' strategies used to seek help to learners' reaction of the received help. It is worth noting that the answer message here specifically represents the answer from ChatGPT/Teacher that address the learner's help-seeking, rather than other messages, such as casual chatting or rhetorical questions. 
4. Clicking the Essay Writing Tool: This event indicates the transition from the learner's reaction to the received help to learner's process to the received help.

Based on these key events, we first review the screen recording videos from both the AI Group and the HE Group, and split each video into multiple segments by recording the beginning and ending timestamps for the subsequent coding process. Then, our coding

![](images/fd10e3a1cb8a098c0d56c8ccb2d2a3929a8f92803715d43278c9e7a0ef5143db.jpg)  
Fig. 2. Learning environment.

![](images/e8bf1bed4f95b33efeae238a32ab94c64979af7bd5d9bf8c853e7323aee177f5.jpg)  
Fig. 3. Unified screen recording.

process involved three phases:

(1) Exploratory coding. We adapted the theoretical framework put forward by Nelson-Le Gold (1981) to our research context. For instance, we merge theoretical stage of "Awareness need of help" with "Decision to Seek Help" into "Diagnosing questions", remove the "Identification of Potential Help Source", and divide "Reactions to Help-seeking Attempt(s)" into "Evaluating Help" and "Processing help" stage. 
(2) Operational coding. We provided detailed operational description of each activity in help-seeking process. Discrepancies, such as the time threshold of eye-tracking staying in diagnosing questions activity were resolved by discussion. We formed the final formal coding framework (see Table 3, examples can be seen in Appendix). Three researchers coded  $50\%$  videos based on this framework, with a high level of reliability (Krippendorff's Alpha  $= 0.82$ ). 
(3) Formal coding. In this phase, three researchers performed formal coding according to the final coding framework. Researchers coded the rest of videos separately.

Table 3 presents the final coding framework we proposed, which contains four major stages of help- seeking process: Diagnosing Questions, Asking Help, Evaluating Help and Processing Help. Diagnosing Questions means learners need to determine if there is a problem based on their own learning status and decide if they need help. Asking Help refers to learners ask help for ChatGPT or human expert. This stage involves five activities: Instrumental help- seeking (asking hints), Executive help- seeking (asking for answers), Avoidant help- seeking (asking questions but not to send them), Clarifying asked help (clarifying or explained asked questions) and Showing Understanding of asked help (showing learners' understanding or thoughts of their problem). We distinguish these activities through conversational data. Evaluating Help is learners evaluate the help messages after receiving it. This stage is prevalent and unique in our context, as eye- tracking data is captured by our platform. We checked learners' eye- tracking stays in the replies and read it from start to the end, suggesting they are evaluating the help message. If they give positive feedback in the conversational data, we coded as Evaluating Help. Positive; If they give negative feedback, we coded as Evaluating Help. Negative; If they did not give any feedback, we coded as Evaluating Help. No Feedback. The last stage is Processing help, where learners choose to accept, neglect or return help. Accepting help means learners apply the help directly in revising their essays; Neglecting help is learners refuse the help with no revising their essays; Returning help refers to learners looking back to some previous help message.

# 3.4. Data analysis

To investigate the difference between AI group and HE group, we carried out a descriptive analysis of the ratio of stages and activities in the help- seeking process. To understand the help- seeking process comprehensively, it is necessary to compare its stages and activities, as they depicted help- seeking process at different granularity. In this study, we used ratios (i.e., the proportion of each stage or activity relative to the entire process) rather than counts for comparison because we aimed to explore the relative differences between stages and activities in AI Group and HE Group. This indicator helped us identify which stages had a larger proportion in their help- seeking process. The Shapiro- Wilk test was used to assess the normality of the data, and the results provided strong evidence of non- normality. Since the assumption of normality of the data was violated, a non- parametric Mann- Whitney  $U$  test was performed to determine significant differences in help- seeking stages and activities between groups. The effect size was calculated by Cliff's delta (Macbeth et al., 2011). Additionally, to compare the temporal pattern of help- seeking process between AI Group and HE Group, we utilised the process mining method pMineR package (Gatta et al., 2017). Through process mining, we were able to create and visualise

Table 3 Codebook for coding the help-seeking process using multimodal data.  

<table><tr><td>Stage</td><td>Activities</td><td>Definition</td><td>Code</td><td>Trace Data</td><td>Eye tracking Data</td><td>Conversational data</td></tr><tr><td>Diagnosing Question</td><td>Diagnosing Question</td><td>learners need to determine if there is a problem based on their own learning status and decide if they need help</td><td>Diag. Ques</td><td>Mouse moving to the toolbar</td><td>Eye tracking stays in the reading materials, writing instructions, writing area over 5s</td><td>/</td></tr><tr><td rowspan="5">Asking Help</td><td>Asking Help. Instrumental</td><td>Instrumental help-seeking (learners asking hints that can assist them in revising their essays independently afterwards)</td><td>Ask. Instr</td><td>Type in the dialog boxes</td><td>Eye tracking stays in the dialog area</td><td>Message text is a question for seeking facilitating hints</td></tr><tr><td>Asking Help. Executive Asking Help. Avoidant</td><td>Executive help-seeking (learners tend to look for answers that can be applied directly) Avoid asking for help (learners attempt to ask questions but delete them without send ing)</td><td>Ask. Exec. Avo</td><td>Type in the dialog boxes</td><td>Eye tracking stays in the dialog area</td><td>Message text is a question for seeking executive results /</td></tr><tr><td>Asking Help. Complementing</td><td>Complementing questions (learners typed their questions in the dialog box and seek additional information to refine or improve them)</td><td>Ask. Compl</td><td>Type in the dialog boxes but then deleted all the question text and not sent it</td><td>Eye tracking stays in the dialog area</td><td>Message text is improved after revision</td></tr><tr><td>Asking Help. Clarifying</td><td>Clarifying asked help (Learners clarified or explained their questions to make them clearer to the help source)</td><td>Ask. Clar</td><td>Type in the dialog boxes</td><td>Eye tracking stays in the dialog area</td><td>Message text is a clarification or explanation for previous learner sent messages</td></tr><tr><td>Asking Help. Understanding</td><td>Showing Understanding to the asked help (Learners showed their understanding or thoughts of their problem)</td><td>Ask. Und</td><td>Type in the dialog boxes</td><td>Eye-tracking stays in the dialog area</td><td>Message text shows their understanding or thoughts of their problem</td></tr><tr><td rowspan="2">Evaluating Help</td><td>Evaluating Help. Positive Evaluating Help. NoFeedback</td><td>Positive evaluation (learners evaluate the help message and give positive feedback) Evaluation with no feedback (Learners evaluate the help message but not give feedback messages)</td><td>Eva. Pos. Eva. NoFB</td><td>learners type in the input box to sent a feedback</td><td>Eye tracking stays in the replies in the dialog box</td><td>The text is a positive comment /</td></tr><tr><td>Evaluating Help. Negative</td><td>Negative evaluation (learners evaluate the help messages and give negative feedback)</td><td>Eva. Neg</td><td>whether a feedback was sent</td><td>Eye-tracking focused on the response message and read it from start to the end</td><td>The text is a negative comment /</td></tr><tr><td rowspan="3">Processing Help</td><td>Processing Help. Accepting</td><td>Accepting help (learners apply the help directly in revising their essay)</td><td>Pro.Acc</td><td>Easy text has been revised</td><td>Eye tracking stays in the replies in the dialog box</td><td>/</td></tr><tr><td>Processing Help. Neglecting</td><td>Neglecting help (learners do not apply the help directly in revising their essays)</td><td>Pro. Neg</td><td>Mouse clicks on another page or close the dialog box</td><td>Eye tracking moves away from the dialog box</td><td>/</td></tr><tr><td>Processing Help. Returning</td><td>Returning to the help (learners look back to some previous help message)</td><td>Pro.Re</td><td>learners re-open the ChatGPT/Human expert chat window, or learners scroll up the slide bar of the message box</td><td>Eye tracking moves to the dialog box</td><td>/</td></tr></table>

first- order Markov models (FOMM) of help- seeking stages and activities for each identified process with the  $5\%$  transition threshold setting. The pMineR employs first- order Markov modelling, which calculates the probability of transitions between help- seeking stages and activities. Process mining method, as highlighted in the works of He et al. (2024) and Saint et al. (2020), has proven effective in interpreting micro- level sequences.

# 4. Results

# 4.1. Comparison of AI group and HE group in their help-seeking stages

For our RQ1, we generated the process maps from pMineR (shown in Figs. 4 and 5). In the AI group, the different stages had stronger connections, indicating a complex, non- linear help- seeking process. There was a strong trend where the help- seeking process began not with a Diagnosing Question stage (0.37) but directly with the Asking Help stage (0.63). For example, learners first asked ChatGPT "What's the problems of my essay?" and then read their essays to form detail questions. Additionally, there were more bidirectional transitions between the Asking Help and Processing Help stages (0.49 and 0.60 respectively) in AI Group, suggesting that many learners in the AI group may have neglected to evaluate the help during the process. However, the process maps showed that the help- seeking process in the HE group was more closely aligned with the linear help- seeking process model as conceptualised in the theory. The stages occurring over time followed a more linear, unidirectional sequence (Diagnosing Question - > Asking for Help - > Evaluating Help - > Processing Help). The only bidirectional transition was from Asking Help to Evaluating Help, showing a small probability (0.23) of follow- up questions in the HE group. For example, when learners evaluated the help message and did not understand the help received, they may asked the human expert for more detailed explanations (e.g., "I don't understand. Could you explain what is past perfect tense?"). In addition, HE Group showed an inner loop in the Asking Help stage, representing learners may engage in more obvious clarifying or explaining activities when posing questions to human experts (e.g., following explaining "I don't mean that. I mean I want some advice to my essay's structure").

We further analysed ratio differences between help- seeking stages detected in AI Group and HE Group. The results of AI Group and HE Group are shown in Table 4. The Mann- Whitney  $U$  test results showed that there was a significant difference between the two groups in Asking Help stage ratio  $(Z = - 3.334$ $\mathrm{ES} = 1.288$ $p< 0.001)$  , with AI Group  $(34.62\%)$  having a significantly higher ratio than that of HE Group  $(22.49\%)$  . Additionally, the ratio of Diagnosing Question stage and Evaluating Help stage in AI Group  $(8.88\%)$  and  $15.92\%$  were lower than HE Group  $11.58\%$  and  $19.46\%$  , but there was no statistically significant difference.

![](images/529ff80e8714fe843fe4819ea3e89aa489ee4a2322541b040614e447ee020b95.jpg)  
Fig. 4. Help-seeking process temporal pattern in stages in AI Group.

![](images/ac9a8e5a01fb07edcd33b722519259057a16e796a0de85e79f4c6f0a94d15ef1.jpg)  
Fig. 5. Help-seeking process temporal pattern in stages in HE Group.

4.2. Comparison of AI group and HE group in their help- seeking activities

For our RQ2, we firstly compared the ratio of each activity in its stage (such as the ratio of Processing Help.Accepting (Pro.Acc) in the whole Processing Help stage). The results are shown in Table 5.

For the activities in the stage of Asking Help, the results showed that there was a significant difference between the two groups in the ratio of Asking Help.Executive (Ask.Exec)  $(Z = - 2.940$ $p< 0.01)$  , which was significantly higher in the AI Group than that in the HE Group  $(\mathrm{ES} = 1.126)$  , indicating learners were more focused on seeking executable results or copyable sentences from ChatGPT than they did from the human teacher. However, there was no significant difference in Asking Help.Avoidant (Ask.Avo)  $(Z = - 0.657$ $p>$  0.05,  $\mathrm{ES} = - 0.467)$  , indicating that learners in the AI Group also engaged in avoidant help- seeking activities. In addition, there was

Table 4 Comparison of stage ratio  $(\%)$  between AI Group and HE Group by Mann-Whitney U.  

<table><tr><td>Stages</td><td>Mean Ratio (%) (AI, 
N = 18)</td><td>Mean Ratio (%) (HE, 
N = 20)</td><td>Mean Rank 
(AI, N = 18)</td><td>Mean Rank 
(HE, N = 20)</td><td>Z</td><td>Effect Size (ES)</td><td>ZSig. (2-tailed)</td></tr><tr><td>Diagnosing Question</td><td>8.88</td><td>11.58</td><td>17.19</td><td>21.58</td><td>-1.214</td><td>-0.487</td><td>0.228</td></tr><tr><td>Asking Help</td><td>34.62</td><td>22.49</td><td>25.83</td><td>13.80</td><td>-3.334</td><td>1.288</td><td>0.001#</td></tr><tr><td>Evaluating Help</td><td>15.92</td><td>19.46</td><td>17.06</td><td>21.70</td><td>-1.287</td><td>-0.445</td><td>0.206</td></tr><tr><td>Processing Help</td><td>40.58</td><td>46.48</td><td>16.89</td><td>21.85</td><td>-1.375</td><td>-0.431</td><td>0.176</td></tr></table>

Note:  $^\ast \mathrm{p}< 0.05$ $^{**}\mathrm{p}< 0.01$  a  $\mathrm{p}< 0.001$

also no significant difference in Asking Help. Complementing  $(Z = - 1.297, p > 0.05, \mathrm{ES} = - 0.632)$ , Asking Help. Clarifying  $(Z = - 1.681, p > 0.05, \mathrm{ES} = - 0.578)$  and Asking Help. Understanding  $(Z = - 0.055, p > 0.05, \mathrm{ES} = - 0.183)$ , which may conclude to the small mean ratio of these activities in the Asking Help stage.

In the stage of Evaluating Help, the Mann- Whitney  $U$  test results showed that the HE Group had many more Evaluating Help. Positive (Eva.Pos) activities than AI Group did  $(Z = - 4.788, \mathrm{ES} = - 2.448, p < 0.001)$  (such as writing more messages to express appreciation to the human expert's help), while AI Group showed many more Evaluating Help. No Feedback (Eva.NoFB) activities than HE Group did  $(Z = - 4.990, \mathrm{ES} = 2.519, p < 0.001)$ , suggesting that learners may have not adhered to social manners when facing AI as the help source, such as providing feedback or expressing thanks.

In the stage of Processing Help, there was no difference between the two groups in Processing Help. Accepting (Pro.Acc). Additionally, AI Group showed more Processing Help. Neglecting (Pro.Neg) activity (e.g., not to revise their essay) than HE Group did and the difference was significant  $(Z = - 2.231, \mathrm{ES} = 0.711, p < 0.05)$ . HE Group showed more Processing Help. Returning (Pro.Re) activity (e.g., review previous received help to revise their essay) than AI Group did and the difference was significant  $(Z = - 2.373, \mathrm{ES} = - 0.686, p < 0.05)$ .

We further compared the help- seeking process in the level of activities between Group AI and Group HE (See Fig. 6). Firstly, the AI Group demonstrated a transition from avoidant help- seeking (Ask.Avo) or complementing asked question (Ask.Comp) to instrumental help- seeking (Ask.Instr)  $(\mathrm{TP} = 1$  and  $\mathrm{TP} = 0.75)$ . This indicates that learners in the AI Group initially avoid their help- seeking or initially complement their question messages but eventually will ask for high- quality questions about facilitated hints to aid their revision. That representing learner did not send their questions after typing, whether they deleted them or edited them, could indicate that they are actively evaluating the appropriateness of their questions. The avoidant help- seeking appears to be strategic, as learners seemed to structure their questions more carefully, likely to receive more effective responses from the help source. Secondly, the HE Group showed a strong tendency to transition from neglecting help (Pro.Neg) to reviewing previous help (Pro.Re)  $(\mathrm{TP} = 1)$ , whereas the AI Group showed a transition to ask instrumental help (Ask.Instr)  $(\mathrm{TP} = 1)$  to ask a new question. This indicates a distinct difference in the approach to process the received help between the two groups. Specifically, the HE Group preferred to reflect on and review past assistance, checking whether previous suggestions from the teacher were beneficial when they found current help unhelpful. In contrast, the AI Group is more inclined to actively seek immediate, practical follow- up help to address their current needs.

# 5. Discussion

# 5.1. Findings in help-seeking stages when seeking help with ChatGPT

# 5.1.1. Theoretical model in capturing help-seeking process with ChatGPT

Models of the help- seeking process outline various stages and decision- making moments that determine whether and when learners seek help to address learning and performance challenges (Onder & Akcapinar, 2023). These stages are grounded in relevant theories to illustrate how the help- seeking process linearly unfolds (Karabenick & Gonida, 2017; Mercier & Frederiksen, 2008). Interestingly, for our RQ1, the used multimodal framework in our study unveiled a non- linear process model when learners seeking help from ChatGPT, while learners seeking help from human expert showed a more linear sequence. Unlike previous research suggesting that the non- linear help- seeking process model appeared in practice through changing the order of stages progress (e.g. Karabenick & Dembo, 2011; Onder & Akcapinar, 2023), our findings indicate that the non- linear help- seeking process model of learners seeking help from ChatGPT were shown by skipping certain stages such as Diagnosing Question and Evaluating Help. A direct connection was observed between Begin stage and Asking Help stage without observable Diagnosing Question stage as a mediation, suggesting learners may ask ChatGPT for diagnosing their essay problems (e.g., asking ChatGPT "What's the problems in my essay?" rather than diagnosing problems first and then asking specific questions) (Liu et al., 2024). Our empirical findings also showed that AI Group tended to

Table 5 Comparison of activities between AI Group and HE Group by Mann-Whitney  $U.$  

<table><tr><td>Activities</td><td>Mean Ratio in 
activities (%) (AI, N = 18)</td><td>Mean Ratio in 
activities (%) (HE, N = 20)</td><td>Mean Rank 
(AI, N = 18)</td><td>Mean Rank 
(HE, N = 20)</td><td>2</td><td>Effect Size (ES)</td><td>Sig. (2-tailed)</td></tr><tr><td>Ask.Instr</td><td>61.14</td><td>69.12</td><td>17.28</td><td>21.05</td><td>-1.184</td><td>-0.377</td><td>0.251</td></tr><tr><td>Ask.Rece</td><td>30.30</td><td>7.06</td><td>24.86</td><td>14.68</td><td>-2.949</td><td>1.126</td><td>0.005b</td></tr><tr><td>Ask.Avo</td><td>5.05</td><td>10.67</td><td>18.47</td><td>20.43</td><td>-0.657</td><td>-0.467</td><td>0.993</td></tr><tr><td>Ask.Compl</td><td>0.76</td><td>4.69</td><td>17.83</td><td>21.00</td><td>-1.297</td><td>-0.632</td><td>0.393</td></tr><tr><td>Ask.Clar</td><td>1.39</td><td>4.71</td><td>17.53</td><td>21.28</td><td>-1.681</td><td>-0.578</td><td>0.290</td></tr><tr><td>Ask.Und</td><td>1.16</td><td>2.75</td><td>19.56</td><td>19.45</td><td>-0.055</td><td>-0.183</td><td>0.988</td></tr><tr><td>Eva.Pos</td><td>4.44</td><td>67.03</td><td>10.94</td><td>27.20</td><td>-4.788</td><td>-2.448</td><td>0.000c</td></tr><tr><td>Eva.NoFB</td><td>93.70</td><td>31.72</td><td>28.50</td><td>11.40</td><td>-4.990</td><td>2.519</td><td>0.000c</td></tr><tr><td>Eva.Neg</td><td>1.85</td><td>1.25</td><td>19.00</td><td>19.95</td><td>-0.949</td><td>0.091</td><td>0.806</td></tr><tr><td>Pro.Acc</td><td>64.93</td><td>60.42</td><td>21.67</td><td>17.55</td><td>-1.142</td><td>0.274</td><td>0.264</td></tr><tr><td>Pro.Neg</td><td>8.42</td><td>3.25</td><td>23.31</td><td>16.08</td><td>-2.231</td><td>0.711</td><td>0.044a</td></tr><tr><td>Pro.Re</td><td>26.65</td><td>26.34</td><td>15.00</td><td>23.55</td><td>-2.373</td><td>-0.686</td><td>0.017a</td></tr></table>

Note. a  $\mathrm{p}< 0.05$  b  $\mathrm{p}< 0.01$  cp0.001.

![](images/4d60b3b848f7909d8e058da44e94f235243750f26dbedb774414c1aef7234a87.jpg)  
Fig. 6. Comparison of help-seeking process temporal patterns in level of activities between AI Group and HE Group (Note: Transition probabilities: TP. Black arcs represent similar TPs (i.e., less than 0.05 difference) in the compared models. Red arcs represent higher TP in the AI Group condition, while green arcs represent higher TP in the HE Group condition). (For interpretation of the references to colour in this figure legend, the reader is referred to the Web version of this article.)

proceed through an inner- loop between Asking Help stage and Processing Help stage, using the result in Processing Help stage to guide following Asking Help stage without connecting Evaluating Help stage as a mediation. These results suggest a trend that learners skip metacognitive stages outlined in the theoretical help- seeking process model when seeking help from ChatGPT (Davison et al., 2023; Liu et al., 2024), thereby exhibiting non- linear characteristics that previous help- seeking models did not capture (Karabenick & Gonida, 2017).

Therefore, our findings empirically extend previous assumptions by indicating that the help- seeking linear process can be influenced by different help source. Help- seeking with ChatGPT is less orderly than theoretical model, particularly regarding the enactment, sequence, and interaction of certain skills with problem- solving (Davison et al., 2023; Mercier & Frederiksen, 2008). When facing different help source, the help- seeking process can also start with the other stages with a probability decreasing towards the end of the process (Mercier & Frederiksen, 2008). In other words, our results suggest that existing discussion in theoretical help- seeking process models may be inadequate for capturing the nature of the help- seeking process with ChatGPT, highlighting the need for further theoretical model exploration in future studies (Mercier & Frederiksen, 2008).

# 5.1.2. Metacognition in help-seeking process with ChatGPT

In the current study, we found AI Group tended to ask questions directly at the beginning stage of help- seeking process, while HE Group tended to diagnose their questions as the beginning stage of help- seeking process. As previous studies discussed, AI users are at risk of failing to correctly monitor the extent of their own contribution when being assisted by an AI, especially for generative AI like ChatGPT (Skulmowski, 2024). Our result further indicated that, when in a complex learning task, learners tend to ask ChatGPT at the beginning of the help- seeking process to gather information for organising subsequent questions (e.g., "What's the problem with my essay?"), indicating that learners may use ChatGPT to offload their metacognitive monitoring (Atchley et al., 2024). This reliance on

ChatGPT to self- monitoring aligns with previous studies found that when under high cognitive load in a complex task, humans are more willing to share workloads with technological aids (Skulmowski, 2023; Wahn et al., 2023).

This finding differs from previous investigations of seeking help from ChatGPT where there was no difference in metacognitive monitoring between groups using ChatGPT and those not using it (Urban et al., 2024). However, our study aligns with Zamfirescu- Pereira et al. (2023), who found that novice users were generally inaccurate at metacognitive monitoring when working with a generative AI tool on a complex prompt design task. We posit that the discrepancy can be attributed to the difficulty of the learning tasks. In the study by Urban et al. (2024), learners were tasked with generating the largest possible number of original ideas about different uses of a common object (e.g., paperclip, brick, can) with ChatGPT. The question was pre- defined in the task, so learners might not have needed to monitor their understanding to formulate individualised questions (Liu et al., 2024). In contrast, the current experiment involved a complex learning task, specifically essay revision, where learners' questions could vary based on differences in metacognitive monitoring (Wang et al., 2023). Our findings indicated that learners may offload monitoring to ChatGPT, thereby broadening our understanding of how learners monitor their own learning when seeking help from AI. This underscores the importance of providing scaffolds to support metacognitive monitoring for learners in complex learning tasks (Kuklick et al., 2023).

In addition, the results also indicated that learners in AI Group had a direct stage transition between Asking Help stage and Processing Help stage without Evaluating Help stage as a mediation. Many studies have emphasised the importance of evaluation in SRL (Winne & Perry, 2000; Zimmerman, 2013). Evaluation serves as a crucial component of SRL, providing learners with insights to assess the effectiveness of their previous actions in achieving learning objectives and guiding adjustments for future endeavours (He et al., 2024; Zimmerman, 2013). Lack of evaluation showed learners may not be effectively internalising the assistance provided, as previous concern of implementing ChatGPT into educational settings showed (Atchley et al., 2024; Kasneci et al., 2023). It is important to note that, on one hand, the prompt we provided for the ChatGPT, which contained a lot of contextual information about the writing task, may have had an impact on the student's evaluation stage. ChatGPT, trained with our prompt, can act as good scaffolding to ensure that the answers returned by ChatGPT are relevant to the writing task, while relieving students of mechanical workload (e.g., sending their essays). But the pre- determined prompt may also have some drawbacks: students may overestimate the effectiveness of answers from the ChatGPT and thus be less proactive in assessing the feedback. As Zirar (2023) points out, the integration of language models in student learning is only valuable if students actively check the validity, reliability, and accuracy of the generated material. On the other hand, it is noteworthy that there may be differences in the type of help provided by ChatGPT and human experts, which could influence students' help- seeking behaviours. For instance, help can range from "swallow help" (i.e., direct answers without prompting further thought) to "reflective metacognitive help" (i.e., guidance that encourages deeper thinking and reflection). ChatGPT's responses are often more direct and may not encourage deep reflection; in contrast, human experts might provide more reflective and heuristic assistance, prompting students to engage in higher- order metacognitive activities (Jia et al., 2024; Urban et al., 2024). These differences in response content could lead to changes in help- seeking behaviour, such as students skipping the evaluation phase.

Moreover, previous studies argue that evaluating ChatGPT- generated content can be challenging for learners unfamiliar with this area, as ChatGPT can produce structurally correct but factually incorrect answers (Dwivedi et al., 2023). That aligned with our results, revealing that learners tend to skip the metacognitive evaluation stage and learners may not be aware of the risks associated with using ChatGPT in practice. This finding contrasts with previous research by Chan and Hu (2023), who conducted a survey and found that students realised several concerns about ChatGPT, such as ethics, privacy, and over- rely on these tools, which could potentially impair their skill development. Our study shows that in real learning contexts, learners might overlook the risks of using ChatGPT, more likely to skip the evaluation stage and over- rely on ChatGPT.

In summary, for our RQ1, the results also indicated that the help- seeking process when learners seeking help from ChatGPT showed a tendency to skip the Diagnosing Question and Evaluating Help stages, which could be concluded to learners' offloading monitoring to and over- rely on the ChatGPT. Therefore, it would be valuable for future studies to develop scaffolding that can enhance learners' metacognitive skills. For instance, educators can encourage learners to evaluate the help provided by ChatGPT through various methods, such as submitting comments or reflections (Davison et al., 2023). This practice fosters metacognitive awareness and promotes more effective instrumental help- seeking activities (Aleven et al., 2016). Such evaluation tasks prompt learners to critically assess the relevance, accuracy, and comprehensiveness of ChatGPT's responses in relation to their learning objectives (Dunn et al., 2014). By encouraging learners to explain their thinking and reasoning when they accept or reject ChatGPT's suggestions, educators can help them better understand the material and improve their ability to know when and how to ask for help (Karabenick & Gonida, 2017).

# 5.2. Findings in help-seeking activities when seeking help with ChatGPT

We examined the differences in learners' help- seeking activities. This investigation focused on their descriptive activity ratios and temporal activity patterns. We found that learners in AI Group showed more activities of seeking executive help. As Karabenick and Gonida (2017) indicated, the rapid growth of information technology made resources instantly accessible, naturally leading to increased executive help seeking, such as learners searching ready- made online schoolwork (Yang & Stefaniak, 2023). Our results further showed that learners tend to seek help by asking for executable results or direct answers to rapidly improve their performance when learners use AI tools like ChatGPT, which is aligned with previous exploration (e.g., Urban et al. (2024); Liu et al. (2024)).

Moreover, we found that there was no significant difference in avoidant help- seeking activities between the AI Group and the HE Group. This finding appears to contrast the findings of previous studies suggesting that seeking help from intelligent systems reduces students' perception of help- seeking as a threat (Aleven et al., 2016). However, it is crucial to note that in our experiment, participants sought help from the human expert in an online chat environment, rather than in a traditional face- to- face setting. In a traditional

classroom environment, students may experience heightened anxiety and fear of judgement from peers when seeking help publicly (Pajares & Kranzler, 1995). This social pressure can lead to avoidant help- seeking behaviours as students attempt to shield themselves from potential embarrassment. In contrast, the anonymity and privacy afforded by online platforms can mitigate these social anxieties, allowing students to feel more secure in their help- seeking efforts (Broadbent & Lodge, 2021). Therefore, our findings suggest that an online environments, students may not perceive help- seeking as threatening, regardless of whether they seek help from an intelligent system or a human expert.

Further analysis of temporal activity patterns revealed that when learners exhibited avoidant help- seeking behaviours, they tended to follow up with instrumental help- seeking activities. On the one hand, that represents avoidant help- seeking, previously considered a negative factor in learning due to feelings of shame about one's own inability (White & Bembenutty, 2013). However, avoidant help- seeking may become an indicator of learning autonomy in a ChatGPT- based help- seeking environment (Karumbaiah et al., 2022). Traditionally, avoidant help- seeking was seen as a mechanism for learners to conceal their weaknesses (Newman, 2008). However, our temporal activity patterns showed that in the AI Group, avoidant help- seeking could be interpreted as a strategic consideration of whether ChatGPT has the capability to answer their questions, rather than a mere avoidance of help- seeking itself (Karabenick & Berger, 2013). In our experiment, the pattern demonstrated that learners deleted their entire question text (indicating Avoidant Help- Seeking) instead of refining it, and subsequently posed instrumental questions. This behaviour suggests that learners engaged in active thinking about how to formulate valuable questions to receive guidance from ChatGPT by discarding less suitable questions. Our findings indicate that in a ChatGPT- based learning environment, avoidant help- seeking should not be automatically considered negative (Newman, 2008). Instead, it can be an important activity that fosters learners' autonomy and critical reflection skills (White & Bembenutty, 2013). On the other hand, avoiding seeking help from ChatGPT may not necessarily imply that learners are abandoning the exploration of their questions. Instead, they may be resolving their questions independently by seeking information from other learning materials. This independent resolution points toward a broader spectrum of self- regulated learning strategies where learners actively decide the most appropriate sources for their needs. It highlights an element of metacognitive skill development, as learners discern the utility of different resources and tailor their help- seeking behaviour accordingly (Karabenick & Berger, 2013). By recognising and encouraging strategic avoidant help- seeking within ChatGPT- based learning environments, educators can better support the development of autonomous, reflective, and self- regulated learners.

In addition, our results showed the significant differences in neglecting received help and reviewing previous help activities between two groups. The temporal activity patterns showed that reviewing previous help can be a significant activity for processing received help from a human teacher, especially when they found current help is unhelpful. In contrast, AI group tended to directly ask follow- up questions for essay writing suggestions. One explanation can be aligned with theoretical considerations that learners' social cost requires them a further consideration on their help- seeking process (Karabenick & Gohida, 2017). For example, learners might consider the social cost of fear of appearing ignorant or attracting negative attention from a human teacher when asking not fully thought out questions (Finney et al., 2018). Therefore, learners usually prepare well by checking previous help messages first before asking the next question (Davison et al., 2023), and more likely to get a high- quality response (Jarvela, 2011). In contrast, when seeking help with ChatGPT, learners were less likely to regard social cost as a significant factor influencing their help- processing activities in the help- seeking process (Adams et al., 2023), and more likely to directly ask ChatGPT for following- up questions. Our results suggested that reviewing previous help can be a significant help- seeking activities that learners seeking help from ChatGPT may overlook. It is valuable to encourage its use in a ChatGPT based environment for better question asking.

# 6. Limitation and future research

There are several limitations in our study and implications for the future research. First, despite we proposed a multimodal framework to measure help- seeking process, there still remain the validity limitation in our measurement framework. The theoretical model (Nelson- Le Gall, 1981; Karabenick & Berger, 2013) depict both cognitive (e.g., awareness of need for help) and behavioural (e.g., employ strategies to elicit help) stages in the help- seeking process. However, activities in the cognitive stages were harder to measure compared to the observable activities in the behavioural stages (Fan et al., 2022). Cognitive stages may encompass many inner psychological activities which may not be observed. For instance, during the "Evaluating Help" stage, we did not differentiate between positive or negative views when learners provided no feedback, coding it simply as "Evaluating Help.NoFeedback." We considered the inner psychological activities may not be precisely inferred through observable events (e.g., clicks), because the coding process relied on human judgement to assess learners' internal psychological activities and that could bring biased interpretations. This lack of measuring learners' inner psychological activities limits the validity of our multimodal measurement framework. Previous studies have shown that think- aloud data can be a useful channel for measuring learners' cognitive and psychological activities (Cheng et al., 2024; van der Linden et al., 2023), as think aloud data involve learners self- reports of their real- time thoughts. Future research can use think- aloud data to validate our coding framework. Moreover, our findings suggest that the current theoretical help- seeking process model may not fully capture the nature of learners seeking help from ChatGPT. Incorporating think- aloud data can offer deeper insights into learners' thoughts and judgements during the process, thus aiding in the development of a more comprehensive help- seeking process model tailored for the hybrid human- AI learning era (Molenaar, 2022a, 2022b).

Second, the interactions between students and human experts were conducted within a controlled online environment rather than a naturalistic classroom setting. In real- world classroom settings, non- verbal cues such as facial expressions and pauses might carry an additional significance, influencing the dynamics of help- seeking interactions. Furthermore, one- on- one settings in our study may not have fully captured the complexities of classroom- based interactions, where peer presence and teacher involvement can affect students' behaviour. For instance, due to the constraints of our experiment platform, we did not provide learners with the opportunity to

freely choose between different help sources (ChatGPT/Human expert) when they were seeking help. However, identifying different help sources to seek help is a common stage for learners in authentic learning environments (Karabenick & Gonida, 2017). According to previous theories, identifying potential help sources requires learners' social and metacognitive competencies (Karabenick & Berger, 2013). In authentic learning environment, recognising when and how to seek help from different sources is an important part for learners' self- regulation in help- seeking process (Karabenick & Gonida, 2017). As our findings indicated, it is interesting to investigate how the metacognition develop in the process of learners' help- seeking when they seek help from ChatGPT. Therefore, future studies could explore conditions where learners have the freedom to choose between ChatGPT and human experts, in order to explore whether our findings can be extended to authentic learning environment when learners actively choosing ChatGPT for help. Additionally, our current laboratory experiment had a relatively small sample size, potentially affecting the statistical reliability and overall stability of the results. The sample size could increase the risk of random variability and outlier influence, which may not accurately represent the general population. To ensure more robust and stable conclusions, future studies should engage a larger number of participants from diverse, authentic learning environments. Expanding the sample size and scope will help validate our findings and enhance their applicability to real- world scenarios. Moreover, the prompt we provided for ChatGPT made the students' help- seeking behaviour different from the real condition. With the support of the prompt, students have a higher probability of trusting the answers given by the ChatGPT without subjective assessment. Future research should explore the impact of whether or not to provide prompt, and what kind of prompt are provided, on students' seeking help from ChatGPT.

Finally, our experiment was contextualised in developing ESL learners' writing skills, where ChatGPT was proven capable in this area (Bibi & Atta, 2024; Mogavi et al., 2024). In the meantime, we did not perform an indepth analysis of the quality of the context and the nature of the help provided. For example, the content of the help provided by ChatGPT versus human experts may differ significantly, directly impacting students' help- seeking behaviours. In essay revision task, ChatGPT might tend to provide more direct help, whereas human experts might offer more reflective and heuristic assistance (Jia et al., 2024). As Urban et al. (2024) and Liu et al. (2024) indicated that, students' perception of task interest and ChatGPT's generated content quality may influence their problem- solving behaviour with ChatGPT.

Similarly, the learning task could potentially influence how learners engaged in different help- seeking activities. To generalise the findings of the current study, along with the effects of the help content on learners' help- seeking process from ChatGPT should be explored in other academic areas (Jia et al., 2024). This exploration could help to understand the broader potential of ChatGPT tools in aiding learner learning.

# 7. Conclusion

In conclusion, our study utilised a combination of statistical testing and process mining methods with multimodal data, revealing learners' actual help- seeking process in an essay revision task with different help source (ChatGPT/Human expert). The analysis of stages showed help- seeking process with ChatGPT exhibited non- linear sequence that previous theoretical process models did not capture, while help- seeking process with human showed more linear sequence aligned with theory. Further investigation showed the non- linear help- seeking process may exhibit due to learners' offload monitoring to ChatGPT and over- rely on ChatGPT. The analysis of activities discussed that avoidant help- seeking activity and reviewing previous help activity may be beneficial to learners to seek better help from ChatGPT. Our findings provide insights for enhancing the use of ChatGPT as a help source in the future educational contexts, and highlight the needs for metacognition scaffolding in ChatGPT- based help- seeking environment. Our study offers a new perspective on the interaction between learners and ChatGPT, proposing that ChatGPT can serve a unique role in learners' help- seeking process.

# CRediT authorship contribution statement

Angxuan Chen: Writing - review & editing, Writing - original draft, Methodology, Formal analysis, Conceptualization. Mengtong Xiang: Writing - original draft, Methodology, Formal analysis, Conceptualization. Junyi Zhou: Writing - original draft, Methodology, Formal analysis, Conceptualization. Jiyou Jia: Supervision. Junjie Shang: Supervision, Resources. Xinyu Li: Software, Data curation. Dragan Gasevic: Writing - review & editing, Supervision, Resources, Project administration, Conceptualization. Yizhou Fan: Writing - review & editing, Writing - original draft, Supervision, Resources, Project administration, Investigation, Funding acquisition, Data curation, Conceptualization.

# Ethics approval (include appropriate approvals or waivers)

This study was conducted in compliance with the ethical policy and approval by the Peking University Research Ethics Committee.

# Consent for publication (include appropriate statements)

We have the consent from the ethical committee and all co- authors to publish this paper. This paper has not been submitted and published elsewhere.

# Research involving human participants and/or animals

Yes, we collected the learning trace data of human participants. We collected, stored and analysed these data in accordance with

ethical approvals. At the time of acquisition, the data has been anonymized.

# Declaration of competing interests

The authors declare that there is no conflict of interest that could be perceived as prejudicing the impartiality of the research reported.

# Acknowledgements

This study was funded by the Society for Learning Analytics Research (Early Career Research Grant 2023) and the National Natural Science Foundation of China (Grant No. 62407001). Thanks to Huixiao Le and Yuan Shen for their valuable discussions and comments, and to Luzhen Tang for her support in data collection.

# Appendix A. Supplementary data

Supplementary data to this article can be found online at https://doi.org/10.1016/j.compedu.2024.105198.

# Data availability

Data will be made available on request.

# References

Adams, D., Chuah, K- M., Devadason, E., & Azzis, M. S. A. (2023). From novice to navigator: Students' academic help seeking behaviour, readiness, and perceived usefulness of chatgpt in learning. Education and Information Technologies, 29, 1- 18. Aleven, V., Mclaren, B., Roll, I., & Koedinger, K. (2006). Toward meta- cognitive tutoring: A model of help seeking with a cognitive tutor. International Journal of Artificial Intelligence in Education, 16, 101- 124. Aleven, V., Roll, I., McLaren, B. M., & Koedinger, K. R. (2016). Help helps, but only so much: Research on help seeking with intelligent tutoring systems. International Journal of Artificial Intelligence in Education, 26, 205- 223. Aleven, V., Stahl, E., Schworm, S., Fischer, F., & Wallace, R. (2003). Help seeking and help design in interactive learning environments. Review of Educational Research, 73, 277- 320. Antonietti, C., Schmitz, M- L., Consoli, T., Cattano, A., Gonon, P., & Petko, D. (2023). Development and validation of the icap technology scale to measure how teachers integrate technology into learning activities. Computers & Education, 192, Article 104648. Atchley, P., Pannell, H., Wofford, K., Hopkins, M., & Atchley, R. A. (2024). Human and ai collaboration in the higher education environment: Opportunities and concerns (Vol. 9, pp. 20). Cognitive Research: Principles and Implications. Bibi, Z., & Atta, A. (2024). The role of chatgpt as ai English writing assistant: A study of student's perceptions, experiences, and satisfaction. Annals of Human and Social Sciences, 5, 433- 443. Broadbent, J., & Lodge, J. (2021). Use of live chat in higher education to support self- regulated help seeking behaviours: A comparison of online and blended learner perspectives. International journal of educational technology in higher education, 18, 17. Chan, C. K. Y., & Hu, W. (2023). Students' voices on generative ai: Perceptions, benefits, and challenges in higher education. International Journal of Educational Technology in Higher Education, 20, 43. Cheng, K- H., Liang, J.- C., & Tsai, C.- C. (2013). The role of internet- specific epistemic beliefs and self- regulation in high school students' online academic help seeking: A structural equation modeling analysis. Journal of Educational Computing Research, 48, 469- 489. Cheng, G., Zou, D., Xie, H., & Wang, F. L. (2024). Exploring differences in self- regulated learning strategy use between high- and low- performing students in introductory programming: An analysis of eye- tracking and retrospective think- aloud data from program comprehension. Computers & Education, 208, Article 104948. Chu, Y., Palmer, S., & Persky, A. M. (2018). Assessing metacognition in the classroom: Student help- seeking behavior. Currents in Pharmacy teaching and Learning, 10, 1478- 1487. Clegg, S., Bradley, S., & Smith, K. (2006). 'i've had to swallow my pride': Help seeking and self- esteem. Higher Education Research and Development, 25, 101- 113. Davison, K., Malmberg, L- E., & Sylva, K. (2023). Academic help- seeking interactions in the classroom: A microlinguinal study. British Journal of Educational Psychology, 93, 33- 55. https://doi.org/10.1111/bjep.12538. Diasamidze, L., & Tedoradze, T. (2024). Application of gpt models in English language teaching. Language and Culture, 9, 76- 81. Dulli, R. E., Rakes, G. C., & Rakes, T. A. (2014). Influence of academic self- regulation, critical thinking, and age on online graduate students' academic help- seeking. Distance Education, 35, 75- 89. Dwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabullah, A. M., Koohang, A., Raghavan, V., Ahuja, M., Albanna, H., Albashrawi, M. A., Al- Busaidi, A. S., Balakrishnan, J., Barlette, T., Basu, S., Bose, I., Brooks, L., Buhalis, D., et al. (2023). Opinion paper: "so what if chatgpt wrote it?" multidisciplinary perspectives on opportunities, challenges and implications of generative conversational ai for research, practice and policy. International Journal of Information Management, 71, 1026- 42. Exintaris, B., Karunaratne, N., & Yuriev, E. (2023). Metacognition and critical thinking: Using chatgpt- generated responses as prompts for critique in a problem- solving workshop (smartchemper). Journal of Chemical Education, 100, 2972- 2980. Fan, Y.- H., & Lin, T.- J. (2023). Identifying university students' online academic help- seeking patterns and their role in internet self- efficacy. The Internet and Higher Education, 56, Article 100893. Fan, Y., van der Graaf, J., Lim, L., Rakovic, M., Singh, S., Kilgour, J., Moore, J., Molenaar, I., Bannert, M., & Gasevic, D. (2022). Towards investigating the validity of measurement of self- regulated learning based on trace data. Metacognition and Learning, 17, 949- 987. Finney, S., Barry, C. L., Horst, S. J., & Johnston, M. M. (2018). Exploring profiles of academic help seeking: A mixture modeling approach. Learning and Individual Differences, 61, 158- 171. https://doi.org/10.1016/J.LINDIF.2017.11.011. Gatta, R., Lenkovicz, J., Vallati, M., Rojas, E., Damiani, A., Sindici, L., De Bari, B., Dagliati, A., Fernandez- Llatas, C., Montesi, M., et al. (2017). pminer: An innovative library for performing process mining in medicine. In Artificial Intelligence in medicine: 16th conference on artificial intelligence in medicine, AIME 2017, Vienna, Austria, June 21- 24, 2017, proceedings (Vol. 16, pp. 351- 355). Springer.

He, S., Epp, C. D., Chen, F., & Cui, Y. (2024). Examining change in students' self- regulated learning patterns after a formative assessment using process mining techniques. Computers in Human Behavior, 152, Article 108061. Herbold, S., Haulti- Janisz, A., Heuer, U., Kikteva, Z., & Trautsch, A. (2023). A large- scale comparison of human- written versus chatgpt- generated essays. Scientific Reports, 13, Article 18617. Hou, I., Mettille, S., Man, O., Li, Z., Zastudil, C., & MacNeil, S. (2024). The effects of generative ai on computing students' help- seeking preferences. In Proceedings of the 26th australasian computing education conference (pp. 39- 48). Huang, K., Law, V., & Lee- Post, A. (2024). Relationships among class climate, students' internal help- seeking inclinations, participation in peer help and achievement in an online class. British Journal of Educational Technology, 55, 2132- 2150. Järvelä, S. (2011). How does help seeking help? new prospects in a variety of contexts. Learning and Instruction, 21, 297- 299. Jia, J., Wang, T., Zhang, Y., & Wang, G. (2024). The comparison of general tips for mathematical problem solving generated by generative ai with those generated by human teachers. Asia Pacific Journal of Education, 44, 8- 28. Karabenick, S. A., & Berger, J- L. (2013). Help seeking as a self- regulated learning strategy. In Applications of self- regulated learning across diverse disciplines. A tribute to barry J. Zimmerman (pp. 237- 261). IAP Information Age Publishing. Publisher: IAP Information Age Publishing. Karabenick, S. A., & Dembo, M. H. (2011). Understanding and facilitating self- regulated help seeking. New Directions for Teaching and Learning, 2011, 33- 43. Karabenick, S. A., & Gonida, E. N. (2017). Academic help seeking as a self- regulated learning strategy: Current issues, future directions. In Handbook of self- regulation of learning and performance (pp. 421- 433). Routledge. Karbenick, S. A., & Newman, R. S. (2009). Scheduling help: Generalizable self- regulatory process and social- cultural behavior. In Contemporary motivation research. From global to local perspectives (pp. 25- 48). Germany: Hogrefe & Huber Publishers. Hogrefe & Huber. Publisher. Karumbaiah, S., Ocumpaugh, J., & Baker, R. S. (2022). Context matters: Differing implications of motivation and help- seeking in educational technology. International Journal of Artificial Intelligence in Education, 32, 685- 724. Kasneci, E., Seßler, K., Kuchemann, S., Bannert, T., Dementieva, D., Fischer, F., Gasser, U., Groh, G., Gündemans, S., Hüllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, G., Pfeffer, J., Poquet, O., Sailer, M., Schmidt, A., Seidel, T., Stadler, M., et al. (2023). Chatgpt for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 103, 102274. Kuklick, L., Greiff, S., & Lindner, M. A. (2023). Computer- based performance feedback: Effects of error message complexity on cognitive, metacognitive, and motivational outcomes. Computers & Education, 200, Article 104785. Leenknecht, M. J., & Carless, D. (2023). Students' feedback seeking behaviour in undergraduate education: A scoring review. Educational Research Review, Article 100549. Lin, C- J., & Mubarak, H. (2021). Learning analytics for investigating the mind map- guided ai chatbot approach in an efl flipped speaking classroom. Educational Technology & Society, 24, 16- 35. Liu, M., Zhang, L. J., & Biebricher, C. (2024). Investigating students' cognitive processes in generative ai- assisted digital multimodal composing and traditional writing. Computers & Education, 211, Article 104977. Macbeth, G., Razumiejczyk, E., & Ledesma, R. D. (2011). Cliff's delta calculator: A non- parametric effect size program for two groups of observations. Universitas Psychologica, 10, 545- 555. Makara, K. A., & Karabenick, S. A. (2013). Characterizing sources of academic help in the age of expanding education technology: A new conceptual framework. In Advances in help- seeking research and applications. The role of emerging technologies (pp. 37- 72). Information Age Publishing. Martin- Arbos, S., Castarlenas, E., & Duenas, J- M. (2021). Help- seeking in an academic context: A systematic review. Sustainability, 13, 4460. Mercier, J., & Frederiksen, C. (2008). The structure of the help- seeking process in collaboratively using a computer coach in problem- based learning. Computers & Education, 51, 17- 33. Mogavi, R. H., Deng, C., Kim, J. J., Zhou, P., Kwon, Y. D., Metwally, A. H. S., Tlili, A., Bassanelli, S., Bucchiarone, A., Gujar, S., et al. (2024). Chatgpt in education: Blessing or a curse? A qualitative study exploring early adopters' utilization and perceptions. Computers in Human Behavior, Artificial Humans, 2, Article 100027. Molenaar, I. (2022a). The concept of study human- ai regulation: Exemplifying how to support young learners' self- regulated learning. Computers & Education: Artificial Intelligence, 3, Article 100070. Molenaar, I. (2022b). Towards hybrid human- ai learning technologies. European Journal of Education, 57, 632- 645. Nelson, L. J., & Fyfe, E. R. (2019). Metacognitive monitoring and help- seeking decisions on mathematical equivalence problems. Metacognition and Learning, 14, 167- 187. Nelson- Le Gall, S. (1981). Help- seeking: An understudied problem- solving skill in children. Developmental Review, 1, 224- 246. Newman, R. S. (2008). Adaptive and nonadaptive help seeking with peer harassment: An integrative perspective of coping and self- regulation. Educational Psychologist, 43, 1- 15. Onder, A., & Akcapinar, G. (2023). Investigating the effect of prompts on learners' academic help- seeking behaviors on the basis of learning analytics. Education and Information Technologies, 28, 16909- 16934. Pajares, F., & Kranzler, J. (1995). Self- efficacy beliefs and general mental ability in mathematical problem- solving. Contemporary Educational Psychology, 20, 426- 443. Pintrich, P. R. (2004). A conceptual framework for assessing motivation and self- regulated learning in college students. Educational Psychology Review, 16, 385- 407. Roussel, P., Elliot, A. J., & Feltman, R. (2011). The influence of achievement goals and social goals on help- seeking from peers in an academic context. Learning and Instruction, 21, 394- 402. Saint, J., Gasevici, D., Matcha, W., Uzir, N. A., & Pardo, A. (2020). Combining analytic methods to unlock sequential and temporal patterns of self- regulated learning. In Proceedings of the tenth international conference on learning Analytics & knowledge LAK (Vol. 20, pp. 402- 411). Frankfurt, Germany: Association for Computing Machinery. https://doi.org/10.1145/3375461.3375487, 10.1145/3375462.3375487. Skulmowski, A. (2023). The cognitive architecture of initial externalization. Educational Psychology Review, 35, 101. Skulmowski, A. (2024). Place or assistant? Generalization externalization. Educational anthropomorphization. Educational Psychology Review, 36, 1- 18. Tossell, C. C., Tenhundfeld, N. L., Momen, A., Cooley, K., & de Visser, E. J. (2024). Student perceptions of chatgpt use in a college essay assignment: Implications for learning, grading, and trust in artificial intelligence. IEEE Transactions on Learning Technologies, 17, 1069- 1071. Urban, M., Dechterenko, F., Lukavsky, J., Hrabalova, V., Svacha, F., Brom, C., & Urban, K. (2024). Chatgpt improves creative problem- solving performance in university students: An experimental study. Computers & Education, Article 105031. van Der Graaf, J., Lim, L., Fan, Y., Kilgour, J., Moore, J., Bahnert, M., Gasevic, D., & Molenaar, I. (2021). Do instrumentation tools capture self- regulated learning?. In LAK21: 11th international learning analytics and knowledge conference (pp. 438- 448). van der Linden, S., Papadopoulos, P. M., Nieveen, N., & McKenney, S. (2023). Reflect: Formative assessment for teacher reflection in video- coaching settings. Computers & Education, 203, Article 104845. Wahn, B., Schmitz, L., Gerster, F. N., & Weiss, M. (2023). Offloading under cognitive load: Humans are willing to offload parts of an attentionally demanding task to an algorithm. PLoS One, 18, Article e0286102. Wang, T., Li, S., Tan, C., Zhang, J., & Lajoie, S. P. (2023). Cognitive load patterns affect temporal dynamics of self- regulated learning behaviors, metacognitive judgments, and learning achievements. Computers & Education, 207, Article 104924. Webb, N., & Mastergeorge, A. M. (2003). Promoting effective helping behavior in peer- directed groups. International Journal of Educational Research, 39, 73- 97. https://doi.org/10.1016/S0883- 0355(03)00074- 0. White, M. C., & Bembenutty, H. (2013). Not all avoidance help seekers are created equal: Individual differences in adaptive and executive help seeking. Sage Open, 3, 1- 14. Winne, P. H., & Perry, N. E. (2000). Chapter 16 - measuring self- regulated learning. In M. Boekaerts, P. R. Pintrich, & M. Zeidner (Eds.), Handbook of self- regulation (pp. 531- 566). San Diego: Academic Press. https://doi.org/10.1016/B978- 012109890- 2/50045- 7. URL: http://www.sciencedirect.com/science/article/pii/B9780121098902/000073. Yang, F., & Stefaniak, J. (2023). A systematic review of studies exploring help- seeking strategies in online learning environments. Online Learning, 27, 107- 126.

Zamfiresc- Pereira, J., Wong, R. Y., Hartmann, B., & Yang, Q. (2023). Why johnny can't prompt: How non- ai experts try (and fail) to design I'm prompts. In Proceedings of the 2023 CHI conference on human factors in computing systems (pp. 1- 21). Zimmerman, B. J. (2002). Becoming a self- regulated learner: An overview. Theory into practice, 41, 64- 70. Zirar, A. (2023). Exploring the impact of language models, such as chatgpt, on student learning and assessment. The Review of Education, 11, 3.