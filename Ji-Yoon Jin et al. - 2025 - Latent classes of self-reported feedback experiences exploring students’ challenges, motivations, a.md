# Latent classes of self-reported feedback experiences: exploring students' challenges, motivations, and action-taking behaviours in feedback processes

Flora Ji- Yoon Jin $^{1}$ $\oplus$  Lixiang Yan $^{1}$ $\cdot$  Roberto Martinez- Maldonado $^{1}$ $\cdot$  Dragan Gašević $^{1}$ $\cdot$  Philip Wing Keung Chan $^{2}$ $\cdot$  Yi- Shan Isai $^{1}$

Received: 3 July 2023 / Accepted: 8 August 2025  $\mathfrak{G}$  The Author(s) 2025

# Abstract

Although students often acknowledge the importance of feedback, they generally struggle to engage with it and act upon it. Specific pedagogical factors, such as poorly structured feedback, unsuitable tone, and weak educator- student relationships, can impede effective utilisation of feedback. Students also exhibit varying degrees of comprehension, engagement, and action in response to feedback. Despite these observations, there is a lack of empirical studies systematically investigating diverse feedback experiences, practices, and action- taking behaviours of students. This paper addresses this gap by reporting on a study that aimed to explore students' current feedback practices, self- reported action- taking behaviours, and perceived challenges related to students' sensemaking and action- taking processes. A sample of 641 students from higher education was surveyed to investigate: (a) their feedback experiences, including practices, attitudes and beliefs; (b) variations in their motivations and emotional responses to feedback; and (c) variations in students' perceived challenges in understanding and acting on feedback. The study employed 29 Likert scale items and latent class analysis (LCA) to identify four distinct classes of students based on their feedback experiences, aiming to uncover heterogeneity in their inclination to act upon feedback and challenges experienced in the feedback process. Additionally, thematic analysis of four open- ended questions captured a comprehensive understanding of their challenges, motivations, and emotional responses to feedback. The analysis revealed that students showed various levels of feedback experiences, engagement, and challenges in the feedback process across different classes. The paper concludes by highlighting the importance of self regulation skills and the social- affective component of a dialogic feedback process. This process can potentially be facilitated by technology- enhanced feedback tools, such as learning analytics (LA) tools.

Keywords Student feedback experience  $\cdot$  Higher education  $\cdot$  Learning analytics  $\cdot$  Dialogic feedback  $\cdot$  Latent class analysis

# Introduction

Feedback is an essential part of learning. It can help students improve their performance, build self- confidence, and achieve learning objectives (Hattie & Timperley, 2007; Henderson et al., 2019). Although the importance of feedback is widely acknowledged, students often struggle to engage with feedback meaningfully and to convert it into practical insights that enhance their learning (Evans, 2013; Geyskens et al., 2012; Winstone et al., 2017a, b). This disconnect between the potential value of feedback and the ability of students to make use of it has prompted researchers to shift the focus from effective feedback provision to understanding how students interact with, interpret and utilise feedback (Boud & Molloy, 2013). This shift recognises that the effectiveness of feedback depends not only on the quality of its content and delivery but also on students' capacity to understand, process, and act upon the feedback they receive (Carless & Boud, 2018). Both elements are critical: high- quality, specific, and actionable feedback from educators is necessary, but so too is the development of students' skills to engage with and make use of that feedback. Factors such as students' attitudes, learning strategies, and emotional responses to feedback all play crucial roles in determining how effectively they can make use of feedback for their learning (Carless & Boud, 2018; Molloy et al., 2020).

Current literature often treats students as a homogeneous group, overlooking the variations in how different subgroups of students interact with and respond to feedback (Pitt & Norton, 2016; van Wijk et al., 2024; Walker et al., 2020). This can lead to one- size- fits- all interventions that may fail to address the diverse needs and challenges faced by different student populations (Gašević et al., 2016). In practice, students' feedback experiences can vary based on their ability to understand and respond to feedback, the challenges they encounter, and their attitudes towards the feedback process. To address this limitation, there is a need for a deeper understanding of common distinct patterns of feedback experiences and how these experiences differ among students. The current study aimed to fill this gap by exploring the heterogeneity in students' feedback experiences, including their practices, attitudes, and perceived challenges. By identifying and characterising distinct groups of students based on their feedback experiences, we can gain insights into the varying needs and challenges of different student subgroups.

To achieve this goal, we employed Latent Class Analysis (LCA) to identify distinct groups of students based on their feedback practices, attitudes, and perceived challenges. We then explored how different student groups engage with feedback, including their emotional response to critical feedback, motivations to make use of feedback, and challenges in sense- making and action- taking processes. Such insights can inform the development of targeted interventions and support that are better aligned with the specific needs of different student groups (West et al., 2024).

# Background

# Conceptualisation of feedback

Feedback has been acknowledged as one of the most essential components in students' learning and achievement in higher education (Hattie & Timperley, 2007; Henderson et al.,

2019). Feedback aims to help students to bridge the gap between their current and desired understanding by identifying misconceptions and issues with learning strategies and skills (Sadler, 
1989). In recent years, conceptualisations of effective feedback have shifted from the traditional transmission-focused model to a reciprocal model (Boud & Molloy, 
2013). Previously, various studies focused on enhancing the effectiveness of feedback, in particular, the feedback content and structure, premised on the assumption that educators hold the primary onus of ensuring feedback quality (Boud & Molloy, 
2013). For instance, studies advocated the nostrums of constructive feedback, which is intended to sandwich corrective feedback information between two pieces of positive comments (Molloy, 
2010). Furthermore, scholars suggested that effective feedback should be clear, explicit and simple without a multiplicity of intentions packed into each sentence (Ryan et al., 
2022). Another well-known model for providing effective feedback content suggests that effective feedback should include three features (feed up, feed back, and feed forward) and target at four levels (feedback on task, feedback on process, feedback on self-regulation, and feedback on person) (Hattie & Timperley, 
2007). This model encourages more discussion around the topic, such as feedback being more effective when it feeds forward. Despite numerous recommendations for delivering effective feedback content, existing research has revealed a disparity between educators' and students' perceptions of feedback (Mulliner & Tucker, 
2017). While educators may be satisfied with their current feedback practices, believing that their feedback is helpful and beneficial to students' learning, students may feel the opposite and struggle to make sense of feedback or respond to it (Mulliner & Tucker, 2017; Price et al., 
2010). From the perspectives of educators, these issues may lie with students' lack of engagement and ability to interpret or act on feedback (Geyskens et al., 
2012; Jin et al., 2022).

Gradually, feedback researchers have reconceptualised feedback as a reciprocal, dialogic process that emphasises both the educator's responsibility to provide clear, meaningful feedback and the student's active role in engaging with and responding to that feedback (Boud & Molloy, 2013). Scholars have advocated for dialogic feedback as a means of promoting active student engagement, cultivating trust, and facilitating effective communication (Sutton, 2009; Yang & Carless, 2013). To facilitate this, a triangular framework has been proposed that includes three dimensions: cognitive, social- affective, and structural (Yang & Carless, 2013). The cognitive dimension pertains to feedback content that enhances students' cognitive abilities, while the social- affective dimension underscores the importance of trust and balanced power relationships between educators and students. The structural dimension focuses on the management and organisation of the feedback process by educators and institutions.

# Student feedback experience

Despite the shift towards more student- centred, dialogic approaches to feedback (Ryan et al., 2022; Yang & Carless, 2013), research consistently shows that students struggle to engage with and act upon the feedback they receive (O'Donovan et al., 2021; Price et al., 2010). These difficulties stem from various factors related to both feedback design and students' own capabilities, particularly their proactive role and ability to make effective use of feedback, as emphasised in frameworks such as feedback literacy (Carless & Boud, 2018; Molloy et al., 2020). Students frequently report frustration with feedback that is unclear,

shallow, untimely, or difficult to understand and apply (Evans, 2013; Winstone et al., 2017a, b). This disconnect between educator intentions and student perceptions highlights the need for a deeper understanding of students' actual experiences with feedback. Current research indicates that students' responses to feedback vary considerably. Some students actively seek clarification and engage in dialogue about the feedback they receive, while others tend to focus primarily on grades, paying less attention to qualitative comments (Winstone et al., 2017a, b). Many students reported difficulties in translating feedback into concrete actions for improvements (Price et al., 2010). Winstone et al. (2017a, b) identified four key processes that underpin students' engagement with feedback: awareness, cognisance, agency, and volition. These processes influence whether students are capable or willing to engage with feedback effectively.

Students have also reported that they face various challenges in engaging with and utilising feedback. Moreover, their ability to make sense of feedback, such as difficulty understanding the language and terminology used in feedback, has been reported as a significant issue in the feedback processes (Price et al., 2010). The relevance of feedback has also posed a challenge, with students often disregarding feedback that they do not perceive as applicable to future work or assessments (O'Donovan et al., 2021). Timeliness of feedback delivery plays a crucial role, as delayed feedback can be less impactful when students have already moved on to new assignments (Evans, 2013). The specificity of feedback is another concern, with vague or overly general comments commonly proving challenging for students to act upon effectively (Mulliner & Tucker, 2017). Emotional barriers have also been reported as hinders of engagement, because negative responses to critical feedback can affect students' willingness to engage with the feedback process (Blewett, 2020; Robinson et al., 2013). Finally, many students have reported a lack of strategies for effectively implementing the feedback they receive (Winstone et al., 2017a, b), indicating a need for guidance on how to translate feedback into concrete actions for improvement (Carless & Boud, 2018).

# Research questions and contribution

Research questions and contributionWhile the studies described above have provided valuable insights into students' experiences with feedback processes, they have often treated students as a homogeneous group when examining feedback experiences in higher education. This oversimplification hinders a detailed exploration of how different student groups engage with feedback, limiting our understanding at a more granular level. Specifically, this approach obscures important variations in how students from different groups take action on feedback, the specific challenges various student subgroups experience in the feedback process, and the diverse motivations driving students to engage with and act upon feedback. Addressing these limitations is crucial for developing a deeper understanding of students' feedback experiences. By exploring the heterogeneity in students' interactions with feedback, we can gain insights into the varying needs and challenges of different student subgroups. This granular approach is essential for developing targeted interventions and support mechanisms that cater to the diverse needs of different student populations in higher education.

To address these gaps, this study aimed to explore students' feedback experiences, focusing on identifying distinct patterns and understanding the nuances within these patterns. Specifically, this study investigates the following research questions:

RQ1 What distinct patterns of feedback experiences can be identified among students?

RQ2 How do students in distinct patterns of feedback experiences describe their inclination to act on feedback?

RQ3 How do students in distinct patterns of feedback experiences describe their experiences of challenges with feedback?

# Methods

# Sample

This study adopted a mixed- method approach to investigate students' current feedback practices, with a particular focus on the challenges students face in deriving benefits from feedback and their behaviours in taking action (Collins & Lanza, 2009). The sample of participants in this study comprised 641 higher education students (449 females, 176 males, 16 others) from various degree programs. Specifically, 358  $(55.9\%)$  participants were enrolled in undergraduate programs, 40  $(6.2\%)$  in postgraduate diploma or certificate programs, 30  $(4.7\%)$  in honour's programs, 171  $(26.7\%)$  in master's program, 9  $(1.4\%)$  in doctoral programs, and 33  $(5.1\%)$  belonged to other degree programs or did not indicate their program (Table 1). The participants' fields of study were diverse, with 56  $(8.7\%)$  studying science, 350  $(54.6\%)$  studying social science, 76  $(11.9\%)$  studying engineering and computer sciences, and 98  $(15.3\%)$  enrolled in a double- degree program.

Table 1 Demographic characteristics of participants  $(N = 641)$  

<table><tr><td></td><td>Participants</td></tr><tr><td>Gender</td><td></td></tr><tr><td>Male</td><td>176</td></tr><tr><td>Female</td><td>449</td></tr><tr><td>Other</td><td>16</td></tr><tr><td>Degree</td><td></td></tr><tr><td>Undergraduate degree</td><td>358</td></tr><tr><td>Postgraduate diploma or certificate</td><td>40</td></tr><tr><td>Honour&#x27;s degree</td><td>30</td></tr><tr><td>Master&#x27;s degree</td><td>171</td></tr><tr><td>Doctoral degree</td><td>9</td></tr><tr><td>Other</td><td>33</td></tr><tr><td>Discipline</td><td></td></tr><tr><td>Science</td><td>56</td></tr><tr><td>Social Sciences</td><td>350</td></tr><tr><td>Engineering and Computer Science</td><td>76</td></tr><tr><td>Medicine and Health Sciences</td><td>61</td></tr><tr><td>Double-degree</td><td>98</td></tr></table>

# Procedure

ProcedureThe survey was primarily distributed to students in large [Australian] universities, with researchers contacting lecturers through their professional networks at the unit/course level for assistance in promoting the study. It was advertised across various academic units rather than sent directly to specific students. Ethics approval was obtained from Monash University's human research ethics committee under application number, and all participants provided their consent before taking the survey.

# Instruments

The survey instrument used in this study was self- developed based on relevant literature (Boud & Molloy, 2013; Carless & Boud, 2018; O'Donovan et al., 2021; Price et al., 2010; Winstone et al., 2017a, b) and is structured into two parts: the first part consists of a demographic section with eight items, and the second part contains items corresponding to the main research questions. This latter section comprises twenty- nine items and four openended questions, designed to capture a comprehensive understanding of students' feedback experiences (The survey questions are accessible here https://bit.ly/student_feedback_lite_racy_survey). Respondents answered these items related to the main research questions (29 items; Cronbach's alpha  $= 0.85$  ) on a 5- point Likert scale, which ranges from "Strongly disagree" (1) to "Strongly agree" (5). Five items (Act_01 to Act_05) focused on students' actions in response to feedback ('Act' stands for 'action behaviours'). Sixteen items (Chall_1 to Chall_16) addressed various challenges experienced by students ('Chall' stands for 'feedback challenges'). Additionally, eight items (Exp_01 to Exp_08) were included to explore students' feedback practices, including their attitudes, beliefs and their experiences with feedback ('Exp' stands for 'feedback experiences'). Lastly, four open- ended questions were designed to understand students' emotional responses to feedback, challenges in making sense of and acting on feedback, and their motivations to act on feedback. The four open- ended questions were:

Q1: If you have experienced negative feelings when receiving feedback, what were these feelings and how did you cope with them? Q2: If you can recall any experience where you were motivated to act on your teacher's feedback, what might be the reasons? Q3: If you can recall any experience where you struggled to understand your teacher's feedback, what might be the reasons? Q4: If you can recall any experience where you struggled to act on your teacher's feedback, what might be the reasons?

To ensure clarity for survey participants, we included instructions at the beginning of the survey prompting them to reflect on their overall experiences with feedback across their degree program. This encompassed various forms of feedback, including written, oral, and multimodal interactions with teachers. The instruction specifically asked participants to consider, "Please think about your overall experiences with feedback received from teachers in your current study (across units or courses of the degree program)."

# Analysis strategy

Analysis strategyThis study adopted a mixed- methods approach, incorporating both quantitative and qualitative analyses, to address the research questions (Collins & Lanza, 2009). We first utilised latent class analysis (LCA) in an exploratory manner to identify and segment students' feedback experiences. Subsequently, we conducted a thematic analysis to gain detailed insights into the differences in motivations, emotional responses, and challenges experienced by the various latent classes. The specifics of each analysis are detailed in the following sections.

# Latent class analysis

Before performing LCA, we first performed a correlation analysis on all survey items to identify and eliminate. highly correlated pairs. Although LCA does not impose assumptions regarding linearity, normal distribution, homogeneity, or collinearity, highly collinear observed variables can complicate model estimation and potentially hinder convergence. Consequently, removing these variables is justified as they do not contribute unique information (Lanza & Rhoades, 2013; Sinha et al., 2021). An absolute correlation threshold of 0.7 was used as any correlations above this threshold can be considered high, indicating a potential lack of unique information for LCA (Hinkle et al., 2003). As illustrated in the heatmap (Appendix Fig. 7), we excluded two items (Chall_04 and Chall_05) due to their high correlations (Spearman's rho above 0.7) with Chall_03. Additionally, Chall_08 was removed because of its high correlation with Chall_07. This process culminated in the retention of 26 items for the LCA.

To determine the optimal number of latent classes, we fitted latent class models across a range of possible class numbers until the number of parameters estimated exceeds the number of observations (class number  $= 7$  ). We also recorded the Log- likelihood and Bayesian Information Criterion (BIC) values for each model. While higher loglikelihood values suggest a better fit, the BIC penalises model complexity. Hence, the model with the lowest BIC is generally deemed the best fit (Sinha et al., 2021). Once the number of latent classes was determined, we used several metrics to evaluate the model fit for each latent class, including the Average Posterior Probabilities (AvePP), estimated class proportions  $(\hat{\pi}_k)$  , and mean classification accuracy probabilities (MAP). We also considered discrepancies between observed and expected frequencies (Lanza & Rhoades, 2013; Sinha et al., 2021). Throughout the latent class model- building process, the interpretability of the solution remained a key consideration. According to Lanza and Rhoades (2013), class interpretability should be guided by a clear separation between classes, ease of labelling, and logical patterns. To aid in assessing the interpretability of the solution, we followed the steps recommended by Oberski (2016) and utilised profile plots. These plots present the estimated class means rather than the estimated distributions, making them more accessible given the five possible response categories (  $1 =$  Strongly Disagree to  $5 =$  Strongly Agree).

# Qualitative analysis of open-ended questions

Qualitative analysis of open- ended questionsTo analyse the responses to the four open- ended questions of the survey, a thematic analysis was conducted using the NVivo software. Our coding process involved both inductive and deductive approaches. We initially developed codes inductively based on participants'

responses. We then categorised these codes into structured themes based on existing literature. For the feedback design codes, we drew on the learner- centred feedback framework (Ryan et al., 2022) and the triangular framework of dialogic feedback process (Yang & Carless, 2013). We developed one comprehensive coding scheme applicable to all questions, as many themes were relevant across different aspects of feedback experiences. This approach allowed us to capture the interconnected nature of feedback experiences across different questions. For example, challenges in making sense of feedback and taking action could both relate to issues with feedback design (e.g., lack of depth, not highlighting strengths) or students' own abilities (e.g., difficulty processing feedback).

A coding scheme consisting of twenty- nine codes was developed and then grouped into three levels of themes, with the top- level themes being feedback design and student factors (The coding scheme is accessible here https://bit.ly/student_survey_codebook). To analyse student factors in feedback experiences, we utilised the feedback literacy framework as a structured approach to understand students' capabilities, challenges, and motivations. Feedback literacy refers to students' ability and mindset to understand, interpret, and utilise feedback to enhance their learning (Carless & Boud, 2018). This concept is closely related to how students experience and engage with feedback processes. The set of codes for student factors draws on the work of Carless and Boud (2018) as well as Molloy et al. (2020), providing a comprehensive lens through which to examine student experiences.

Based on these frameworks, we developed the following codes to categorise student factors:

- Appreciation: Students' recognition of the value and importance of feedback in their learning process.- Commits to feedback as improvement: Students' dedication to using feedback as a tool for enhancing their performance and learning.- Elicits information to improve learning: Students' proactive approach in seeking additional information or clarification to better understand and apply feedback.- Managing affect: Students' ability to handle emotional responses to feedback, particularly when it is critical or challenging.- Processes feedback information: Students' capacity to interpret, analyse, and make sense of the feedback they receive.- Taking actions: Students' ability to implement concrete steps based on the feedback to improve their work or learning strategies.

By using this framework as a guide, we were able to systematically explore how students' own capabilities and dispositions influence their feedback experiences, challenges, and motivations. This approach allowed us to gain insights into the various factors that contribute to effective feedback engagement from the student perspective.

One round of inter- rater reliability test between two researchers was conducted by using the first  $10\%$  of the survey responses, and Cohen's Kappa result was 0.87, indicating a "very good" agreement according to Mabmud (2010). Subsequently, the main coder completed the coding process for all responses. Participants' responses were not limited to a single code. We coded responses into multiple categories when applicable. In the following section, quotations from study participants are identified as P (participant) with a numerical value assigned to distinguish between individuals (e.g., P1 and P2). All the numbers

cited throughout Sect. Results (e.g.,  $n = 20$ ) indicate the count of participants who expressed a specific idea (Code comparison tables provided in the Appendix A). The percentages reported represent the relative frequencies of each code within each latent class, facilitating direct comparisons between groups of different sizes. To enhance the clarity and comprehensiveness of the data presentation in the Sect. Results, a bar chart was plotted for visualising the data. This visualisation effectively illustrates the hierarchical structure of the codes along with their corresponding percentages, enabling an intuitive and comparative view of the data across different classes. For clarity and ease of comparison, codes with relatively low frequencies have been removed from the visualisation. Additionally, all direct quotes presented in Sect. Results were slightly modified for clarity while preserving the accuracy of the participants' original statements. Explanations or corrections were inserted in square brackets to ensure grammatical correctness. The process for selecting quotes was as follows:

We aimed to choose quotes that best exemplified the key themes or patterns identified in each latent class. We selected quotes that were clear, concise, and representative of the broader sentiment expressed by multiple participants within that class. We prioritised quotes that provided specific examples or detailed explanations of students' experiences, as these offered richer insights into the phenomena we were studying.

Lastly, codes are emphasised in bold to enhance readability in the results of the qualitative analysis.

# Results

# RQ1: latent classes based on feedback experiences

As shown in Fig. 1, the BIC reached its minimum value when the model included four latent classes, indicating that this model provides the best balance between fit and complexity. The fit metrics for each latent class are summarised in Table 2. The Average Posterior Probabilities (AvePP) for the four classes were 0.966, 0.955, 0.949, and 0.956, respectively, demonstrating a high degree of confidence in- class assignments. The estimated class proportions  $\left(\hat{\pi}_{k}\right)$  were 0.143, 0.331, 0.297, and 0.228, respectively, indicating the distribution of respondents across the four latent classes. The mean classification accuracy probabilities (mcaP) were 0.144, 0.332, 0.300, and 0.225, respectively, which were closely aligned with the estimated class proportions. The discrepancies between observed and expected frequencies were minimal, with values of 0.000256, 0.00138, 0.00205, and 0.00368 for the four classes, respectively.

The profile plots (Fig. 2) show distinctive patterns for four latent classes in terms of their feedback experiences (i.e., feedback practices, action- taking behaviours, and challenges). Table 3 shows the corresponding characteristics and descriptions of each class, along with their respective numbers. All Likert scale items used for the latent class analysis are summarised in Appendix Table 4.

![](images/7a0a47b32e0e1ba8d1a809e86c2f9157dd80274cdcc8470d3648524fd4766fc6.jpg)  
Fig. 1 Model fit indices for Log-likelihood and Bayesian Information Criterion (BIC)

Table 2 Model fit metrics for each latent class  

<table><tr><td>Class</td><td>AvePP</td><td>pi hat_k</td><td>mcaP</td><td>Discrepancies</td></tr><tr><td>1</td><td>0.966</td><td>0.143</td><td>0.144</td><td>0.00026</td></tr><tr><td>2</td><td>0.955</td><td>0.331</td><td>0.332</td><td>0.00138</td></tr><tr><td>3</td><td>0.949</td><td>0.297</td><td>0.300</td><td>0.00205</td></tr><tr><td>4</td><td>0.956</td><td>0.228</td><td>0.225</td><td>0.00368</td></tr></table>

![](images/46bf104379703c3099af28d0ad8edfe02fe4b388663f5e8c9885c6883cf7766c.jpg)  
Fig. 2 Estimated class means for feedback experience items for the four latent classes

Class 1 (Information Seekers with Low Emotional Strain;  $n = 92$ ) comprised students who strongly valued feedback and actively engaged with it when it provided actionable insights. They demonstrated high motivation (e.g., Exp_01=5, Exp_07=5) and consistently took action, such as reflecting on feedback and using it to improve future performance. Their challenge profile suggests they were particularly frustrated when feedback lacked sufficient detail, clarity, or timeliness (e.g., high on Chall_03, Chall_09, Chall_11 – Chall_15), but they were relatively unaffected by tone or emotional aspects (low on Chall_06 – Chall_08). These students were emotionally resilient (Exp_04=2) and focused primarily on the utility of feedback.

Class 1 (Information Seekers with Low Emotional Strain;  $n = 92$ ) comprised students who strongly valued feedback and actively engaged with it when it provided actionable insights. They demonstrated high motivation (e.g., Exp_01=5, Exp_07=5) and consistently took action, such as reflecting on feedback and using it to improve future performance. Their challenge profile suggested they were particularly frustrated when feedback lacked sufficient detail, clarity, or timeliness (e.g., high on Chall_03, Chall_09, Chall_11 – Chall_15), but they were relatively unaffected by tone or emotional aspects (low on Chall_06 – Chall_08). These students were emotionally resilient (Exp_04=2) and focused primarily on the utility of feedback.

Class 2 (Feedback Contemplators with High Emotional Strain;  $n = 213$ ) showed similar behavioural traits with Class 1—including high appreciation, motivation, and engagement with feedback—they diverge in their affective experience. Their emotional sensitivity was evident in elevated ratings for feedback tone and delivery challenges (Chall_06 - Chal_08=3, Exp_04=3), suggesting that how feedback is presented can impact their willingness or capacity to act. While they recognised the importance of feedback, emotional and structural barriers may undermine their follow- through. They would benefit from feedback that is both supportive in tone and explicit in its guidance.

Class 3 (Inconsistent Action Takers with Low Challenge Awareness;  $n = 192$ ) exhibited inconsistent and sometimes contradictory feedback behaviours. On one hand, they showed passive tendencies—rating Act_02=4 (“I read feedback and that’s all it is”)—yet also reported relatively high engagement in clarification and planning (Act_03/04/05=4). Notably, they also struggled to take action (Exp_08=4), indicating that self- reported proactive behaviour may not align with actual ability to implement feedback. Despite these struggles, they reported very few challenges (i.e., reported all challenges with a rating of 2), including Chall_13 (“I understood the feedback but didn’t know what to do next”), suggesting low awareness of the barriers they face. This mismatch implied that students in this group may believe they were engaging well, but lack critical reflection on why they struggled.

Class 4 (Feedback Appreciators with Action Struggles;  $n = 144$ ) comprised students who were highly motivated and demonstrated a clear appreciation for feedback’s role in learning (Exp_01 and Exp_07=5). They took steps to reflect (Act_04=5) and plan (Act_05=5) based on feedback, showing strong engagement. However, they reported significant difficulties in taking action based on feedback (Exp_08=4). The main challenges they faced were not emotional but instructional—specifically, feedback that lacked clear expectations or feed- up information (Chall_03=4), and feeling unsure how to proceed despite understanding the feedback (Chall_13=4). These students were willing to act on feedback but struggled due to inadequate information on expected standards.

# RQ2—inclination to act on feedback

# Qualitative analysis of students' responses to negative emotions

Qualitative data obtained through the open- ended question Q1 revealed students' various actions and responses to manage negative emotions when receiving feedback (see Fig. 3). The question also uncovered that these negative feelings often stem from issues with feedback design, such as insufficient information in the feedback content and inappropriate feedback tone, which can leave students feeling unsatisfied and frustrated. More than half of the students  $(n = 393, 61.31\%)$  shared their experiences of coping with negative feelings triggered by educators' feedback. Among this group, there were 42 Information Seekers with Low Emotional Strain, 182 Feedback Contemplators with High Emotional Strain, 118 Inconsistent Action Takers with Low Challenge Awareness, and 51 Feedback Appreciators with Action Struggles. Among those students who shared their responses to Q1, the class of Feedback Contemplators with High Emotional Strain stood out, with the largest number of students reporting that they either "ignore the feedback" (P60) or "take no action" (P224) when feeling negative about the feedback provided (i.e., code—no action). They expressed that the cognitive aspect  $(n = 24, 11.27\%)$  of feedback often contributed to their negative feelings, particularly when the feedback content lacked depth and failed to clearly explain the reasons for deductions in their marks. For example, student P48 shared their experience of feeling negative about the feedback they received: "I was given vague and unclear feedback that did not identify why or how I lost marks, what I needed to improve on, or where my issues were" (P48). Additionally, social- affective aspect  $(n = 13, 6.1\%)$  of feedback was identified as another significant source of negative feelings. This negativity was often attributed

![](images/5f4232cddb5c173dd2a8006e89dab48effa36d54940528ed53c831f375f40767.jpg)  
Fig. 3 The bar chart for the proportion of different responses to Q1: Negative feelings when receiving feedback

to unapproachable educators (T- S relationship) and the use of an inappropriate feedback tone, which left students feeling attacked or ashamed. For instance, student P181 expressed frustration, stating, "They will not discuss things with you and are hostile to those asking for additional feedback, claiming they don't have time to help individuals at all". Similarly, P371 described experiencing negative emotions when "a feedback that attacks you personally and makes you feel shameful". On the other hand, students from this class demonstrated various capabilities in managing negative emotions, as illustrated by their proactive strategies for coping with such feelings. Notably, twenty- two students  $(n = 22, 10.33\%)$  exhibited a strong intention to elicit information. They actively "engaged in dialogue with educators or peers" (P513), with the goals of "clarifying any confusion" (P370) and gaining an understanding of the "different perspectives and expectations of different markers" (P215).

Moving to the next class, we observed different dynamics within the Information Seekers with Low Emotional Strain class. While only a limited number of students  $(n = 4, 4.35\%)$  explicitly shared the underlying reasons for their negative responses to feedback, they were forthcoming about their emotional reactions and the strategies they employ to manage such feelings. This class, Information Seekers with Low Emotional Strain, had the highest proportion of students  $(n = 21, 22, 83\%)$  capable of managing affect. Their proficiency was marked by an openness to the comments of educators, a lack of defensiveness, and a readiness to engage further with suitable individuals. Their approach to feedback involved actively seeking suggestions and continuing dialogues, which empowered them to act constructively on feedback. One student exemplified this attitude: "I consider it the area for improvement, so I reflect on them and ask for help if needed." (P378). It was also found that the highest proportion of students in this class not only tended to take action  $(n = 15, 16.3\%)$  on the feedback provided but also demonstrated a greater capability in processing feedback information  $(n = 11, 11.96\%)$ . This latter capability involves understanding, interpreting, and making sense of feedback to make evaluative judgements about their own work and decide whether to accept or reject the feedback.

For instance, P609 showcased their ability to interpret and critically evaluate feedback: "When feedback [challenges my] strengths, I try to figure out why and how I can fix it". Additionally, the ability to take action, which involves applying the outcomes of processed feedback, is exemplified by P395: "I view [negative feedback] as a learning experience and setting learning goals to improve and avoid making the same mistakes again". This demonstrated a goal- oriented, self- directed approach to using feedback effectively.

Overall, students across all classes identified issues with feedback design as a significant source of negative emotions, particularly noting a lack of depth and actionable advice. Notably, Feedback Contemplators with High Emotional Strain reported the highest dissatisfaction with feedback design, a stark contrast to Feedback Appreciators with Action Struggles, who reported the least engagement and issues with feedback design. In terms of coping strategies, Information Seekers with Low Emotional Strain demonstrated the most effective strategies for managing affect and processing feedback information. On the other hand, Feedback Appreciators with Action Struggles showed minimal action- taking. Action on feedback also varied between groups. Feedback Contemplators with High Emotional Strain and Inconsistent Action Takers with Low Challenge Awareness were more proactive in their feedback responses compared to Feedback Appreciators with Action Struggles, who displayed considerably less initiative.

# Qualitative analysis of motivations for acting on feedback

The open- ended question Q2 sought to explore students' motivations to take action on feedback (see Fig. 4). Of the 471 students  $(n = 471, 73.48\%)$  who answered to this question, 95 were Proactive Feedback Advocates with Minimal.

Barriers, 170 were Feedback Contemplators with High Emotional Strain, 119 were Inconsistent Action Takers with Low Challenge Awareness, and 103 were Feedback Appre. ciators with Action Struggles. In the Information Seekers with Low Emotional Strain class, a significant proportion of students demonstrated a strong commitment to feedback as improvement  $(n = 50,54.35\%)$  . These students were motivated by an understanding of the feedback's purpose and a determination to use it for improvement. This commitment was exemplified by student P10 who expressed, "I trust that the feedback I receive is from a professional standpoint, designed to improve my skill and progress, therefore thereis no reason to not act on them - even if I believe these feedback may not work, I would still rather give them a try".

Additionally,  $16.30\%$ $(n = 15)$  of the class displayed a proactive, goal- oriented approach to taking action on feedback, indicative of their self- direct nature and belief in feedback as critical to their learning and future development: "I wanted to get the most out of the learning experience, so when I received feedback, I was self- motivated to take action on the feedback to help reach my personal expectations and academic goals for myself" (P389). Additionally, in this class, social- affective aspects  $(n = 11, 11.96\%)$  emerged as prominent motivators for taking action on feedback compared to other classes. Particularly, a trusting and supportive teacher- student relationship was highlighted as a crucial factor that encouraged students to engage more deeply with feedback. For example, student P275 mentioned, "I have found feedback

![](images/d95161d44a2936bcdd857a6c2888d9f5a16a607f52354eddc9e5ed1181cdf912.jpg)  
Fig. 4 The bar chart for the proportion of different responses to Q2: The motivations for acting on teachers' feedback

to be of immense value. In year one, a tutor provided detailed video feedback for an assessment. I was extremely motivated to act on the feedback of this tutor as they clearly expressed the expectations and ways to improve". This sentiment was echoed by another student who felt motivated "when I felt or knew the teacher was looking forward to my improvement" (P299).

In the class of Feedback Contemplators with High Emotional Strain, students showed a strong inclination to act on feedback that not only provided actionable information  $(n = 40, 18.78\%)$  but was also communicated in a clear  $(n = 17, 7.98\%)$  and concise manner, making it easy for students to understand. Additionally, feedback tone  $(n = 18, 8.45\%)$  was seen as a crucial motivator. This was evidenced by student P266, who highlighted the influence of respectful and thoughtful feedback tone, when combined with clear, practical steps, significantly enhanced their motivation to engage with and apply feedback in their learning process: "Typically I'm more inclined to act on feedback if there are opportunities to use it. If I feel the point has been effectively and concisely expressed with an example, phrased politely and in a way that doesn't trigger anxieties, then I am more like to act on it." For the classes of Inconsistent Action Takers with Low Challenge Awareness and Feedback Appreciators with Action Struggles motivations to take action based on feedback presented nuanced dynamics that differ from the more actively engaged groups. Although both classes exhibited considerable commitments to feedback as a tool for improvement - with Inconsistent Action Takers with Low Challenge Awareness at  $33.33\%$  and Feedback Appreciators with Action Struggles at  $43.75\%$ , there was a notable discrepancy in their actual behaviours concerning taking action, at only  $6.25\%$  and  $9.03\%$  respectively.

Overall, the analysis across different latent classes concerning how students' inclination to act on feedback varied revealed insightful patterns. The qualitative data highlighted that while feedback design and its execution significantly impacted student reactions and motivations, the degrees of engagement, commitment to improvement, and actual feedback utilisation varied across classes.

# RQ3—Challenge experienced

# Qualitative analysis of students' perceived challenges in making sense of feedback

Through a qualitative analysis of the open- ended question Q3, we explored students' perceived challenges in the feedback process, in particular their sense- making process (see Fig. 5). Approximately a half of the respondents  $(n = 348, 54.29\%)$  stated they had experienced difficulty making sense of educators' feedback. Among them, there were 29 Information Seekers with Low Emotional Strain, 176 Feedback Contemplators with High Emotional Strain, 108 Inconsistent Action Takers with Low Challenge Awareness, and 37 Feedback Appreciators with Action Struggles.

In the Feedback Contemplators with High Emotional Strain class, students perceived poorly structured feedback content as the biggest challenge in making sense of feedback. These included feedback content lacked depth  $(n = 70, 32.86\%)$ , clarity  $(n = 35, 16.43\%)$ , actionable information  $(n = 30, 14.08\%)$ , and personalisation  $(n = 22, 10.33\%)$ , causing considerable difficulty for students in understanding the nature of their errors and in developing strategies to improve their learning. For example, student P491 expressed that 'There are times w[h]ere feedback has felt 'copy- paste'. For example, when [the] teacher's write 'more analysis required' I am never sure what they mean. It is just too general and I never

![](images/8c9a2044471da3c45225f406488722b770e72b06a1aaf275c7d5b7fe35bf77aa.jpg)  
Fig. 5 The bar chart for the proportion of different responses to Q3: The reasons for struggling to understand teachers' feedback

![](images/3231c0f4405c0c1c96b3e84baaa02da4ec97a91d62a690efca7c6766619c9399.jpg)  
Fig. 6 The bar chart for the proportion of different responses to Q4: The reasons for struggling to act on teachers' feedback

feel I understand why I went wrong'. Additionally, students in this class placed a high value on learning design  $(n = 22, 10.33\%)$ , rendering them unable to make sense of feedback when there was a misalignment between feedback design and assessment design. This issue was particularly pronounced when the assessment instruction was ambiguous or unclear. For example, student P145 noted, 'I found the assessment instructions were not sufficiently outlined or explained, [leaving me] wondering what the examiners were really looking for

from students, which made the feedback difficult to comprehend and interpret'. Apart from the external challenges observed above, students in this class also reflected on their own factors, particularly expressing concerns about their incompetence in processing feedback  $(n = 20, 9.39\%)$ , which they identified as one of the main reasons for struggling to understand feedback. These students reported difficulties in comprehending the requirements or making judgements about their own work, which consequently hindered their ability to utilise feedback effectively. For instance, respondent P80 shared that: 'I'm not [always] sure. Sometimes I just don't  $100\%$  understand what they are expecting from me, and I feel bad [about] asking again, so [I] just say I understand'.

Students in the class of Inconsistent Action Takers with Low Challenge Awareness also indicated significant difficulties in understanding their educators' feedback due to poorly crafted feedback content, though to a lesser extent compared to the Feedback Contemplators with High Emotional Strain class. Challenges such as depth  $(n = 32, 16.67\%)$ , language clarity  $(n = 24, 12.50\%)$ , and the need for actionable information  $(n = 14, 7.29\%)$  were prominent. On the other hand, both Information Seekers with Low Emotional Strain and Feedback Appreciators with Action Struggles classes reported fewer challenges in understanding their educators' feedback and showed the least concern with feedback design as well as their own capabilities in making sense of feedback.

# Qualitative analysis of students' perceived challenges in taking action

The open- ended question Q4 provided us with qualitative data to explore the reasons students struggle to act on educators' feedback (see Fig. 6). Out of the total participants  $(n = 641)$ , 304 students  $(n = 304, 47.43\%)$  shared their challenges in implementing feedback into their learning. Among them, there were 33 Information Seekers with Low Emotional Strain, 176 Feedback Contemplators with High Emotional Strain, 87 Inconsistent Action Takers with Low Challenge Awareness, and 43 Feedback Appreciators with Action Struggles.

Students in the class of Feedback Contemplators with High Emotional Strain, faced the most substantial challenges, with  $45.07\%$  of students indicating issues with feedback design, particularly the depth  $(n = 33, 15.49\%)$  and clarity of language  $(n = 31, 14.55\%)$ . These students expressed difficulty acting on feedback that lacked specific, actionable information  $(n = 33, 15.49\%)$ , emphasising the need for feedback that is not only identifies areas for improvement but also provides clear, constructive guidance on how to address these issues. Their frustrations were encapsulated by P210: "Sometimes when given feedback saying that something you've done is wrong or not meeting the expectations, it's hard to change or improve that when [you're] not told why or directed to resources that could help".

Students in the Inconsistent Action Takers with Low Challenge Awareness class reported concerns not only with feedback content but also highlighted issues with learning design  $(n = 14, 7.29\%)$  and their own engagement with feedback (i.e., taking actions  $(n = 20, 10.42\%)$ ). A relatively higher proportion of students in this class mentioned challenges related to the alignment of learning design  $(n = 14, 7.29\%)$ , which affected their uptake of feedback, especially when subsequent assessments were not relevant or connected. As a result, some students failed to recognise the value of acting on feedback if there was no opportunity to apply feedback in their future assessments. Therefore, student P248 commented that "It can be difficult to act on feedback if upcoming/future assessment tasks are not relevant or similar to the previous assignment for which feedback was given". A higher

proportion of students in this class reflected on their own competencies to take action  $(n = 20, 10.42\%)$  rather than the issues with the feedback itself. Their challenges were attributed to a lack of motivation towards learning, insufficient knowledge or skills to act on feedback, and an absence of effective learning tactics or strategies for improvement. For example, one student expressed, "I am already aware and agree with the feedback provided, but I do not know what to actually do to get better" (P334). This sentiment was echoed by another who stated, "I do not struggle to act and am perfectly capable of acting upon feedback, however, the likelihood of me doing so is not very high" (P329).

Both the Information Seekers with Low Emotional Strain and Feedback Appreciators with Action Struggles classes exhibited relatively fewer challenges in taking action on feedback compared to other groups. However,  $17.3\%$  of the Information Seekers with Low Emotional Strain still encountered issues with feedback design, particularly concerning the lack of actionable information  $(n = 9, 9.78\%)$ . On the other hand, a higher proportion of Feedback Appreciators with Action Struggles demonstrated low commitment to using feedback  $(n = 9, 6.25\%)$  for improvement. Their challenges in understanding the purpose of feedback, combined with a lack of motivation and limited academic goals, significantly impacted their engagement with feedback. This disengagement was expressed by P124: "When you only need to pass a subject, it can make you feel unmotivated to put in an exceeding amount of effort to [act on feedback]".

Overall, the findings revealed various challenges in the feedback process, which varied across classes. The Feedback Contemplators with High Emotional Strain experienced the most pronounced difficulties in both understanding and applying feedback. Although fewer challenges reported by the Information Seekers with Low Emotional Strain and Feedback Appreciators with Action Struggles, all classes demonstrated a need for feedback that better facilitates understanding and action.

# Discussion

The study explored students' feedback experiences, challenges, and motivations across different student groups to deepen the understanding of feedback processes in higher education. Through latent class analysis, four student groups were identified, each exhibiting unique feedback experiences. These interactions highlighted varied levels of engagement and challenges, as illustrated by their qualitative data. Our findings revealed variations in feedback experiences across the four identified groups, particularly in terms of their emotional responses, motivations and challenges in the feedback processes.

# Discussions on research questions

The discussion below addresses all research questions (Q1, Q2, and Q3) together and is presented based on the different groups.

# Feedback contemplators with high emotional strain

In the class of Feedback Contemplators with High Emotional Strain, our results showed that students' emotional reactions and motivations to take action were significantly influenced by the feedback design. Despite their self reported proactive attitude and appreciation for feedback, these students often reported emotional challenges when they perceived feedback as lacking depth and actionable advice. This difficulty aligned with their reported perception of how feedback design impacted their ability to understand and act upon feedback, preventing them from fully benefiting from it.

Based on these findings, we interpret that while students recognise the value of feedback and express readiness to engage with it, the perceived quality and specificity of the feedback critically influence their actual responses. Our data suggest that when students perceive feedback as shallow or lacking practical applicability, it often leads to frustration and inaction, even among those who are generally motivated and appreciative of feedback.

This observation aligns with the finding of Karunarathne and colleagues (2023), who noted that students with high positive attitudes towards feedback did not always comprehend their educators' feedback and know how to apply it for improvement. It suggests that enhancing educators' feedback literacy and fostering students' emotional resilience may be crucial for effective feedback processes (Carless & Boud, 2018; Carless & Winstone, 2023). Educators need to be equipped with the skills necessary to understand feedback principles and practices, enabling them to craft effective feedback that allows students to clearly understand and apply the guidance provided (Carless & Winstone, 2023). On the other hand, enhancing students' emotional resilience is critical in ensuring their openness to feedback, regardless of its perceived feedback quality. Carless and Boud (2018) posit that students with high emotional resilience are less likely to experience adverse reactions to feedback. Instead, these students are more inclined to maintain engagement with the feedback process. By fostering emotional resilience, students are more likely to approach their educators to seek further clarification or additional feedback when initial feedback is unclear or insufficient, rather than dismissing it or failing to act upon it (Karunarathne et al., 2023).

# Information seekers with low emotional strain

Our results showed that this group showcased a distinct resilience in managing emotions compared to other groups. Unlike other groups that struggled with negative emotional responses to feedback, this group tended to approach feedback with a more constructive mindset, actively seeking help and engaging in actions that enhance their learning.

Based on these findings, we interpret that their emotional capacity may result in greater motivation to respond to feedback. This interpretation aligns with a prior study by Olafson and Ferraro (2001), which suggested that positive emotional states can enhance motivation to approach learning tasks. Additionally, Pekrun et al. (2009) found that affective states (e.g., anxiety, anger, enjoyment, pride) can serve as primary predictors of performance attainment.

These observations highlight the significance of fostering emotional resilience (Managing affect) as the emotional dimension of feedback can directly impact the acceptance of feedback, learning motivation, self- regulatory behaviours, and feedback effectiveness (Price et al., 2010; Robinson et al., 2013; Yang & Carless, 2013). Therefore, it is crucial to cultivate students' dispositions to manage feedback affect, enabling them to actively engage in the feedback process and uptake feedback effectively (Carless & Boud, 2018; Molloy et al., 2020).

Another key finding was this group's strong valuation of positive teacher- student relationship. They perceived supportive and trusting relationships with educators as crucial enablers for deeper engagement with feedback. Such relationships likely provide a safe and encouraging environment where students feel more comfortable seeking clarifications and discussing feedback in greater depth (Carless & Winstone, 2023; Yang & Carless, 2013). This social- affective aspect of the educational dynamic can significantly enhance the effectiveness of feedback, as it encourages open dialogue and continuous interaction, which are essential for translating feedback into actionable insights (Yang & Carless, 2013). Making feedback as a dialogic process can facilitate a shared understanding of evaluation criteria through effective communication, with the social- affective component of dialogic feedback playing a crucial role. The social- affective component aids in promoting emotional management, enabling educators to support students in processing feedback. By engaging students in dialogue, educators can help clarify meanings, resolve misunderstandings, and create more valuable uses of feedback. This fosters a trusting relationship and balanced power dynamics between educators and students, leading to more fruitful feedback exchanges (Yang & Carless, 2013).

This is particularly beneficial for those who may be vulnerable to critical and negative feedback (i.e., Exp_04=4), such as Inconsistent Action Takers with Low Challenge Awareness and Feedback Appreciators with Action Struggles, as research has shown that unbalanced power relationships can negatively impact how students engage with the feedback process and may affect their motivations to seek clarification or ask questions (Carless, 2006; Yang & Carless, 2013). Focusing on affective factors, such as emotions, within a positive educator- student relationship, can encourage students to think more about their learning potential and take action to improve their learning instead of focusing overly on emotional responses to grades that may lead to apathy towards feedback (Carless, 2006).

# Inconsistent action takers with low challenge awareness and feedback appreciators with action struggles

Both classes of Inconsistent Action Takers with Low Challenge Awareness and Feedback Appreciators with Action Struggles showed how metacognitive barriers can undermine the translation of feedback appreciation into effective action, albeit in different ways. Despite self- reporting high motivation, appreciation for feedback, and commitment to improvement, a significant proportion of students in both classes failed to act on feedback, revealing critical gaps in their ability to bridge intention and action.

For the class of Inconsistent Action Takers with Low Challenge Awareness, they presented a contradictory behaviour: they reported high appreciation for feedback and sometimes sought clarification or planned actions, but their behaviours often remain passive or superficial. Despite these efforts, they struggled to implement feedback meaningfully and, crucially, reported very few perceived challenges. We interpret this pattern as indicative of a critical barrier: a lack of metacognitive awareness and reflective practices needed to translate feedback into actionable steps (Winne & Hadwin, 1998). This deficit may result in an intention- action gap, where students' positive attitudes toward feedback do not translate into meaningful changes in their learning behaviours (Heckhausen & Gollwitzer, 1987).

Feedback Appreciators with Action Struggles, in contrast, were highly motivated and actively engaged in reflection and planning based on feedback. However, they also experienced significant difficulties in taking action. Unlike Inconsistent Action Takers with Low Challenge Awareness, these difficulties were not rooted in emotional or motivational deficits but rather in instructional and metacognitive challenges. These students understood what needed improvement but lacked the metacognitive strategies to determine how to proceed – a gap exacerbated by insufficient "feed- up" information about expected standards (Hattie & Timperley, 2007).

One framework that helps explain this discrepancy (i.e., intention- action gap) is the concept of feedback literacy, which encompasses the skills and dispositions needed to process and act on feedback (Carless & Boud, 2018; Molloy et al., 2020). Closely related to feedback literacy are self- regulated learning skills (SRL), which play a crucial role in students' ability to engage with feedback effectively (Perera Muthupoltotage & Gardner, 2024; Yan & Carless, 2022). Recent research by Pereira et al. (2016) found that feedback literacy was significantly associated with students' control over their learning processes, thereby promoting better self- regulation and action- taking behaviours. This finding suggests that the disparities in students' feedback literacy skills and SRL may cause variance in engagement with feedback.

SRL and feedback literacy are closely related, as self- regulated learners engage with academic tasks, set goals, and attempt to achieve them by applying tactics and strategies under the self- monitoring process (Zimmerman, 2002). Students who are feedback literate possess the ability to engage actively in the feedback process, make sound judgements about their work, and self- regulate their learning (Carless & Boud, 2018).

Taken together, these findings suggest that both classes would benefit from targeted support to develop metacognitive strategies and feedback literacy. For Inconsistent Action Takers with Low Challenge Awareness, interventions should focus on fostering self- awareness and critical reflection – helping students identify and articulate the specific barriers they face (Boud & Molloy, 2013; Zimmerman, 2002). For Feedback Appreciators with Action Struggles, support should emphasise the development of action- planning skills and provide clearer, more actionable feedback that includes explicit standards and examples of quality work (Carless & Boud, 2018). Structured opportunities for dialogue, self- assessment, and

iterative practice can help both groups move beyond intention to effective feedback use (Carless & Boud, 2018; Nicol, 2009; Yang & Carless, 2013).

# Implications

The findings highlight significant challenges in the feedback process across different student groups. Making feedback processes more dialogic could address many of these challenges for students, as discussed earlier. However, facilitating dialogic feedback requires more than just giving feedback; it also necessitates ongoing discussions between educators and students. This approach, while beneficial, may place additional burdens on educators in terms of their responsibilities to support students in the feedback process, particularly when managing large cohorts (Jin et al., 2022).

In light of this, technology- enabled feedback, such as learning analytics (LA) enhanced feedback, could be utilised to facilitate the feedback process (Lim et al., 2021; Pardo et al., 2019). This approach has the potential to ease educators' burdens of providing timely and personalised feedback to large cohorts, while also creating opportunities for educators and students to build a dialogic environment (Yang & Carless, 2013). By leveraging advanced computational methods and technological infrastructure, LA solutions have the ability to collect, analyse, and report on students' learning and their interactions with feedback (Lang et al., 2022). This includes tracking students' engagement with and emotional responses to feedback (Winstone, 2019).

Such data- driven insights can enable educators to identify students' genuine needs and offer personalised support, thereby enhancing students' overall feedback experiences and strengthening the relationship between educators and students (Dourado et al., 2021; Pozdniakov et al., 2023). These improved feedback experiences and strengthened relationships act as enablers of dialogues between educators and students (Boud & Molloy, 2013), encouraging students' engagement and uptake of feedback, resulting in a more effective feedback process (Winstone, 2019; Yang & Carless, 2013).

The findings of this study also highlighted the importance of the social- affective component of dialogic feedback process and the role of SRL skills in making feedback processes effective. These insights have important implications for curriculum design and the development of technology- enhanced feedback tools. Educators can consider embedding opportunities for developing feedback literacy into the curriculum. This can be achieved through a thoughtful alignment of learning design, assessment mechanisms, and technology. For example, incorporating peer review activities can provide students with opportunities to engage in meaningful dialogues with educators and peers regarding their work and feedback (Carless & Boud, 2018).

Engaging in such dialogic feedback process can facilitate students' sense- making process and enhance their ability to critically evaluate feedback and apply it to their learning (Yang & Carless, 2013). Technology- enhanced feedback tools, particularly those based on Learning Analytics (LA), can play a crucial role in supporting this process. LA tools can be purposefully designed (e.g., feedback advising system) to facilitate dialogue between educators and students while considering students' varying feedback experiences. These LA tools can guide educators in crafting feedback tailored to students' needs, taking into account effective elements such as (e.g., feedback tone, feed forward, feedback on self- regulation). This approach encourages students to reflect on their learning, set goals, make action plans, and monitor their progress (Jin et al., 2024, 2025).

# Limitations

Generalisations should be made with caution due to the inherent limitations of this survey- based study. These limitations include potential sampling bias, the subjective nature of the responses, reliance on self- reported data, and potential self- selection bias where students with strong opinions about feedback might be overrepresented. Additionally, the majority of the samples were drawn from Australian universities, which may limit the generalisability of the findings to other contexts. Furthermore, while the study identifies correlations, it cannot definitively establish causality. A deeper understanding of feedback literacy and students' experiences may benefit from incorporating longitudinal and qualitative approaches in future research.

# Concluding remarks

The survey study provided valuable insights into the students' feedback experiences, including their inclination to act upon feedback and perceived challenges during the feedback process. The insights are crucial for designing targeted interventions to enhance students' engagement with feedback more effectively. The findings highlighted the importance of building self- regulation skills and incorporating the social- affective component of dialogic feedback process in enhancing students feedback uptake. Additionally, technology- enhanced feedback tools, such as LA tools, have the potential to facilitate this process by providing personalised, timely support and creating opportunities for meaningful dialogue between educators and students. The observed differences among groups should be considered when developing curriculum design or implementing LA tools. By tailoring approaches to the specific needs and experiences of different student groups, institutions can create effective feedback processes that support diverse learners in engaging with and benefiting from feedback.

# Appendix A

See Fig. 7, Tables 3, 4, 5, 6, 7 and 8.

![](images/d301e6bd407d97bfc61e07663227cd64824de3de2233132afd145284cd9cd73f.jpg)  
Fig. 7 Heatmap of item correlation

Table 3 Latent classes based on students' feedback experiences  

<table><tr><td>Latent class</td><td>n</td><td>Characteristics</td><td>Description</td></tr><tr><td>Class 1 (Information Seekers with Low Emotional Strain)</td><td>92</td><td>·Act_01 to Act_05: Actively engaged with feedback, with strong follow-through on planning and improvement.
·Chall_01 to Chall_16: High challenges when feedback lacked actionable content or timeliness; low sensitivity to tone and delivery.
·Exp_01 to Exp_08: Highly motivated and emotionally resilient; feedback utility is prioritised.</td><td>These students valued feedback for its instructional value. They were proactive in using it and resilient to tone or delivery issues, but became frustrated when it lacked depth, clarity, or is not timely.</td></tr><tr><td>Class 2 (Feedback-Sensitive Responders)</td><td>213</td><td>·Act_01 to Act_05: Often reflected on feedback but struggled with implementation and follow-through.
·Chall_01 to Chall_16: High emotional sensitivity to tone, delivery, and inconsistency in feedback.
·Exp_01 to Exp_08: Appreciated feedback but showed difficulty coping emotionally (e.g., criticism or vague feedback).</td><td>Similar to Class 1, but more emotionally affected. These students valued feedback and engaged with it reflectively, but their emotional responses to negative or poorly delivered feedback can hinder action-taking.</td></tr><tr><td>Class 3 (Inconsistent Action Takers with Low Challenge Awareness)</td><td>192</td><td>·Act_01 to Act_05: Mixed and contradictory behaviour: passive when receiving feedback, but claim proactive action-taking.
·Chall_01 to Chall_16: Reported few challenges, possibly due to low reflection or low challenge awareness.
·Exp_01 to Exp_08: Experienced high emotional strain but lacked active coping or deep engagement.</td><td>These students had low self-reported challenges despite clear behavioural contradictions and emotional difficulty. For example, they struggled to act (Exp_08=4), but did not recognise this as a challenge (Chall_13=2).</td></tr><tr><td>Class 4 (Feedback Appreciators with Action Struggles)</td><td>144</td><td>·Act_01 to Act_05: Highly proactive in planning strategies based on feedback, despite emotional strain. Chall_01 to Chall_16: Low overall challenges, except where feedback was unclear about the expected standards (i.e., feed up) and not knowing next steps.
·Exp_01 to Exp_08: Highly motivated but struggled to take action.</td><td>These students were motivated and willing to take action, but unsure how to proceed.</td></tr></table>

Table 4 Survey items and descriptive analysis  

<table><tr><td>Label</td><td>Survey item</td><td>M</td><td>SD</td></tr><tr><td>Exp_01</td><td>I think feedback is important for my learning.</td><td>4.59</td><td>0.66</td></tr><tr><td>Exp_02</td><td>I believe that feedback should be a reciprocal (two-way) process between students and teachers.</td><td>4.3</td><td>0.74</td></tr><tr><td>Exp_03</td><td>I try to ask for feedback.</td><td>3.67</td><td>0.97</td></tr><tr><td>Exp_04</td><td>I have experienced negative feelings when receiving feedback.</td><td>3.09</td><td>1.08</td></tr><tr><td>Exp_05</td><td>Do you tend to find that the grades you have received in your current degree programme meet your expectations?</td><td>2.81</td><td>0.75</td></tr><tr><td>Exp_06</td><td>I can understand my teachers&#x27; feedback.</td><td>3.79</td><td>0.79</td></tr><tr><td>Exp_07</td><td>I am motivated to take action on feedback.</td><td>4</td><td>0.85</td></tr><tr><td>Exp_08</td><td>I struggle to act on my teachers&#x27; feedback.</td><td>2.6</td><td>0.98</td></tr><tr><td>Act_01</td><td>I only look at grades.</td><td>2.53</td><td>1.15</td></tr><tr><td>Act_02</td><td>I read through the feedback and that&#x27;s all it is.</td><td>3.17</td><td>1.2</td></tr><tr><td>Act_03</td><td>I read through the feedback and ask for clarification.</td><td>3.14</td><td>1.06</td></tr><tr><td>Act_04</td><td>I read through the feedback and think how I can improve next time.</td><td>4.24</td><td>0.81</td></tr><tr><td>Act_05</td><td>I read through the feedback and make an action plan (e.g., study plan, learning strategies, etc.)</td><td>3.1</td><td>1.19</td></tr><tr><td>Chall_01</td><td>The feedback was incomprehensible (difficult to understand).</td><td>3.19</td><td>1.2</td></tr><tr><td>Chall_02</td><td>The feedback was not relevant to my learning.</td><td>2.74</td><td>1.11</td></tr><tr><td>Chall_03</td><td>The feedback did not provide me with enough information about expected standards.</td><td>3.58</td><td>1.17</td></tr><tr><td>Chall_04</td><td>The feedback did not provide me with enough information about my learning progress.</td><td>3.4</td><td>1.14</td></tr><tr><td>Chall_05</td><td>The feedback did not provide me with a clear direction on how to improve learning.</td><td>3.66</td><td>1.2</td></tr><tr><td>Chall_06</td><td>The feedback was too positive.</td><td>2.59</td><td>1.01</td></tr><tr><td>Chall_07</td><td>The feedback was too negative.</td><td>2.5</td><td>0.99</td></tr><tr><td>Chall_08</td><td>The feedback was too critical.</td><td>2.58</td><td>1.06</td></tr><tr><td>Chall_09</td><td>The feedback was not timely.</td><td>3.22</td><td>1.22</td></tr><tr><td>Chall_10</td><td>The feedback was too lengthy.</td><td>2.05</td><td>0.91</td></tr><tr><td>Chall_11</td><td>The feedback was too short/not descriptive (not detailed).</td><td>3.58</td><td>1.18</td></tr><tr><td>Chall_12</td><td>Feedback quality was not consistent across all teachers.</td><td>3.63</td><td>1.17</td></tr><tr><td>Chall_13</td><td>I understood the feedback, but I was not sure what to do next.</td><td>3.35</td><td>1.11</td></tr><tr><td>Chall_14</td><td>There were no opportunities to use previous feedback (e.g., learning tasks were disconnected).</td><td>3.29</td><td>1.17</td></tr><tr><td>Chall_15</td><td>The teacher did not know me well enough to provide effective feedback.</td><td>3.17</td><td>1.18</td></tr><tr><td>Chall_16</td><td>I did not trust my teacher&#x27;s feedback.</td><td>2.23</td><td>1.08</td></tr></table>

Table 5 Frequencies of different responses to negative feelings when receiving feedback (Q1)  

<table><tr><td>Code</td><td>Information Seek-ers with Low Emotional Strain (n=92)</td><td>Feedback Con-templators with High Emotional Strain (n=213)</td><td>Inconsistent Action Takers with Low Challenge Aware-ness (n=192)</td><td>Feedback Ap-peciators with Action Struggles (n=144)</td></tr><tr><td>1. Feedback design</td><td>4 (4.35%)</td><td>36 (16.90%)</td><td>25 (13.02%)</td><td>5 (3.47%)</td></tr><tr><td>1.1 Cognitive</td><td>3 (3.26%)</td><td>24 (11.27%)</td><td>20 (10.42%)</td><td>3 (2.08%)</td></tr><tr><td>1.1.1 Depth</td><td>3 (3.26%)</td><td>12 (5.63%)</td><td>10 (5.21%)</td><td>3 (2.08%)</td></tr><tr><td>1.1.2 Encourage learner agency</td><td>0 (0.00%)</td><td>4 (1.88%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.3 Highlight strengths</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.4 Language and clarity</td><td>0 (0.00%)</td><td>5 (2.35%)</td><td>4 (2.08%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.5 Other information</td><td>0 (0.00%)</td><td>6 (2.82%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.6 Personalised</td><td>0 (0.00%)</td><td>4 (1.88%)</td><td>3 (1.56%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.7 Provide actionable information</td><td>2 (2.17%)</td><td>4 (1.88%)</td><td>4 (2.08%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.8 Provide critiques</td><td>0 (0.00%)</td><td>2 (0.94%)</td><td>3 (1.56%)</td><td>0 (0.00%)</td></tr><tr><td>1.2 Social-affective</td><td>3 (3.26%)</td><td>13 (6.10%)</td><td>7 (3.65%)</td><td>3 (2.08%)</td></tr><tr><td>1.2.1 Feedback tone</td><td>2 (2.17%)</td><td>7 (3.29%)</td><td>5 (2.60%)</td><td>3 (2.08%)</td></tr><tr><td>1.2.2 T-S relationship</td><td>2 (2.17%)</td><td>8 (3.76%)</td><td>3 (1.56%)</td><td>0 (0.00%)</td></tr><tr><td>1.3 Structural</td><td>0 (0.00%)</td><td>9 (4.23%)</td><td>3 (1.56%)</td><td>0 (0.00%)</td></tr><tr><td>1.3.1 Feedback timing</td><td>0 (0.00%)</td><td>4 (1.88%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>1.3.2 Learning design</td><td>0 (0.00%)</td><td>6 (2.82%)</td><td>3 (1.56%)</td><td>0 (0.00%)</td></tr><tr><td>1.3.3 Technology</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>2. Student factors</td><td>38 (41.30%)</td><td>146 (68.54%)</td><td>93 (48.44%)</td><td>46 (31.94%)</td></tr><tr><td>2.1 Cognitive ability or knowledge</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>2.2 Cultural background</td><td>0 (0.00%)</td><td>2 (0.94%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>2.3 Feedback literacy</td><td>31 (33.70%)</td><td>79 (37.09%)</td><td>54 (28.13%)</td><td>32 (22.22%)</td></tr><tr><td>2.3.1 Appreciation</td><td>2 (2.17%)</td><td>2 (0.94%)</td><td>0 (0.00%)</td><td>3 (2.08%)</td></tr><tr><td>2.3.2 Commits to feed-back as improvement</td><td>7 (7.61%)</td><td>8 (3.76%)</td><td>4 (2.08%)</td><td>5 (3.47%)</td></tr><tr><td>2.3.3 Elicits informa-tion to improve learning</td><td>3 (3.26%)</td><td>22 (10.33%)</td><td>18 (9.38%)</td><td>5 (3.47%)</td></tr><tr><td>2.3.4 Managing affect</td><td>21 (22.83%)</td><td>46 (21.60%)</td><td>28 (14.58%)</td><td>19 (13.19%)</td></tr><tr><td>2.3.5 Processes feed-back information</td><td>11 (11.96%)</td><td>15 (7.04%)</td><td>18 (9.38%)</td><td>7 (4.86%)</td></tr><tr><td>2.3.6 Taking actions</td><td>15 (16.30%)</td><td>29 (13.62%)</td><td>22 (11.46%)</td><td>11 (7.64%)</td></tr><tr><td>2.4 No action</td><td>8 (8.70%)</td><td>67 (31.46%)</td><td>42 (21.88%)</td><td>16 (11.11%)</td></tr></table>

Note 7 Percentages do not sum to  $100\%$  because (1) individual responses could be assigned with multiple codes, (2) percentages are calculated based on the total number of participants in each class rather than only those who responded to the specific question, and (3) not all participants answered every open-ended question

Note 2 The frequency for each code represents the number of unique participants who raised that idea at least once in their response. Because a single participant can be assigned to multiple subcategories within the same higher- level code, the sum of subcategory frequencies may exceed the frequency reported for the higher- level code

Table 6 Frequencies of different responses to motivations for acting on feedback (Q2)  

<table><tr><td>Code</td><td>Information Seek-ers with Low Emotional Strain (n=92)</td><td>Feedback Con-templators with High Emotional Strain (n=213)</td><td>Inconsistent Action Takers with Low Challenge Aware-ness (n=192)</td><td>Feedback Ap-peciators with Action Struggles (n=144)</td></tr><tr><td>1. Feedback design</td><td>25 (27.17%)</td><td>85 (39.91%)</td><td>42 (21.88%)</td><td>34 (23.61%)</td></tr><tr><td>1.1 Cognitive</td><td>15 (16.30%)</td><td>65 (30.52%)</td><td>25 (13.02%)</td><td>20 (13.89%)</td></tr><tr><td>1.1.1 Depth</td><td>3 (3.26%)</td><td>10 (4.69%)</td><td>6 (3.13%)</td><td>2 (1.39%)</td></tr><tr><td>1.1.2 Encourage learner agency</td><td>2 (2.17%)</td><td>7 (3.29%)</td><td>2 (1.04%)</td><td>2 (1.39%)</td></tr><tr><td>1.1.3 Highlight strengths</td><td>4 (4.35%)</td><td>9 (4.23%)</td><td>3 (1.56%)</td><td>3 (2.08%)</td></tr><tr><td>1.1.4 Language and clarity</td><td>6 (6.52%)</td><td>17 (7.98%)</td><td>6 (3.13%)</td><td>7 (4.86%)</td></tr><tr><td>1.1.5 Other information</td><td>0 (0.00%)</td><td>2 (0.94%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.6 Personalised</td><td>2 (2.17%)</td><td>16 (7.51%)</td><td>4 (2.08%)</td><td>3 (2.08%)</td></tr><tr><td>1.1.7 Provide actionable information</td><td>9 (9.78%)</td><td>40 (18.78%)</td><td>17 (8.85%)</td><td>12 (8.33%)</td></tr><tr><td>1.1.8 Provide critiques</td><td>5 (5.43%)</td><td>15 (7.04%)</td><td>5 (2.60%)</td><td>6 (4.17%)</td></tr><tr><td>1.2 Social-affective</td><td>12 (13.04%)</td><td>28 (13.15%)</td><td>21 (10.94%)</td><td>16 (11.11%)</td></tr><tr><td>1.2.1 Feedback tone</td><td>3 (3.26%)</td><td>18 (8.45%)</td><td>12 (6.25%)</td><td>6 (4.17%)</td></tr><tr><td>1.2.2 T-S relationship</td><td>11 (11.96%)</td><td>13 (6.10%)</td><td>10 (5.21%)</td><td>12 (8.33%)</td></tr><tr><td>1.3 Structural</td><td>3 (3.26%)</td><td>14 (6.57%)</td><td>3 (1.56%)</td><td>6 (4.17%)</td></tr><tr><td>1.3.1 Feedback timing</td><td>0 (0.00%)</td><td>2 (0.94%)</td><td>0 (0.00%)</td><td>2 (1.39%)</td></tr><tr><td>1.3.2 Learning design</td><td>3 (3.26%)</td><td>13 (6.10%)</td><td>3 (1.56%)</td><td>5 (3.47%)</td></tr><tr><td>1.3.3 Technology</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>2. Student factors</td><td>54 (58.70%)</td><td>85 (39.91%)</td><td>77 (40.10%)</td><td>69 (47.92%)</td></tr><tr><td>2.1 Cognitive ability or knowledge</td><td>2 (2.17%)</td><td>2 (0.94%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>2.2 Cultural background</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>2.3 Feedback literacy</td><td>53 (57.61%)</td><td>84 (39.44%)</td><td>76 (39.58%)</td><td>69 (47.92%)</td></tr><tr><td>2.3.1 Appreciation</td><td>5 (5.43%)</td><td>5 (2.35%)</td><td>6 (3.13%)</td><td>5 (3.47%)</td></tr><tr><td>2.3.2 Commits to feed-back as improvement</td><td>50 (54.35%)</td><td>74 (34.74%)</td><td>64 (33.33%)</td><td>63 (43.75%)</td></tr><tr><td>2.3.3 Elicits informa-tion to improve learning</td><td>0 (0.00%)</td><td>6 (2.82%)</td><td>8 (4.17%)</td><td>2 (1.39%)</td></tr><tr><td>2.3.4 Managing affect</td><td>3 (3.26%)</td><td>4 (1.88%)</td><td>4 (2.08%)</td><td>2 (1.39%)</td></tr><tr><td>2.3.5 Processes feed-back information</td><td>2 (2.17%)</td><td>4 (1.88%)</td><td>3 (1.56%)</td><td>0 (0.00%)</td></tr><tr><td>2.3.6 Taking actions</td><td>15 (16.30%)</td><td>22 (10.33%)</td><td>12 (6.25%)</td><td>13 (9.03%)</td></tr><tr><td>2.4 No action</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr></table>

Note 7 Percentages do not sum to  $100\%$  because (1) individual responses could be assigned with multiple codes, (2) percentages are calculated based on the total number of participants in each class rather than only those who responded to the specific question, and (3) not all participants answered every open-ended question

Note 2 The frequency for each code represents the number of unique participants who raised that idea at least once in their response. Because a single participant can be assigned to multiple subcategories within the same higher- level code, the sum of subcategory frequencies may exceed the frequency reported for the higher- level code

Table 7 Frequencies of different responses to the reasons for struggling to understand teachers feedback (Q3)  

<table><tr><td>Code</td><td>Information Seek-ers with Low Emotional Strain (n=92)</td><td>Feedback Con-templators with High Emotional Strain (n=213)</td><td>Inconsistent Action Takers with Low Challenge Aware-ness (n=192)</td><td>Feedback Ap-peciators with Action Struggles (n=144)</td></tr><tr><td>1. Feedback design</td><td>17 (18.48%)</td><td>128 (60.09%)</td><td>75 (39.06%)</td><td>22 (15.28%)</td></tr><tr><td>1.1 Cognitive</td><td>16 (17.39%)</td><td>115 (53.99%)</td><td>60 (31.25%)</td><td>21 (14.58%)</td></tr><tr><td>1.1.1 Depth</td><td>7 (7.61%)</td><td>70 (32.86%)</td><td>32 (16.67%)</td><td>15 (10.42%)</td></tr><tr><td>1.1.2 Encourage learner agency</td><td>2 (2.17%)</td><td>2 (0.94%)</td><td>5 (2.60%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.3 Highlight strengths</td><td>0 (0.00%)</td><td>2 (0.94%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.4 Language and clarity</td><td>9 (9.78%)</td><td>35 (16.43%)</td><td>24 (12.50%)</td><td>7 (4.86%)</td></tr><tr><td>1.1.5 Other information</td><td>3 (3.26%)</td><td>14 (6.57%)</td><td>5 (2.60%)</td><td>6 (4.17%)</td></tr><tr><td>1.1.6 Personalised</td><td>2 (2.17%)</td><td>22 (10.33%)</td><td>9 (4.69%)</td><td>4 (2.78%)</td></tr><tr><td>1.1.7 Provide actionable information</td><td>7 (7.61%)</td><td>30 (14.08%)</td><td>14 (7.29%)</td><td>6 (4.17%)</td></tr><tr><td>1.1.8 Provide critiques</td><td>4 (4.35%)</td><td>6 (2.82%)</td><td>3 (1.56%)</td><td>3 (2.08%)</td></tr><tr><td>1.2 Social-affective</td><td>4 (4.35%)</td><td>11 (5.16%)</td><td>13 (6.77%)</td><td>2 (1.39%)</td></tr><tr><td>1.2.1 Feedback tone</td><td>2 (2.17%)</td><td>2 (0.94%)</td><td>4 (2.08%)</td><td>0 (0.00%)</td></tr><tr><td>1.2.2 T-S relationship</td><td>3 (3.26%)</td><td>11 (5.16%)</td><td>10 (5.21%)</td><td>2 (1.39%)</td></tr><tr><td>1.3 Structural</td><td>3 (3.26%)</td><td>22 (10.33%)</td><td>11 (5.73%)</td><td>2 (1.39%)</td></tr><tr><td>1.3.1 Feedback timing</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>1.3.2 Learning design</td><td>2 (2.17%)</td><td>22 (10.33%)</td><td>9 (4.69%)</td><td>2 (1.39%)</td></tr><tr><td>1.3.3 Technology</td><td>2 (2.17%)</td><td>0 (0.00%)</td><td>3 (1.56%)</td><td>0 (0.00%)</td></tr><tr><td>2. Student factors</td><td>10 (10.87%)</td><td>48 (22.54%)</td><td>33 (17.19%)</td><td>15 (10.42%)</td></tr><tr><td>2.1 Cognitive ability or knowledge</td><td>0 (0.00%)</td><td>15 (7.04%)</td><td>9 (4.69%)</td><td>8 (5.56%)</td></tr><tr><td>2.2 Cultural background</td><td>3 (3.26%)</td><td>5 (2.35%)</td><td>3 (1.56%)</td><td>2 (1.39%)</td></tr><tr><td>2.3 Feedback literacy</td><td>8 (8.70%)</td><td>33 (15.49%)</td><td>24 (12.50%)</td><td>8 (5.56%)</td></tr><tr><td>2.3.1 Appreciation</td><td>0 (0.00%)</td><td>4 (1.88%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>2.3.2 Commits to feed-back as improvement</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>2.3.3 Elicits informa-tion to improve learning</td><td>5 (5.43%)</td><td>11 (5.16%)</td><td>10 (5.21%)</td><td>3 (2.08%)</td></tr><tr><td>2.3.4 Managing affect</td><td>0 (0.00%)</td><td>3 (1.41%)</td><td>3 (1.56%)</td><td>2 (1.39%)</td></tr><tr><td>2.3.5 Processes feed-back information</td><td>2 (2.17%)</td><td>20 (9.39%)</td><td>16 (8.33%)</td><td>5 (3.47%)</td></tr><tr><td>2.3.6 Taking actions</td><td>3 (3.26%)</td><td>4 (1.88%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>2.4 No action</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>2 (1.39%)</td></tr></table>

Note 1 Percentages do not sum to  $100\%$  because (1) individual responses could be assigned with multiple codes, (2) percentages are calculated based on the total number of participants in each class rather than only those who responded to the specific question, and (3) not all participants answered every open-ended question

Note 2 The frequency for each code represents the number of unique participants who raised that idea at least once in their response. Because a single participant can be assigned to multiple subcategories within the same higher- level code, the sum of subcategory frequencies may exceed the frequency reported for the higher- level code

Table 8 Frequencies of different responses to the reasons for struggling to act on teachers' feedback (Q4)  

<table><tr><td>Code</td><td>Information Seek-ers with Low Emotional Strain (n=92)</td><td>Feedback Con-templators with High Emotional Strain (n=213)</td><td>Inconsistent Action Takers with Low Challenge Aware-ness (n=192)</td><td>Feedback Ap-peciators with Action Struggles (n=144)</td></tr><tr><td>1. Feedback design</td><td>16 (17.39%)</td><td>96 (45.07%)</td><td>45 (23.44%)</td><td>19 (13.19%)</td></tr><tr><td>1.1 Cognitive</td><td>15 (16.30%)</td><td>77 (36.15%)</td><td>27 (14.06%)</td><td>11 (7.64%)</td></tr><tr><td>1.1.1 Depth</td><td>5 (5.43%)</td><td>33 (15.49%)</td><td>10 (5.21%)</td><td>3 (2.08%)</td></tr><tr><td>1.1.2 Encourage learner agency</td><td>0 (0.00%)</td><td>4 (1.88%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.3 Highlight strengths</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.4 Language and clarity</td><td>7 (7.61%)</td><td>31 (14.55%)</td><td>10 (5.21%)</td><td>6 (4.17%)</td></tr><tr><td>1.1.5 Other information</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>1.1.6 Personalised</td><td>4 (4.35%)</td><td>20 (9.39%)</td><td>7 (3.65%)</td><td>2 (1.39%)</td></tr><tr><td>1.1.7 Provide actionable information</td><td>9 (9.78%)</td><td>33 (15.49%)</td><td>12 (6.25%)</td><td>4 (2.78%)</td></tr><tr><td>1.1.8 Provide critiques</td><td>2 (2.17%)</td><td>0 (0.00%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>1.2 Social-affective</td><td>0 (0.00%)</td><td>16 (7.51%)</td><td>7 (3.65%)</td><td>4 (2.78%)</td></tr><tr><td>1.2.1 Feedback tone</td><td>0 (0.00%)</td><td>6 (2.82%)</td><td>0 (0.00%)</td><td>2 (1.39%)</td></tr><tr><td>1.2.2 T-S relationship</td><td>0 (0.00%)</td><td>11 (5.16%)</td><td>7 (3.65%)</td><td>3 (2.08%)</td></tr><tr><td>1.3 Structural</td><td>4 (4.35%)</td><td>20 (9.39%)</td><td>16 (8.33%)</td><td>7 (4.86%)</td></tr><tr><td>1.3.1 Feedback timing</td><td>2 (2.17%)</td><td>6 (2.82%)</td><td>4 (2.08%)</td><td>2 (1.39%)</td></tr><tr><td>1.3.2 Learning design</td><td>4 (4.35%)</td><td>15 (7.04%)</td><td>14 (7.29%)</td><td>5 (3.47%)</td></tr><tr><td>1.3.3 Technology</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>2 (1.39%)</td></tr><tr><td>2. Student factors</td><td>17 (18.48%)</td><td>45 (21.13%)</td><td>42 (21.88%)</td><td>24 (16.67%)</td></tr><tr><td>2.1 Cognitive ability or knowledge</td><td>5 (5.43%)</td><td>4 (1.88%)</td><td>5 (2.60%)</td><td>0 (0.00%)</td></tr><tr><td>2.2 Cultural background</td><td>2 (2.17%)</td><td>0 (0.00%)</td><td>2 (1.04%)</td><td>0 (0.00%)</td></tr><tr><td>2.3 Feedback literacy</td><td>15 (16.30%)</td><td>43 (20.19%)</td><td>41 (21.35%)</td><td>23 (15.97%)</td></tr><tr><td>2.3.1 Appreciation</td><td>0 (0.00%)</td><td>5 (2.35%)</td><td>3 (1.56%)</td><td>6 (4.17%)</td></tr><tr><td>2.3.2 Commits to feed-back as improvement</td><td>2 (2.17%)</td><td>10 (4.69%)</td><td>7 (3.65%)</td><td>9 (6.25%)</td></tr><tr><td>2.3.3 Elicits informa-tion to improve learning</td><td>2 (2.17%)</td><td>9 (4.23%)</td><td>10 (5.21%)</td><td>2 (1.39%)</td></tr><tr><td>2.3.4 Managing affect</td><td>3 (3.26%)</td><td>7 (3.29%)</td><td>5 (2.60%)</td><td>2 (1.39%)</td></tr><tr><td>2.3.5 Processes feed-back information</td><td>6 (6.52%)</td><td>14 (6.57%)</td><td>11 (5.73%)</td><td>2 (1.39%)</td></tr><tr><td>2.3.6 Taking actions</td><td>9 (9.78%)</td><td>13 (6.10%)</td><td>20 (10.42%)</td><td>13 (9.03%)</td></tr><tr><td>2.4 No action</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>0 (0.00%)</td><td>2 (1.39%)</td></tr></table>

Note 7 Percentages do not sum to  $100\%$  because (1) individual responses could be assigned with multiple codes, (2) percentages are calculated based on the total number of participants in each class rather than only those who responded to the specific question, and (3) not all participants answered every open-ended question

Note 2 The frequency for each code represents the number of unique participants who raised that idea at least once in their response. Because a single participant can be assigned to multiple subcategories within the same higher- level code, the sum of subcategory frequencies may exceed the frequency reported for the higher- level code

Funding Open Access funding enabled and organized by CAUL and its Member Institutions. This work was funded by Early Career Researcher (ECR) Seed Grant from the Faculty of Information Technology, Monash University.

# Declarations

Conflict of interest The authors declare that they have no conflict of interest.

Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.

# References

Assessment & Evaluation in Higher Education, 1–14.  Blewett, K. (2020). Fyc students' emotional labor in the feedback cycle. The Journal of the Assembly for Expanded Perspectives on Learning, 25(1), 12.  Boud, D., & Molloy, E. (2013). Reflinking models of feedback for learning: The challenge of design. Assessment & Evaluation in Higher Education, 38(6), 698–712.  Carless, D. (2006). Differing perceptions in the feedback process. Studies in Higher Education, 31(2), 219–233.  Carless, D., & Boud, D. (2018). The development of student feedback literacy: Enabling uptake of feedback. Assessment & Evaluation in Higher Education, 43(8), 1315–1325.  Carless, D., & Winstone, N. (2023). Teacher feedback literacy and its interplay with student feedback literacy. Teaching in Higher Education, 28(1), 150–163. https://doi.org/10.1080/13562517.2020.1782372  Collins, L. M., & Lanza, S. T. (2009). Latent class and latent transition analysis: With applications in the social, behavioral, and health sciences (Vol. 718). Wiley.  Dourado, R. A., Rodrigues, R. L., Ferreira, N., Ferreira Mello, R., Gomes, A. S., & Verbert, K. (2021). A teacher- facing learning analytics dashboard for process- oriented feedback in online learning. Proceedings of the 11th International Learning Analytics and Knowledge Conference, 482–489.  Evans, C. (2013). Making sense of assessment feedback in higher education. Review of Educational Research, 83(1), 70–120.  Gašević, D., Dawson, S., Rogers, T., & Gasevic, D. (2016). Learning analytics should not promote one size fits all: The effects of instructional conditions in predicting academic success. The Internet and Higher Education, 28, 68–84.  Geyskens, J., Donche, V., & Van Potegem, P. (2012). Towards effective feedback in higher education: Bridging theory and practice. Reflecting Education, 8(1), 132–147.  Hattie, J., & Timperley, H. (2007). The power of feedback. Review of Educational Research, 77(1), 81–112.  Heckhausen, H., & Gollwitzel, P. M. (1987). Thought contents and cognitive functioning in motivational versus volitional states of mind. Motivation And Emotion, 11, 101–120.  Henderson, M., Ajjawi, R., Boud, D., & Molloy, E. (2019). The impact of feedback in higher education: Improving assessment outcomes for learners. Springer Nature.  Hinkle, D. E., Wiersma, W., & Jurs, S. G. (2003). Applied statistics for the behavioral sciences (Vol. 663). Houghton Mifflin.  Jin, H., Martinez- Maldonado, R., Li, T., Chan, P. W. K., & Tsai, Y. S. (2022). Towards supporting dialogic feedback processes using learning analytics: The educators' views on effective feedback. Proceedings of the 39th International Conference on Innovation, Practice and.  Jin, F., Maheshi, B., Martinez- Maldonado, R., Gašević, D., & Tsai, Y. S. (2024). Scaffolding feedback literacy: Designing a feedback analytics tool with students. Journal of Learning Analytics, 15. https://doi.org/10.18608/jla.2024.8339

Jin, F. J. - Y., Maheshi, B., Lai, W., Li, Y., Gasevic, D., Chen, G., Charwat, N., Chan, P. W. K., Martinez- Maldonado, R., Gašević, D., Tsai, Y.- S. (2025). Students' perceptions of generative AI- powered learning analytics in the feedback process: A feedback literacy perspective. Journal of Learning Analytics, 12(1), 152- 168. https://doi.org/10.18608/jla.2025.8609Karunarathne, W., Selman, C., & Ryan, T. (2023). Evaluating student feedback literacies: A study using first- year business and economics students. Assessment & Evaluation in Higher Education. https://doi.org/10.1080/02602938.2023.2267803Lang, C., Siemens, G., Wise, A., Gašević, D., & Merceron, A. (Eds.). (2022). Handbook of learning analytics (Second). Society for Learning Analytics; Research.Lanza, S. T., & Rhoades, B. L. (2013). Latent class analysis: An alternative perspective on subgroup analysis in prevention and treatment. Prevention Science, 14(2), 157- 168. Lim, L. A., Dawson, S., Gašević, D., Joksimović, S., Pardo, A., Fudge, A., & Gentili, S. (2021). Students' perceptions of, and emotional responses to, personalised learning analytics- based feedback: An exploratory study of four courses. Assessment & Evaluation in Higher Education, 46(3), 339- 359. Mabmud, S. M. (2010). Cohen's kappa. In N. J. Salkind (Ed.), Encyclopedia of research design (Vol. 1, pp. 188- 189). SAGE Publications Inc.Molloy, E. (2010). The feedforward mechanism: A way forward in clinical learning? Medical Education, 44(12), 1157- 1159. Molloy, E., Boud, D., & Henderson, M. (2020). Developing a learning- centred framework for feedback literacy. Assessment & Evaluation in Higher Education, 45(4), 527- 540. Mulliner, E., & Tucker, M. (2017). Feedback on feedback practice: Perceptions of students and academics. Assessment & Evaluation in Higher Education, 42(2), 266- 288. Nicol, D. (2009). Assessment for learner self- regulation: Enhancing achievement in the first year using learning technologies. Assessment & Evaluation in Higher Education, 34(3), 335- 352. O'Donovan, B. M., den Outer, B., Price, M., & Lloyd, A. (2021). What makes good feedback good? Studies in Higher Education, 46(2), 318- 329. Oberski, D. (2016). Mixture models: Latent profile and latent class analysis. Modern statistical methods for HCI, 275- 287. Olafson, K. M., & Ferraro, F. R. (2001). Effects of emotional state on lexical decision performance. Brain and Cognition, 45(1), 15- 20. Pardo, A., Jovanovic, J., Dawson, S., Gašević, D., & Mirriahi, N. (2019). Using learning analytics to scale the provision of personalised feedback. British Journal of Educational Technology, 50(1), 128- 138. Pekrun, R., Elliot, A. J., & Maier, M. A. (2009). Achievement goals and achievement emotions: Testing a model of their joint relations with academic performance. Journal of Educational Psychology, 101(1), 115- 135. Pereira, D., Flores, M. A., Simão, A. M. V., & Barros, A. (2016). Effectiveness and relevance of feedback in higher education: A study of undergraduate students. Studies in Educational Evaluation, 49, 7- 14. Perera Muthupoltotage, U., & Gardner, L. (2024). The role of feedback literacy in supporting self- regulated learning: Insights from a digital innovation class. Pacific- Asia Conference on Information Systems.Pitt, E., & Norton, L. (2016). Now that's the feedback i want!' students' reactions to feedback on graded work and what they do with it. Assessment & Evaluation in Higher Education, 42(4), 499- 516. https://doi.org/10.1080/02602938.2016.1142500Pozdniakov, S., Martinez- Maldonado, R., Tsai, Y. S., Echeverria, V., Srivastava, N., & Gašević, D. (2023). How do teachers use dashboards enhanced with data storytelling elements according to their data visualisation literacy skills? Proceedings of the 13th International Learning Analytics and Knowledge Conference, 89- 99. Price, M., Handley, K., Millar, J., & O'donovan, B. (2010). Feedback: All that effort, but what is the effect? Assessment & Evaluation in Higher Education, 35(3), 277- 289. Research in the Use of Educational Technologies in Tertiary Education, e22054- e22054. Robinson, S., Pope, D., & Holyoak, L. (2013). Can we meet their expectations? Experiences and perceptions of feedback in first year undergraduate students. Assessment & Evaluation in Higher Education, 38(3), 260- 272. Ryan, T., Henderson, M., Ryan, K., & Kennedy, G. (2022). Feedback in higher education: Aligning academic intent and student sensemaking. Teaching in Higher Education. https://doi.org/10.1080/13562517.2022.2029394Sadler, D. R. (1989). Formative assessment and the design of instructional systems. Instructional Science, 18(2), 119- 144. Sinha, P., Calfee, C. S., & Delucchi, K. L. (2021). Practitioner's guide to latent class analysis: Methodological considerations and common pitfalls. Critical Care Medicine, 49(1), e63- e79. Sutton, P. (2009). Towards dialogic feedback. Critical and Reflective Practice in Education, 1(1).

van Wijk, E. V., van Blankenstein, F. M., Janse, R. J., Dubois, E. A., & Langers, A. M. J. (2024). Understanding students' feedback use in medical progress testing: A qualitative interview study. *Medical Education*, 58(8), 980–988. https://doi.org/10.1111/medu.15378Walker, R., Oliver, R., & Mackenzie, R. (2020). Interviews with secondary school students: Perceptions of feedback. *Issues in Educational Research*, 30(4), 1576–1595. West, C. L., Chen, Q., & Boika, N. (2024). Bringing them back: Using latent class analysis to re- engage college stop- outs. *Frontiers in Psychology*, 15, 1297464. Winne, P., & Hadwin, A. (1998). Studying as self- regulated learning. In, dj hacker, j. dunlosky, & ac Graesser. *Metacognition in Educational Theory and Practice*, 277–304. Winstone, N. (2019). Facilitating students' use of feedback: Capturing and tracking impact using digital tools. In M. Henderson, R. Ajjawi, D. Boud, & E. Molloy (Eds.), *The impact of feedback in higher education* (pp. 225–242). Springer.Winstone, N., Nash, R. A., Rowntree, J., & Parker, M. (2017a). It'd be useful, but I wouldn't use it': Barriers to university students' feedback seeking and recipience. *Studies in Higher Education*, 42(11), 2026–2041. Winstone, N. E., Nash, R. A., Parker, M., & Rowntree, J. (2017b). Supporting learners' agentic engagement with feedback: A systematic review and a taxonomy of recipience processes. *Educational Psychologist*, 52(1), 17–37. Yan, Z., & Carless, D. (2022). Self- assessment is about more than self: The enabling role of feedback literacy. *Assessment & Evaluation in Higher Education*, 47(7), 1116–1128. https://doi.org/10.1080/02602938.2021.2001431Yang, M., & Carless, D. (2013). The feedback triangle and the enhancement of dialogic feedback processes. *Teaching in Higher Education*, 18(3), 285–297. Zimmerman, B. J. (2002). Becoming a self- regulated learner: An overview. *Theory Into Practice*, 41(2), 64–70.

Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

# Authors and Affiliations

Flora Ji- Yoon Jin $^{1}$ $\oplus$  - Lixiang Yan $^{1}$ $\cdot$  Roberto Martinez- Maldonado $^{1}$ $\cdot$  Dragan Gašević $^{1}$ $\cdot$  Philip Wing Keung Chan $^{2}$ $\cdot$  Yi- Shan Tsai $^{1}$

$\boxed{ \begin{array}{r l} \end{array} }$  Flora Ji- Yoon Jin flora.jin@monash.edu Lixiang Yan lixiang.yan@monash.edu Roberto Martinez- Maldonado Roberto.MartinezMaldonado@monash.edu Dragan Gašević Dragan.Gasevic@monash.edu Philip Wing Keung Chan Philip.K.Chan@monash.edu Yi- Shan Tsai Yi- Shan.Tsai@monash.edu

$^{1}$  Faculty of Information Technology, Monash University, Melbourne, VIC 3800, Australia $^{2}$  Faculty of Education, Monash University, Melbourne, VIC 3800, Australia