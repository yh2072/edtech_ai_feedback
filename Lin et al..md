# Advancing self-directed learning in STEM education: integrating GPT-based learning aid with multimodal learning analytics

Chia- Ju Lin, Wei- Sheng Wang, Hsin- Yu Lee, Pin- Hui Li, Yueh- Min Huang & Ting- Ting Wu

To cite this article: Chia- Ju Lin, Wei- Sheng Wang, Hsin- Yu Lee, Pin- Hui Li, Yueh- Min Huang & Ting- Ting Wu (19 May 2025): Advancing self- directed learning in STEM education: integrating GPT- based learning aid with multimodal learning analytics, Journal of Research on Technology in Education, DOI: 10.1080/15391523.2025.2504358

To link to this article: https://doi.org/10.1080/15391523.2025.2504358

# Advancing self-directed learning in STEM education: integrating GPT-based learning aid with multimodal learning analytics

Chia- Ju Lin $^{a}$ , Wei- Sheng Wang $^{a}$ , Hsin- Yu Lee $^{b}$ , Pin- Hui Li $^{a}$ , Yueh- Min Huang $^{a}$  and Ting- Ting Wu $^{b}$

$^{a}$ National Cheng Kung University, Tainan, Taiwan;  $^{b}$ National Yunlin University of Science and Technology, Douliu, Taiwan

# ABSTRACT

Precision education employs technology to diagnose learning processes and provide adaptive feedback tailored to individual needs. This study explores the impact of generative AI as a learning aid to enhance self- directed learning (SDL) in STEM education. In a four- week randomized controlled trial with 72 university students, a GPT- based learning aid was compared to a traditional FAQ tool. The GPT- based aid, powered by large language models (LLMs), offered personalized feedback, while the FAQ tool provided static responses. Results showed the experimental group outperformed the control group in learning performance and SDL abilities. Multimodal learning analytics (MMLA) revealed richer self- assessment, reflective thinking, and interactive behaviors among GPT- aid users, highlighting the transformative potential of generative AI in advancing personalized learning and SDL in STEM.

ARTICLE HISTORY  Received 4 December 2024  Revised 13 February 2025  Accepted 16 April 2025

# KEYWORDS

Precision education; multimodal learning analytics; generative AI learning aid; STEM education; self- directed learning

# Introduction

The advancement of technology and diversification of educational needs have gradually positioned precision education at the forefront. Precision education leverages AI- driven analytics and multimodal learning data to diagnose learners' needs and provide personalized, real- time interventions, thereby optimizing learning experiences (Tsai et al., 2020). Unlike traditional adaptive learning, which primarily adjusts content based on pre- defined learning pathways, precision education integrates multimodal learning analytics (MMLA) to track and interpret students' self- directed learning (SDL) behaviors, engagement patterns, and knowledge construction processes (Lin, Pedaste, et al., 2024). Multimodal Learning Analytics (MMLA) plays a crucial role in this process by integrating data on students' behaviors, interactions, and outcomes, offering insights that enable educators to design more precise instructional strategies (Lin, Wang, et al., 2024). By offering detailed insights into learning processes, MMLA identifies students' strengths and areas for improvement, supporting the development of personalized learning paths and resources (Qushem et al., 2021).

STEM (Science, Technology, Engineering, and Mathematics) education emphasizes an interdisciplinary approach to enhance learners' comprehensive abilities. Adaptive education within this framework allows students to select content and methods based on their pace, interests, and abilities, improving learning motivation and outcomes (Wu et al., 2023). Self- directed learning

(SDL) is pivotal in STEM education, as it cultivates essential skills such as innovative thinking and autonomous problem- solving. Integrating precision education into STEM offers the potential to enhance SDL by leveraging analytical insights to formulate effective teaching strategies, promoting self- regulated learning and preparing students for future challenges (Olivier, 2020).

Traditional digital learning tools often fall short in meeting students' diverse needs. Such tools are frequently characterized by lengthy and complex question- answer collections, limiting their usability and efficiency (Han & Lee, 2022). Al Rawashdeh et al. (2021) highlighted that the lack of personalized guidance in traditional digital tools hinders student engagement and negatively impacts the learning experience. Recent advancements in natural language processing (NLP) and big data analytics have led to the development of intelligent educational tools, such as chatbots and interactive educational robots. These conversational agents (CAs) provide real- time assistance and tailored guidance, addressing the diverse needs of learners and enhancing their engagement (Ait Baha et al., 2024). Chatbots, based on artificial intelligence dialogue systems, can process human language through various technologies, including natural language processing and neural networks (Mahmoud & Kumar, 2020). They can answer students' questions, recommend learning resources, and even provide knowledge assessment feedback. This mode of real- time interaction is particularly suitable for students needing flexible learning schedules or those engaged in distance learning. Such educational interactive robots can simulate human communication methods to help students acquire essential knowledge and skills, thereby more effectively stimulating students' interest and participation. Simultaneously, they can serve as learning aids, assisting students in tackling difficult problems and providing timely feedback and explanations (Shim et al., 2023). The integration of MMLA with intelligent learning aids provides a promising pathway to enhance personalized and adaptive learning in STEM education.

Despite the increasing use of intelligent educational tools, many still rely on rule- based models, which may struggle with complex, non- linear learning scenarios and fail to provide personalized learning experiences (Jeon et al., 2023). Traditional rule- based systems often lack the capacity to adapt to individual student differences, such as prior knowledge levels, and interest profiles. This can lead to learning content and feedback not precisely matching students' actual needs, thereby affecting learning outcomes and students' motivation to engage (Pane et al., 2017). Nee et al. (2023) noted that such educational aids, if not continuously optimized or updated, could fail to meet learners' needs, affecting their willingness to use them. This challenge becomes more pronounced in STEM education, which emphasizes interdisciplinary learning and the application of knowledge in real- world contexts (Su, 2024). The application of intelligent educational tools in STEM learning activities highlights these challenges, as STEM education involves an integrated curriculum of science, technology, engineering, and mathematics. These fields often encompass complex and dynamic problem- solving needs, making the use of teaching tools crucial for students' self- directed learning (SDL) and regulatory capabilities (Li et al., 2020). When employing traditional rule- based or supervised learning intelligent tools, learners may encounter more difficulties and limitations in simulating this complex and variable learning process. Therefore, leveraging technology for teaching and learning to achieve adaptive and autonomous learning is a critical research direction in today's digital learning environment (Mirata et al., 2020).

With the rapid development of generative AI, particularly ILMs like GPT (Generative Pre- trained Transformer) (Feldman- Maggor et al., 2025), the potential for humanized and adaptive educational tools has expanded (Wu, Lee, et al., 2024). LLM- based tools generate diverse content, engage in human- like interactions, and adapt teaching strategies in real time based on student feedback, offering personalized and interactive learning experiences (Meyer et al., 2023). Unlike traditional rule- based systems, GPT- based educational tools adapt dynamically to learners' needs, fostering deeper engagement and better learning outcomes (Wu, Lee, et al., 2024). To explore their educational potential, this study examines how such tools, guided by precision education principles—diagnosis, prediction, intervention, and treatment—enhance self- directed learning (SDL) and interdisciplinary inquiry in STEM education. The GPT- based learning aid aligns with these principles by diagnosing students' learning difficulties through

real- time interactions, predicting potential misunderstandings based on their queries, intervening with adaptive feedback tailored to their needs, and continuously refining responses to guide self- directed learning cycles. Furthermore, this study investigates whether educational robots built on LLMs can support lifelong learning by enabling students to learn at their own pace and according to their interests.

# Related work

# Multimodal learning analytics in precision education

Precision education is an AI- driven educational paradigm that utilizes multimodal learning analytics (MMLA) and adaptive feedback mechanisms to diagnose learners' needs and optimize instruction at an individual level (Hart, 2016). By systematically analyzing learners' behaviors, contexts, and strategies through diagnostic, predictive, intervention, and preventive processes to identify suitable solutions (Lu et al., 2018). The integration of technology in education has greatly enhanced learning interactivity and introduced more personalized elements (Watters, 2021). Researchers use technology to diagnose learners' strengths and weaknesses, providing targeted support (Qushem et al., 2021). MMLA plays a key role in this by collecting and analyzing diverse data to better understand learners' behaviors and cognitive performances (Lin, Wang, et al., 2024). Additionally, Blikstein and Worsley (2016) state that MMLA can provide new insights into students' learning trajectories in more complex and open learning environments. The emergence of AI- powered tools, particularly Large Language Models (LLMs), further enhances precision education by delivering adaptive feedback and personalized guidance, thereby supporting self- directed learning (SDL).

Recent advancements in generative AI, such as GPT- based models, have demonstrated the ability to generate human- like responses, engage in natural interactions, and provide real- time, context- aware recommendations, making them powerful tools for fostering SDL in technology- enhanced learning environments (Xia et al., 2025). Unlike rule- based AI tutors, GPT models dynamically adapt to learners' queries, fostering active learning, self- reflection, and personalized feedback based on students' evolving needs (Wu et al., 2025; Wu, Lin, et al., 2024). Gao (2014) highlights that traditional educational systems struggle to meet modern demands for innovation- driven learning, further emphasizing the need for AI- powered educational tools that support autonomous learning and critical thinking.

The latest advancements in artificial intelligence, generative AI, and educational data mining have intensified interest in precision education and its potential to enhance personalized learning (Hu, 2022). While higher education institutions increasingly adopt data- driven instructional methods, the role of precision education in optimizing learning tools through multimodal analytics remains underexplored (Chen et al., 2023). Qushem et al. (2021) emphasize that integrating multimodal technologies can enhance personalized learning by aligning instructional design with students' cognitive and behavioral patterns. In response to this research gap, this study leverages MMLA to examine how AI- powered learning aids influence students' self- directed learning behaviors and overall learning outcomes, providing deeper insights into the effectiveness of precision education frameworks.

# Generative AI-powered learning aids for STEM education

Technological advancements have increased the emphasis on practical instructional tools in science education. The design of tools like robots has gained attention in educational research, enhancing understanding of learners and enabling timely interventions (Wei et al., 2023). STEM education highlights the importance of active learning and the need for autonomous learning spaces supported by effective strategies and tools. For instance, Wei et al. (2023) developed educational robots using fuzzy theory and hierarchical analysis, serving as assessment tools across

interdisciplinary education. However, the adoption of universal learning designs in STEM within higher education remains limited. Schreffler et al. (2019) observed that project tasks in traditional settings could burden students, necessitating careful design to engage students and foster learning.

With the rise of LLM technologies like ChatGPT, intelligent learning tools such as educational robots can integrate technology into students' learning experiences, enhancing academic performance and supporting instructional practices (Okonkwo & Ade- Ibijola, 2021). Wei et al. (2023) emphasized the importance of utilizing educational robots in STEM education, noting that these tools can not only effectively address students' academic issues but also enhance their learning motivation. However, Jeon et al. (2023) noted that many current educational interactive robots, while offering diverse interactive experiences, still rely on predefined dialogue systems, which may not fully support student- centered learning in STEM. As interdisciplinary education grows, there is a need to integrate AI and LLMs into learning tools to provide up- to- date knowledge and resources (Lin et al., 2025). Thus, tracking and analyzing interactions between learners and educational robots will become increasingly important in enhancing educational outcomes (Wang et al., 2024).

# Self-directed learning progress

Self- directed learning (SDL) is an autonomous approach where individuals control their own learning processes, including diagnosing needs, setting goals, selecting resources, implementing strategies, and evaluating outcomes (Knowles, 1975). Over the years, SDL has evolved to incorporate more structured frameworks. For example, Li et al. (2021) outline the SDL process in three stages: planning, execution, and evaluation. SDL promotes flexibility, personalized learning, and autonomous problem- solving, encouraging active learning (Robinson & Persky, 2020). SDL broadly encompasses four stages: preparing for learning, setting learning goals, engaging in the learning process, and finally evaluating learning outcomes. Brookfield (2013) emphasized that learners should decide what, when, and how much to learn, with teachers acting as facilitators who support knowledge construction. Robinson and Persky (2020) also highlighted SDL as essential for university students, providing autonomy and fostering creativity.

SDL is critical for developing higher- order thinking skills in higher education (Wu, Lee, et al., 2024). Research by Li et al. (2023) found that students with different academic achievements exhibit distinct SDL behaviors, underlining the need for further exploration of these differences. However, Li et al. (2021) noted that most SDL research relies on questionnaires, lacking objective behavior measurements. In digital education, educators increasingly use AI- powered tools to enhance SDL (Kim et al., 2014; Li et al., 2021; Zhu et al., 2020). While Wu and Yu (2024) acknowledged the benefits of AI learning aids, Ali et al. (2023) argued that tools based solely on big data or rule- based systems might limit student engagement and personalization. Therefore, developing more adaptive learning tools to support SDL remains a key area for technological innovation.

# Purposes of this study

Precision education has gained increasing attention in higher education due to its potential to provide personalized and adaptive learning experiences. However, while precision education offers significant benefits, previous studies have also highlighted certain limitations, such as concerns about over- reliance on data- driven learning recommendations and the potential reduction of peer collaboration opportunities. Therefore, it is crucial to examine both the advantages and challenges of precision education, particularly in the context of self- directed learning (SDL).

To address this gap, this study employs MMLA to systematically track and analyze students' SDL behaviors and investigates the effectiveness of a GPT- 4- based intelligent learning aid designed in accordance with precision education principles. Specifically, the study explores how AI- driven

diagnosis, prediction, intervention, and treatment mechanisms contribute to the enhancement of SDL. The GPT- 4- based tool applies these principles by analyzing students' real- time learning interactions, predicting areas where they may struggle, providing targeted interventions through adaptive feedback, and offering continuous support to refine their understanding. By integrating these mechanisms, the tool aims to facilitate more effective self- directed learning, helping students independently monitor their progress, adjust strategies, and engage in reflective learning cycles

This study employs a randomized controlled trial (RCT) to investigate how AI- powered learning aids impact SDL performance, behavioral patterns, and learning outcomes. The control group will use traditional FAQ (frequently asked questions) learning aid, while the experimental group will use an intelligent interactive robot built with GPT- 4 model. This will explore the differences in the effectiveness of SDL capabilities among students using educational robots built with LLMs based on GPT- 4 as smart learning aid. The research questions are as follows:

1. Do students in the experimental group using GPT-based intelligent learning aid perform better compared to the control group? 
2. Do students in the experimental group using GPT-based intelligent learning aid demonstrate higher self-directed learning (SDL) capabilities compared to the control group? 
3. Are there differences in SDL behaviors between the experimental group, using GPT-based intelligent learning aid, and the control group?

# Methodology

# Participants

This course activity adopted a voluntary registration approach, with participants being 72 university students, including 32 females and 40 males. The control group consisted of 18 females and 18 males; the experimental group included 14 females and 22 males. The ages of the students ranged from 19 to 23 years. All students who agreed to participate were clearly informed about the purpose of the research, and the content and use of the data collected were clearly explained. Students had the option to participate in the study and could withdraw at any time. Additionally, this study was reviewed and approved by the ethics committee. This informal embedded development board learning course did not affect the students' academic grades at the university.

# Research context - STEM learning activities

The four- week course, centered on STEM education, aimed to achieve the following core objectives: enabling learners to understand the logic behind program operations and data types, as well as the sequence of program execution (Science); familiarizing with common applications of embedded development boards and contemplating their application in daily life (Technology); understanding the characteristics and functions of each sensor and component, and planning the necessary components based on project objectives (Engineering); and triggering condition logic judgment in embedded development board programming (Mathematics). This STEM learning activity focused on guiding students in the application of Arduino development boards, covering fundamental sensor principles, setting up the Arduino environment, Arduino programming logic, and how to apply this knowledge in project development. The weekly course themes are presented in Table 1.

The course was taught by a professor with over 20 years of teaching experience in relevant subjects. In the first week, the teacher introduced the principles and applications of Arduino development boards through lectures, covering components such as buzzers, LED lights, ultrasonic sensors, and LCD displays. Students were then given time to practice operations

Table 1. STEM learning activities.  

<table><tr><td>Week</td><td>Course topic overview</td><td>Activities</td><td>SDL content</td></tr><tr><td>1</td><td>Application of Arduino Development Boards and Basic Sensor Principles</td><td>·Introduction to the Arduino platform and common sensors
·Features and functions of sensors
·Self-practice and operation</td><td>During self-practice and operation, students use FAQ learning aid/GPT-based learning aid to answer questions about sensor principles and functions encountered during practical exercises.</td></tr><tr><td>2</td><td>Setting Up the Arduino Environment</td><td>·Explanation of how to set up the Arduino development environment
·Introduction to program editing and uploading processes
·Basics of program logic, data types, and execution sequence
·Self-practice and operation</td><td>During self-practice and operation, students use FAQ learning aid/ GPT-based learning aid to answer questions about environment setup and functions encountered during practical exercises.</td></tr><tr><td>3</td><td>Arduino Programming Logic Teaching</td><td>·Practical teaching of writing simple Arduino programs
·Planning of mini-project implementation content
·Self-practice and operation</td><td>During self-practice and operation, students use FAQ learning aid/ GPT-based learning aid to answer questions about programming logic and Arduino program compilation encountered during practical exercises.</td></tr><tr><td>4</td><td>Hands-on Mini-Project</td><td>·Planning required components and development board programming
·Actual project production
·Project presentation</td><td>Students can refer to or brainstorm content and ideas provided by FAQ learning aid/ GPT-based learning aid.</td></tr></table>

independently, with different learning aids provided to different groups for guidance or support. The subsequent weeks followed a similar structure, with the focus shifting to setting up the Arduino programming environment, basic logic applications, and ultimately, a mini- project where students applied what they had learned. A pretest was conducted before the course began to assess students' understanding of Arduino development boards and their level of basic programming logic. A post- test was conducted after all course sessions to evaluate learning outcomes. Additionally, throughout the experimental process, the content of the questions searched by the two groups of students and video recordings of the entire course activities were recorded for back- end MMLA to perform autonomous behavior recognition and classification.

# Experiment procedure

The study aimed to explore differences in self- directed learning (SDL) behaviors and overall learning outcomes between two groups of students using distinct learning aids. The experimental procedure, as shown in Figure 1. Participants were randomly assigned to either the control group, which utilized a static FAQ question- and- answer system, or the experimental group, which engaged with a GPT- based intelligent interactive chatbot fine- tuned with STEM- specific educational content.

The experiment spanned four weeks, with one session per week, adhering to the principle that each session should not exceed  $150\mathrm{min}$ . The experiment spanned four weeks, each week dedicated to a specific aspect of Arduino- based STEM learning activities, including fundamental sensor principles, setting up the Arduino environment, programming logic, and culminating in a hands- on mini- project. Both groups participated in activities on the same day but in different time slots. Each session began with a 60- minute instructor- led lecture, which provided foundational knowledge and an overview of the weekly STEM learning objectives. However, the SDL phase, which lasted between 75 to  $120\mathrm{min}$ , was conducted independently, where students engaged with their assigned learning aids without direct instructor intervention. The instructor's role was limited to delivering the initial knowledge necessary for students to engage in their tasks, and no additional guidance was provided during the SDL phase. This ensured that all observed

![](images/344a7672a1ac6b8e4f7dfd78520d7c779eb12c7f587eea034dc785b81f58f917.jpg)  
Figure 1. Experiment procedure.

learning behaviors and performance differences were solely attributed to students' interactions with their assigned learning tools rather than instructor influence.

During the SDL phase, the control group accessed a database- driven FAQ tool that provided static responses to keyword- based queries, such as "How does an ultrasonic sensor work?" or "How to initialize an Arduino board?" Though extensive in coverage, this tool lacked interactivity

![](images/d7e0044eeabfdcc58409dc9d3400e4c4a8e169e304d7bf1d4531aa3e925b36ba.jpg)  
Figure 2. The workflow of GPT-based intelligent learning aid.

and the ability to adapt responses based on students' evolving understanding. In contrast, the experimental group engaged with a GPT- based chatbot designed to simulate natural dialogue, offering personalized explanations, context- specific guidance, and dynamic feedback to questions such as "What are the best practices for using Arduino libraries?" or "Can you suggest troubleshooting steps for sensor calibration issues?" As illustrated in Figure 2, the GPT- based chatbot facilitated dynamic two- way interactions, enabling students to input detailed queries and receive tailored, actionable feedback. The GPT- based chatbot was designed to support SDL by providing adaptive, context- aware feedback throughout the learning process. During the SDL phase, the system performed three key functions: (1) prompting students to reflect on their learning progress, (2) suggesting alternative strategies when students encountered difficulties, and (3) refining explanations based on students' prior interactions. For instance, when students struggled with sensor calibration, the chatbot did not merely offer a static explanation but instead asked follow- up questions to diagnose the issue and provided step- by- step troubleshooting tailored to the student's specific context. Additionally, the GPT- based chatbot encouraged iterative learning cycles by prompting students to reevaluate their approach after receiving new insights. These mechanisms ensured that AI- assisted interactions were dynamic rather than passive, aligning with the principles of self- directed learning by helping students set learning goals, seek relevant resources, and continuously assess their understanding.

In both groups, all SDL tasks were conducted individually, allowing each student to progress at their own pace and ensuring that the observed outcomes could be attributed solely to their interaction with the assigned learning aid. The final session involved a mini- project that synthesized the concepts learned throughout the course. Students individually planned, implemented, and presented their projects, demonstrating their ability to apply the acquired knowledge and skills. The mini- projects were evaluated using a post- test and an SDL capability questionnaire to assess knowledge acquisition, application skills, and behavioral patterns.

Throughout the experiment, real- time multimodal data—including text interactions with the tools and workspace activity tracking—were monitored and recorded to assess students' engagement with different learning aids. Using Multimodal Learning Analytics (MMLA), student behaviors were categorized into goal setting, access resources, execution tasks, learning interaction, self- assessment, and reflective thinking, providing insights into the immediate and cumulative impact of the two different learning aids.

# Measurements and data collection

The study employed multiple measurement tools, including pre- and post- tests, an SDL capability questionnaire, and multimodal learning analytics (MMLA) for behavior tracking. The pretest and post- test were designed to evaluate students' understanding of Arduino programming, sensor principles, and logic structures. These assessments, developed in collaboration with engineering department instructors, contained 20 multiple- choice questions, each contributing to a total score of 100 points. The pre- and post- tests were similar in content and difficulty, with minor variations in wording and answer choices. Example questions included: Which of the following correctly initializes an ultrasonic sensor in an Arduino program? and What is the primary function of a pull- down resistor in an electrical circuit? The Cronbach's alpha for the pre- and post- tests was 0.702 and 0.7, respectively, indicating moderate reliability.

To evaluate SDL capabilities across different learning aids, we administered an SDL capability questionnaire at the end of the course. The study referenced the SDL Instrument (SDLI) questionnaire proposed by Bhandari et al. (2020) to make it more readable and relevant to this study's context. The questionnaire was measured on a Likert five- point scale (  $1 =$  strongly disagree to  $5 =$  strongly agree), comprising twenty items, with the first six questions about their learning motivation; questions seven to sixteen about the learners' planning and execution capabilities, and the remaining items related to communication and regulation abilities. It is important to note that the SDL capability questionnaire is a self- reported measure, capturing participants' perceptions of their SDL abilities rather than an objective assessment of their actual behaviors. Example items included statements such as I can proactively establish my learning goals and I can monitor my learning progress. The SDLI questionnaire's reliability. Cronbach's alpha, was 0.836, indicating sufficient reliability.

Beyond tests and the SDL questionnaire, this study also collected image and interactive text data from all students during course activities to precisely track and diagnose learners' progress for precision education implementation, thereby supporting the MMLA system's ability to identify and track SDL behaviors. Previous studies have demonstrated the use of MMLA in tracking SDL behaviors by analyzing learning engagement, cognitive strategies, and self- regulation patterns (Lin, Pedaste, et al., 2024). For the multimodal analysis, both image and text data were collected. Figure 3 illustrates the multimodal learning analysis system's process. The MMLA system gathered relevant data in a pilot test, capturing an overhead image of student learning every  $15\mathrm{s}$  along with all text content within that timeframe. Additionally, two expert scholars independently labeled and classified behaviors and imagery. Any discrepancies in their classifications were resolved through discussion to establish a consensus before using the labeled data to train the system's deep learning model. The inter- rater reliability analysis yielded a Cohen's Kappa coefficient of 0.8, indicating strong agreement between the experts. After training, the model was applied to classify student behaviors, and the experts conducted a final validation of the model's output to ensure accuracy and consistency in recognition. Technically, the MMLA system used YOLOv4 as the network architecture model for image recognition (Bochkovskiy et al., 2020), identifying students' body positions and object recognition during Arduino operations, including all learning materials, hand movements, and students' tool screens. Text or keyword data provided by students using the tools were identified using the Latent Dirichlet Allocation (LDA) topic modeling technique to recognize main themes and concepts in the text. Lastly, combining these with the advantages of deep learning for decision classification to identify and categorize students' SDL behaviors. This multimodal tracking and recognition method offers a comprehensive basis for decision- making, allowing observation and understanding of students' learning processes from multiple perspectives (Lin et al., 2024).

The dimensions of SDL behaviors in this study were adapted and modified from the SDL behavior coding researched by Liu et al. (2024), as shown in Table 2. The MMLA system collected both image and text data and categorized learning behaviors into three primary SDL processes: planning, execution and monitoring, and reflection, further subdivided into six key

![](images/0ff8df15e7ffe004d07ea7e61ebca1564ec543cec0c2aaa28715feb68a242747.jpg)  
Figure 3. The process of multimodal learning analysis system.

behavioral dimensions: Goal Setting (GS), Access Resources (AR), Execute Tasks (ET), Learning Interaction (LI), Self- assessment (SA), and Reflective Thinking (RT). To examine the temporal progression of SDL behaviors, the MMLA system captured and timestamped each observed behavior, enabling a sequence analysis of students' learning trajectories. The system tracked transitions between key SDL phases to identify behavioral patterns and assess differences in learning progressions between groups. Specifically, each recorded text query and image capture was labeled with a timestamp, allowing for an event- based sequence analysis that examined how students progressed through different SDL stages over time. For instance, "accessing resources" was identified through image recognition of students browsing Arduino- related websites, while "reflective thinking" involved students revising their learning strategies based on feedback. Through this multimodal and sequential tracking approach, we could assess whether students using the GPT- based learning aid demonstrated different behavioral transition patterns compared to those using the FAQ tool. This method provided a comprehensive basis for analyzing SDL behaviors, enabling a deeper understanding of how different learning aids influenced students' ability to self- regulate and adapt their learning strategies.

# Results

# Analysis of learning performance

This study investigated whether there were differences in learning performance between the experimental and control groups due to the use of different instructional tools. Pretests and post- tests were conducted to assess the students' level of knowledge. To enhance the internal validity of the study, pretest scores were used as a covariate. This approach aimed to minimize differences between groups, thereby more accurately understanding the impact of the instructional tools rather than other external factors. Before conducting ANCOVA to examine if there were differences in post- test scores between groups, it was necessary to confirm the homogeneity of the students' knowledge levels before the course. Levene's test for equality of variances indicated no significant difference in pretest scores between the two groups  $(F(1,70) = 0.246, p = .622)$ . Additionally, the homogeneity of regression slopes was tested, showing no significant interaction between the covariate and the independent variable  $(F(1,70) = 3.20, p = .078)$ , allowing for subsequent ANCOVA analysis.

The analysis results are presented in Table 3. The experimental group's post- test mean score was 81.5, with a standard error of 2.49, while the control group's post- test mean score was 71.1, with a standard error of 3.21. This indicates that the learning outcomes of the experimental

Table 2. SDL behavior coding.  

<table><tr><td>Phases</td><td>Behaviors</td><td>Description</td><td>Examples (multimodal learning analysis recognition)</td></tr><tr><td rowspan="2">Planning</td><td>Goal setting (GS)</td><td>Setting learning goals and strategies, planning the learning process.</td><td rowspan="4">·Image recognition: Students listing learning goals and plans in a notebook.
·Text analysis: Appearance of words or themes related to “planning” and “goals”.
·Image recognition: Students browsing Arduino-related websites or materials.
·Text analysis: Queries for “Recommended Arduino materials for beginners”.
·Image recognition: Students actively engaging in Arduino learning tasks and writing Arduino code.
·Text analysis: Inquiries such as “Give me some practical Arduino exercises”.
·Image recognition: Students interacting in dialogue with intelligent learning aid.
·Text analysis: Students expressing personal feelings or interactions unrelated to classroom topics.</td></tr><tr><td>Access resources (AR)</td><td>Searching for and organizing resources and materials needed for learning.</td></tr><tr><td rowspan="2">Execution and Regulation</td><td>Execute tasks (ET)</td><td>Implementing learning activities according to the plan, completing specific tasks.</td></tr><tr><td>Learning interaction (LI)</td><td>Interacting with learning aid to obtain information or feedback, conducting SDL.</td></tr><tr><td rowspan="2">Evaluation and Reflection</td><td>Self-assessment (SA)</td><td>Assessing one&#x27;s own learning progress and level of understanding.</td><td rowspan="2">·Image recognition: Students repeatedly checking implementation results with the learning aid.
·Text analysis: Students “explaining their learning progress” to the learning aid.
·Image recognition: Students carefully reading and contemplating their learning tasks.
·Text analysis: Reflections and plans for adjustment in learning diaries.</td></tr><tr><td>Reflective thinking (RT)</td><td>Reflecting on the learning process, learning from experiences, planning future learning strategies.</td></tr></table>

Table 3. Results of ANCOVA analysis for learning outcomes.  

<table><tr><td>Group</td><td>N</td><td>M</td><td>SD</td><td>F</td><td>p</td><td>η²</td></tr><tr><td>Experimental group</td><td>36</td><td>81.5</td><td>14.9</td><td>11.77</td><td>.001</td><td>0.069</td></tr><tr><td>Control group</td><td>36</td><td>71.1</td><td>19.3</td><td></td><td></td><td></td></tr></table>

group were significantly higher than those of the control group  $(F(1,70) = 11.77$ $p = .001)$  This suggests that the GPT- based intelligent learning aid are more effective in enhancing students' knowledge and logical concepts regarding Arduino.

# Analysis of self-directed learning ability

To understand the differences in SDL capabilities between groups after using different learning aids for SDL, the  $t$ - test analysis results for SDL capabilities are shown in Table 4. The mean score of the SDL capability scale for the experimental group was 86.6, with a standard error of 0.607, while the control group had a mean score of 65.5, with a standard error of 0.96. The  $t$ - test results  $(t(70) = 15.7, p < .001)$  indicate a significant difference between the two groups, with a large effect size  $(d = 3.71)$ . This demonstrates that learners using GPT- based intelligent learning aid possess higher levels of SDL capabilities compared to those using traditional FAQ learning aid.

# Analysis of self-directed behavioral pattern

Given the goal of precision education to use learning analytics systems for effectively diagnosing and predicting learning behaviors as a reference for subsequent educational methods and strategy improvements, this study employed MMLA to collect students' object image data and text data from tool interactions to identify SDL behaviors. The behaviors were further quantitatively

Table 4. T-test results for SDL capabilities.  

<table><tr><td>Group</td><td>N</td><td>M</td><td>SD</td><td>t</td><td>p</td><td>d</td></tr><tr><td>Experimental group</td><td>36</td><td>86.6</td><td>3.64</td><td>15.7</td><td>&amp;lt;.001</td><td>3.71</td></tr><tr><td>Control group</td><td>36</td><td>65.5</td><td>5.76</td><td></td><td></td><td></td></tr></table>

![](images/ad360ab00dccb29ca0b90526d4b2ad2ff4fb3b06d544b4744d989c7e085e5e89.jpg)  
Figure 4. SDL behavior distribution.

analyzed using the GSEQ software for behavioral sequences (Bakeman & Quera, 1995). To understand the behavioral differences between groups using different learning aids, we first analyzed the distribution of behaviors among the two groups, as shown in Figure 4. The results from Figure 4 indicate that compared to the control group, students in the experimental group showed higher proportions of self- assessment, reflective thinking, and learning interaction; conversely, students in the control group spent more time executing tasks.

The SDL behaviors of the two groups of students were further analyzed through sequential analysis to establish an adjusted residuals table for calculating the behavioral transition matrix (Bakeman & Gottman, 1997), as shown in Table 5. In Table 5, rows represent initial behaviors, and columns represent subsequent behaviors following the row behavior. When the z- score exceeds 1.96  $(p < .05)$ , a specific behavioral sequence is significant. According to Table 5, significant behavioral sequences in the experimental group include:  $\mathrm{AR} \rightarrow \mathrm{ET}$ ,  $\mathrm{AR} \rightarrow \mathrm{RT}$ ,  $\mathrm{LI} \rightarrow \mathrm{LI}$ ,  $\mathrm{SA} \rightarrow \mathrm{RT}$ , and  $\mathrm{RT} \rightarrow \mathrm{SA}$ ; for the control group, significant sequences include:  $\mathrm{GS} \rightarrow \mathrm{GS}$ ,  $\mathrm{GS} \rightarrow \mathrm{AR}$ ,  $\mathrm{AR} \rightarrow \mathrm{AR}$ ,  $\mathrm{ET} \rightarrow \mathrm{ET}$ ,  $\mathrm{SA} \rightarrow \mathrm{SA}$ ,  $\mathrm{SA} \rightarrow \mathrm{RT}$ ,  $\mathrm{RT} \rightarrow \mathrm{SA}$ , and  $\mathrm{RT} \rightarrow \mathrm{RT}$ .

Figure 5(a) depicts the SDL behavior transition diagram for the experimental group. From the diagram, it is evident that students in the experimental group form a cycle from executing tasks (ET) and self- assessment (SA) to reflective thinking (RT), indicating that students in the experimental group continuously engage in SDL through self- assessment and reflection during learning tasks, thereby establishing a self- centered learning and thinking pattern. Furthermore, students in the experimental group tend to interact with learning aid or assess their work during task execution, suggesting that students may use the guidance of learning aid to understand the outcomes of their tasks. Additionally, students in the experimental group exhibit reflective behavior after accessing resources (AR), indicating that students discuss the information found with learning aid and reflect upon it.

Figure 5(b) shows the SDL behavior transition diagram for the control group. The diagram reveals that students in the control group spend a relatively longer time on goal setting (GS), accessing resources (AR), executing tasks (ET), self- assessment (SA), and reflective thinking

Table 5. Adjusted residuals between the two groups.  

<table><tr><td></td><td></td><td>GS</td><td>AR</td><td>ET</td><td>LI</td><td>SA</td><td>RT</td></tr><tr><td rowspan="6">Experimental group</td><td>GS</td><td>0.11</td><td>1.07</td><td>0.63</td><td>-0.93</td><td>-0.02</td><td>-0.46</td></tr><tr><td>AR</td><td>-0.97</td><td>-0.70</td><td>1.15</td><td>-2.43</td><td>-1.55</td><td>3.33*</td></tr><tr><td>ET</td><td>0.28</td><td>-0.38</td><td>-1.67</td><td>2.13*</td><td>2.01*</td><td>-1.79</td></tr><tr><td>LI</td><td>0.27</td><td>-1.02</td><td>-0.39</td><td>1.17</td><td>-1.69</td><td>1.15</td></tr><tr><td>SA</td><td>0.47</td><td>0.17</td><td>-1.29</td><td>0.34</td><td>-2.08</td><td>2.53*</td></tr><tr><td>RT</td><td>-0.46</td><td>1.19</td><td>2.39*</td><td>-2.00</td><td>2.02*</td><td>-2.90</td></tr><tr><td rowspan="6">Control group</td><td>GS</td><td>2.29*</td><td>3.85*</td><td>-0.40</td><td>-0.68</td><td>-1.63</td><td>-1.63</td></tr><tr><td>AR</td><td>-0.59</td><td>2.65*</td><td>-1.98</td><td>0.34</td><td>1.12</td><td>-0.02</td></tr><tr><td>ET</td><td>-1.66</td><td>-2.45</td><td>6.99*</td><td>-0.25</td><td>-3.46</td><td>-3.65</td></tr><tr><td>LI</td><td>0.97</td><td>-0.35</td><td>-1.26</td><td>1.84</td><td>-0.46</td><td>-0.25</td></tr><tr><td>SA</td><td>-0.54</td><td>0.17</td><td>-3.74</td><td>-0.79</td><td>3.27*</td><td>3.48*</td></tr><tr><td>RT</td><td>0.53</td><td>-0.76</td><td>3.48</td><td>-0.78</td><td>2.79*</td><td>3.48*</td></tr></table>

z-score  $>1.96$

![](images/4054cc3e4aede54d9dd9119b4b7ddd6fd99049b7d327c736864c4828e3ccf9bd.jpg)  
Figure 5. Diagram of SDL behavior transfer. (a) Experimental group; (b) control group.

(RT), suggesting that students might face challenges in these stages that hinder their progress to the next learning behavior.

Another significant finding is that students in both the experimental and control groups form a cycle between self- assessment (SA) and reflective thinking (RT). This infers that the course activity design in this study, aiming for SDL through teacher instruction combined with the use of learning aid, provides students with ample space and time for self- study and hands- on practice. This may lead to the emergence of text themes related to thinking, questioning, and evaluating during interactions with learning aid, allowing students to complete learning tasks through continuous reflection and self- assessment.

# Discussion

Given the relative scarcity of empirical research on the impact of generative AI in enhancing students' SDL capabilities and behavioral differences in STEM education activities, this study aimed to investigate the effects of using different instructional tools (GPT- based intelligent learning aid versus traditional FAQ learning aid) on their learning outcomes, SDL capabilities, and SDL behavioral transitions.

Based on previous studies on SDL and AI- assisted learning, we expected that students using GPT- based learning aids would exhibit more frequent self- assessment and reflective thinking behaviors, as these tools provide personalized feedback and interactive guidance. The results aligned with our expectations, as shown in the MMLA behavior transition patterns, which indicated a higher occurrence of SA and RT transitions in the experimental group compared to the control group. By collecting image data of student learning and text data from interactions with the tools for teaching and analysis, more comprehensive data support was provided. These

findings suggest that the dynamic and responsive nature of the GPT- based tool encouraged students to actively monitor their learning progress, adjust their strategies, and refine their understanding through iterative learning cycles.

To provide a comprehensive analysis, we collected both image data of students' learning activities and textual interactions with the learning tools. The results demonstrated that students in the experimental group not only achieved better learning outcomes but also engaged more effectively in SDL processes, particularly in higher- order thinking skills such as reflection and evaluation. This suggests that AI- powered learning aids, when integrated into STEM education, can play a significant role in supporting SDL by fostering deeper engagement, adaptive learning behaviors, and metacognitive development.

Regarding Research Question 1, which aimed to examine whether students using the GPT- based intelligent learning aid achieved better learning outcomes compared to those using the traditional FAQ learning aid as a self- study tool. The analysis of both groups showed that students engaging in SDL with GPT- based intelligent learning aid had significantly higher learning performance than those using traditional FAQ learning aid. This finding aligns with the research by Robinson and Persky (2020), confirming that external resource support has a positive impact on students' learning performance in an SDL environment. On the other hand, Kim et al. (2014) highlighted that opportunities for sharing and social interaction can help students better prepare for course activities and alleviate the feeling of studying alone. As GPT is a type of generative AI model trained using LLMs, which may be one reason for the increased willingness to learn among students. Furthermore, the implementation of precision education seeks personalized learning aid, and the adaptive perception abilities gained by students through intelligent learning aid grant learners more autonomy, achieving the core objective of precision education: to precisely predict and provide timely interventions (Lalitha & Sreeja, 2020).

To address Research Question 2, we used a questionnaire to understand the performance of SDL capabilities among students using different learning aids. The findings indicate that students who utilized the GPT- based learning aid demonstrated significantly higher levels of SDL capabilities compared to those using the traditional FAQ learning aid. This result aligns with the findings of Liu et al. (2024), who suggested that an increased availability of learning resources and well- organized tools can enhance students' SDL capabilities. As the importance of lifelong learning becomes increasingly prominent, fostering SDL capabilities has become a core goal of contemporary education. This is particularly relevant in the context of emerging technologies and the accumulation of interdisciplinary knowledge, which cannot be fully acquired through traditional subject- based learning alone. Lalitha and Sreeja (2020) argue that SDL fosters personalized learning approaches, where learners independently acquire knowledge or resources using tools without relying on instructors or peers, thereby achieving academic success. Generative AI, by offering a broader range of knowledge responses and emotional interactions, enables intelligent learning aids to better understand user needs and provide more personalized learning experiences, thereby enhancing students' extensive search and reinforcement learning within the SDL process.

This study further investigated the differences in SDL behaviors when learning with different tools (Research Question 3). Multiple modal data were collected to identify SDL behaviors and investigate the behavioral sequence differences between the two groups. Overall, we found that students in the experimental group exhibited more reflective thinking and self- assessment behaviors. Although Kim et al. (2014) emphasized the importance of goal setting, actively obtaining resources, and thinking about learning strategies in SDL activities, our results showed a relatively lower occurrence of goal- setting behaviors in the experimental group compared to the control group. We speculate that this is due to the explicit goals and thematic direction of the course design in our experimental activities, and teachers providing relevant thematic knowledge before students' autonomous practice operations, leading to students not needing to spend much time on setting learning goals and planning. In further analysis of behavioral sequences, we found that students in the experimental group often engage in learning interactions or self- assessment after task operations. GPT- based learning aid provides a bi- directional interactive environment for learners, where students

can indirectly strengthen cognition from various perspectives through interactive dialogues for learning or inquiry to receive feedback (Yin et al., 2021). Similar results were confirmed in the study by Wu, Lee, et al. (2024), which demonstrated the powerful potential of incorporating generative AI's LLMs into higher education for reflection and knowledge construction.

Additionally, according to the results of the SDL behavior transition diagrams for both groups, the experimental group achieved a more complete cycle of learning patterns compared to the control group. For example, the cycle from executing tasks, self- assessment, to reflective thinking  $(\mathrm{ET} \rightarrow \mathrm{SA} \rightarrow \mathrm{RT})$ . This can be interpreted as students in the experimental group evaluating through the tools after task operations and then thinking or improving based on the feedback provided by the tools, continuing this cycle.

One potential concern is the influence of the 60- minute instructor- led lecture on students' SDL behaviors. However, the instructor's role in this study was strictly limited to delivering pre- planned instructional content at the beginning of each session, while all SDL activities were conducted independently. Since the experimental and control groups received identical instruction, the differences observed in learning outcomes and SDL behavioral patterns can be primarily attributed to the learning aids rather than instructor intervention. The MMLA analysis further supports this, as the behavioral transition patterns observed during the SDL phase reflect students' self- directed engagement with their assigned learning tools, rather than direct teacher guidance. This suggests that the GPT- based learning aid facilitated more dynamic self- assessment and reflective thinking behaviors, reinforcing its role in supporting SDL.

In other words, students in the experimental group are more inclined to interact with and be assisted by the tools for monitoring and reflection, fulfilling an indispensable element of SDL theory (Knowles, 1975). In contrast, the behavior transition diagram for the control group indicates that although they spent a lot of time on task operations, they also formed a cycle of self- assessment and reflective thinking  $(\mathrm{SA} \rightleftarrows \mathrm{RT})$ , but they did not form a complete learning sequence relationship. This can be inferred as students in the control group being unable to effectively resolve the problems they faced due to the lack of corresponding assistance from FAQ learning aid, leading to repeated trial- and- error behavior. This result is similar to that of Chang and Hwang (2024), which indicated that although the integration of digital learning tools into the classroom can add diversity to education, students' interest and value perception of interaction with learning aids may decrease over time. This study also confirmed that using highly interactive and more personalized feedback as learning aids can more effectively cultivate students' SDL capabilities. At the same time, the rise of generative AI with robust LLMs to assist them in understanding students' Q&A needs, guiding students to learn and dynamically adjusting the content. On the other hand, using MMLA can provide teachers with more reference bases to make more precise educational decisions, such as adjusting teaching content, methods, and learning activities. This will add greater development potential for precision education to diagnose in real- time and provide appropriate interventions, aiming for effective prevention as the ultimate goal.

# Conclusion

With the growing emphasis on precision education and interdisciplinary learning to develop students' higher- order thinking, MMLA has become crucial in tracking and diagnosing learning processes (Lin et al., 2024). In a student- centered learning model, the capability for SDL has become a crucial skill (Liu et al., 2024). This study leveraged MMLA to gather data on students' learning behaviors, providing educators with insights into SDL within the context of generative AI. It also explored whether AI- guided learning aids could enhance SDL capabilities, including exploratory and reflective learning. Specifically, the study focused on the application of these tools in STEM education and their role in helping students apply theoretical knowledge to solve practical problems. The findings confirm that AI- driven personalized educational tools can improve learning performance and SDL processes, while also promoting active learning and thinking, aligning with the goals of precision education.

However, this study has limitations. Ethical concerns regarding generative AI's content, especially in avoiding sensitive topics, need addressing. Future educators should establish clear guidelines to ensure academic integrity (Adeshola & Adepoju, 2024; Lin et al., 2025). Additionally, the study's short duration and small sample size may limit the generalizability of the results. Future research could extend the course duration and include a broader participant base to examine longer- term SDL behaviors. Despite these limitations, integrating MMLA into SDL courses in STEM education has proven beneficial. Future improvements in system design are expected to further enhance educational technology, providing students with tools that meet diverse and personalized learning needs. This study aims to deepen understanding of generative AI in education and enhance students' overall learning experience and outcomes.

# Disclosure statement

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

# Availability of data and materials

The data presented in this study are available upon reasonable request from the corresponding author, except Experimental Research Participation Consent Form.

# Funding

This research is supported by the National Science and Technology Council, Taiwan, R.O.C. under grant Nos. NSTC 112- 2410- H- 006- 053- MY3, NSTC 113- 2410- H- 006- 125- MY3, NSTC 113- 2410- H- 006- 089- MY3, NSTC 113- 2410- H- 224- 036- MY3, and NSTC 111- 2628- H- 224- 001- MY3.

# Notes on contributors

Chia- Ju Lin is currently a postdoctoral researcher at National Cheng Kung University. She received PhD degree in Engineering Science at National Cheng Kung University, Taiwan, in 2024. Her research interests include educational technology, learning analytics, computer networks, and artificial intelligence.

Wei- Sheng Wang is currently a postdoctoral researcher at National Cheng Kung University. He received PhD degree in Engineering Science at National Cheng Kung University, Taiwan, in 2023. His research interests include virtual reality, educational technology, optimization algorithms, and artificial intelligence.

Hsin- Yu Lee is currently a postdoctoral researcher at National Yunlin University of Science and Technology. He received PhD degree in Engineering Science at National Cheng Kung University, Taiwan, in 2024. His research interests include educational technology, learning analytics, computer vision, and artificial intelligence.

Pin- Hui Li is currently pursuing her PhD degree in engineering science at National Cheng Kung University, Taiwan, R.O.C. Her research interests include educational technology, computer vision, and artificial intelligence.

Yuen- Min Huang is a chair professor at the Department of Engineering Science, National Cheng Kung University, Taiwan. His research interests focus on e- learning, multimedia communications, artificial intelligence, and embedded systems.

Ting- Ting Wu is a distinguished professor and director of the Graduate School of Technological and Vocational Education, National Yunlin University of Science and Technology, Taiwan. Her research covers such areas as technology- enhanced language learning and applications of advanced technology to support nursing education.

# ORCID

Chia- Ju Lin  $\oplus$  http://orcid.org/0000- 0002- 2321- 1834 Wei- Sheng Wang  $\oplus$  http://orcid.org/0000- 0003- 1263- 4820 Hsin- Yu Lee  $\oplus$  http://orcid.org/0000- 0003- 3257- 305X

Pin- Hui Li  $\oplus$  http://orcid.org/0009- 0000- 4891- 9372 Yueh- Min Huang  $\oplus$  http://orcid.org/0000- 0001- 7052- 1272 Ting- Ting Wu  $\oplus$  http://orcid.org/0000- 0003- 4970- 7042

# References

Adeshola, I., & Adepoju, A. P. (2024). The opportunities and challenges of ChatGPT in education. *Interactive Learning Environments*, 32(10), 6159- 6172. https://doi.org/10.1080/10494820.2023.2253858Ait Baha, T., El Hajji, M., Es- Saady, Y., & Fadili, H. (2024). The impact of educational chatbot on student learning experience. *Education and Information Technologies*, 29(8), 10153- 10176. https://doi.org/10.1007/s10639- 023- 12166- wAl Rawashdeh, A. Z., Mohammed, E. Y., Al Arab, A. R., Alara, M., Al- Rawashdeh, B., & Al- Rawashdeh, B. (2021). Advantages and disadvantages of using e- learning in university education: Analyzing students' perspectives. *Electronic Journal of e- Learning*, 19(3), 107- 117. https://doi.org/10.34190/ejel.19.3.2168Ali, F., Choy, D., Divaharan, S., Tay, H. Y., & Chen, W. (2023). Supporting self- directed learning and self- assessment using TeacherGAIA, a generative AI chatbot application: Learning approaches and prompt engineering. *Learning: Research and Practice*, 9(2), 135- 147. https://doi.org/10.1080/23735082.2023.2258886Bakeman, R., & Gottman, J. M. (1997). Observing interaction: An introduction to sequential analysis. Cambridge University Press.Bakeman, R., & Quera, V. (1995). Analyzing interaction: Sequential analysis with SDIS and GSEQ. Cambridge University Press.Bhandari, B., Chopra, D., & Singh, K. (2020). Self- directed learning: Assessment of students' abilities and their perspective. *Advances in Physiology Education*, 44(3), 383- 386. https://doi.org/10.1152/advan.00010.2020Blikstein, P., & Worsley, M. (2016). Multimodal learning analytics and education data mining: Using computational technologies to measure complex learning tasks. *Journal of Learning Analytics*, 3(2), 220- 238. https://doi.org/10.18608/jla.2016.32.11Bochkovskiy, A., Wang, C.- Y., & Liao, H.- Y. M. (2020). Yolov4: Optimal speed and accuracy of object detection. arXiv preprint arXiv:2004.10934. https://doi.org/10.48550/arXiv.2004.10934Brookfield, S. D. (2013). Powerful techniques for teaching adults. Wiley. https://books.google.com.tw/books?id=smTDxB7z8XUCChang, C.- C., & Hwang, G.- J. (2024). Elevating EFL learners' professional English achievements and positive learning behaviours: A motivation model- based digital gaming approach. *Journal of Computer Assisted Learning*, 40(1), 176- 191. https://doi.org/10.1111/jcal.12876Chen, X., Cheng, G., Zou, D., Zhong, B., & Xie, H. (2023). Artificial intelligent robots for precision education: A topic modeling- based bibliometric analysis. *Educational Technology & Society*, 26(1), 171- 186. https://www.jstor.org/stable/48707975Feldman- Maggor, Y., Blonder, R., & Alexandron, G. (2025). Perspectives of generative AI in chemistry education within the TPACK framework. *Journal of Science Education and Technology*, 34(1), 1- 12. https://doi.org/10.1007/s10956- 024- 10147- 3Gao, P. (2014). Using personalized education to take the place of standardized education. *Journal of Education and Training Studies*, 2(2), 44- 47. https://doi.org/10.11114/jets.v2i2.269Han, S., & Lee, M. K. (2022). FAQ chatbot and inclusive learning in massive open online courses. *Computers & Education*, 179, 104395. https://doi.org/10.1016/j.compedu.2021.104395Hart, S. A. (2016). Precision education initiative: Moving toward personalized education. *Mind, Brain and Education: The Official Journal of the International Mind, Brain, and Education Society*, 10(4), 209- 211. https://doi.org/10.1111/mbe.12109Hu, Y.- H. (2022). Effects and acceptance of precision education in an AI- supported smart learning environment. *Education and Information Technologies*, 27(2), 2013- 2037. https://doi.org/10.1007/s10639- 021- 10664- 3Jeon, I., Lee, S., & Choe, H. (2023). Beyond ChatGPT: A conceptual framework and systematic review of speech- recognition chatbots for language learning. *Computers & Education*, 206, 104898. https://doi.org/10.1016/j.compedu.2023.104898Kim, R., Olfman, L., Ryan, T., & Fryilmaz, E. (2014). Leveraging a personalized system to improve self- directed learning in online educational environments. *Computers & Education*, 70, 150- 160. https://doi.org/10.1016/j.compedu.2013.08.006Knowles, M. S. (1975). Self- directed learning: A guide for learners and teachers. Association Press.Lalitha, T. B., & Sreeja, P. S. (2020). Personalised self- directed learning recommendation system. *Procedia Computer Science*, 171, 583- 592. https://doi.org/10.1016/j.procs.2020.04.063Li, H., Majumdar, R., Chen, M.- R. A., & Ogata, H. (2021). Goal- oriented active learning (GOAL) system to promote reading engagement, self- directed learning behavior, and motivation in extensive reading. *Computers & Education*, 171, 104239. https://doi.org/10.1016/j.compedu.2021.104239Li, S., Du, H., Xing, W., Zheng, J., Chen, G., & Xie, C. (2020). Examining temporal dynamics of self- regulated learning behaviors in STEM learning: A network approach. *Computers & Education*, 158, 103987. https://doi.org/10.1016/j.compedu.2020.103987

Li, Y., Jiang, Q., Xiong, W., & Zhao, W. (2023). Investigating behavior patterns of students during online self- directed learning through process mining. *Education and Information Technologies*, 28(12), 15765- 15787. https://doi.org/10.1007/s10639- 023- 11830- 5Lin, C.- J., Lee, H.- Y., Wang, W.- S., Huang, Y.- M., & Wu, T.- T. (2025). Enhancing reflective thinking in STEM education through experiential learning: The role of generative AI as a learning aid. *Education and Information Technologies*, 30(5), 6315- 6337. https://doi.org/10.1007/s10639- 024- 13072- 5Lin, C.- J., Pedaste, M., & Huang, Y.- M. (2024). Insights into precision education through multimodal learning analytics in STEM education. Innovative Technologies and Learning.Lin, C.- J., Wang, W.- S., Lee, H.- Y., Huang, Y.- M., & Wu, T.- T. (2024). Recognitions of image and speech to improve learning diagnosis on STEM collaborative activity for precision education. *Education and Information Technologies*, 29(11), 13859- 13884. https://doi.org/10.1007/s10639- 023- 12426- 9Lin, C.- J., Wang, W.- S., Lee, H.- Y., Huang, Y.- M., & Wu, T.- T. (2025). Interventions in STEM education through speech recognition- based learning analysis. *Journal of Educational Computing Research*, 63(2), 311- 335. https://doi.org/10.1177/07356331241307904Liu, B., Wu, Y., Shu, H., Cui, Y., Zuo, C., & Li, W. (2024). Uncovering the predictive effect of behaviours on self- directed learning ability. *British Journal of Educational Technology*, 55(3), 1231- 1232. https://doi.org/10.1111/bjet.13427Lu, O. H. T., Huang, A. Y. Q., Huang, J. C. H., Lin, A. J. Q., Ogata, H., & Yang, S. J. H. (2018). Applying learning analytics for the early prediction of students' academic performance in blended learning. *Journal of Educational Technology & Society*, 21(2), 220- 232. http://www.jstor.org/stable/26388400Mahmoud, M., & Kumar, R. (2020). A review on chatbot design and implementation techniques. *International Journal of Engineering and Technology*, 7, 2791. Meyer, J. G., Urbanowicz, R. J., Martin, P. C. N., O'Connor, K., Li, R., Peng, P.- C., Bright, T. J., Tatonetti, N., Won, K. J., Gonzalez- Hernandez, G., & Moore, J. H. (2023). ChatGPT and large language models in academia: Opportunities and challenges. *BioData Mining*, 16(1), 20. https://doi.org/10.1186/s13040- 023- 00339- 9Mirata, V., Hirt, F., Bergamin, P., & van der Westhuizen, C. (2020). Challenges and contexts in establishing adaptive learning in higher education: Findings from a Delphi study. *International Journal of Educational Technology in Higher Education*, 17(1), 32. https://doi.org/10.1186/s41239- 020- 00209- yNee, C. K., Rahman, M. H. A., Yahaya, N., Ibrahim, N. H., Razak, R. A., & Sugino, C, the Department of Computing, Faculty of Arts, Computing and Creative Industry, Universiti Pendidikan Sultan Idris, Malaysia. (2023). Exploring the trend and potential distribution of chatbot in education: A systematic review. *International Journal of Information and Education Technology*, 13(3), 516- 525. https://doi.org/10.18178/ijiet.2023.13.3.1834Okonkwo, C. W., & Ade- Ibijola, A. (2021). Chatbots applications in education: A systematic review. *Computers and Education: Artificial Intelligence*, 2, 100033. https://doi.org/10.1016/j.caeai.2021.100033Olivier, J. (2020). Self- directed multimodal learning in higher education (Vol. 3). AOSIS. https://doi.org/10.4102/aosis.2020. BK210Pane, J. F., Steiner, E. D., Baird, M. D., Hamilton, L. S., & Pane, J. D. (2017). How does personalized learning affect student achievement? RAND Corporation. https://doi.org/10.7249/RB9994Qushem, U. B., Christopoulos, A., Oyelere, S. S., Ogata, H., & Laakso, M.- J. (2021). Multimodal technologies in precision education: Providing new opportunities or adding more challenges? *Education Sciences*, 11(7), 338. https://www.mdpi.com/2227- 7102/11/7/338 https://doi.org/10.3390/educsci11070338Robinson, J. D., & Persky, A. M. (2020). Developing self- directed learners. *American Journal of Pharmaceutical Education*, 84(3), 847512. https://doi.org/10.5688/ajpe847512Schreffler, J., Vasquez Iii, E., Chini, J., & James, W. (2019). Universal design for learning in postsecondary STEM education for students with disabilities: A systematic literature review. *International Journal of STEM Education*, 6(1), 8. https://doi.org/10.1186/s40294- 019- 0161- 8Shim, K. J., Menkhoff, T., Teo, L. Y. Q., & Ong, C. S. Q. (2023). Assessing the effectiveness of a chatbot workshop as experiential teaching and learning tool to engage undergraduate students. *Education and Information Technologies*, 28(12), 1- 24. https://doi.org/10.1007/s10639- 023- 11795- 5Su, K.- D. (2024). The challenge and opportunities of STEM learning efficacy for living technology through a transdisciplinary problem- based learning activity. *Journal of Science Education and Technology*, 33(4), 429- 443. https://doi.org/10.1007/s10956- 024- 10094- zTsai, S.- C., Chen, C.- H., Shiao, Y.- T., Ciou, J.- S., & Wu, T.- N. (2020). Precision education with statistical learning and deep learning: A case study in Taiwan. *International Journal of Educational Technology in Higher Education*, 17(1), 12. https://doi.org/10.1186/s41239- 020- 00186- 2Wang, W.- S., Lin, C.- J., Lee, H.- Y., Huang, Y.- M., & Wu, T.- T. (2024). Integrating feedback mechanisms and ChatGPT for VR- based experiential learning: Impacts on reflective thinking and AIoT physical hands- on tasks. *Interactive Learning Environments*, 33(2), 1770- 1787. https://doi.org/10.1080/10494820.2024.2375644Watters, A. (2021). Teaching machines: The history of personalized learning. The MIT Press. https://doi.org/10.7551/mitpress/12262.001.0001Wei, J.- J., Lin, H.- H., & Chen, S.- L. (2023). Design of teaching aids in STEAM education and fuzzy hierarchical analysis of their educational effect. *Eurasia Journal of Mathematics, Science and Technology Education*, 19(11), em2354. https://doi.org/10.29333/ejmste/13749

Wu, R., & Yu, Z. (2024). Do AI chatbots improve students learning outcomes? Evidence from a meta- analysis. British Journal of Educational Technology, 55(1), 10–33. https://doi.org/10.1111/bjet.13334Wu, T.- T., Lee, H.- Y., Chen, P.- H., Lin, C.- J., & Huang, Y.- M. (2025). Integrating peer assessment cycle into ChatGPT for STEM education: A randomised controlled trial on knowledge, skills, and attitudes enhancement. Journal of Computer Assisted Learning, 41(1), e13085. https://doi.org/10.1111/jcal.13085Wu, T.- T., Lee, H.- Y., Li, P.- H., Huang, C.- N., & Huang, Y.- M. (2024). Promoting self- regulation progress and knowledge construction in blended learning via ChatGPT- based learning aid. Journal of Educational Computing Research, 61(8), 1539–1567. https://doi.org/10.1177/07356331231191125Wu, T.- T., Lee, H.- Y., Wang, W.- S., Lin, C.- J., & Huang, Y.- M. (2023). Leveraging computer vision for adaptive learning in STEM education: Effect of engagement and self- efficacy. International Journal of Educational Technology in Higher Education, 20(1), 53. https://doi.org/10.1186/s41239- 023- 00422- 5Wu, T.- T., Lin, C.- J., Pedaste, M., & Huang, Y.- M. (2023). The effect of chatbot use on students' expectations and achievement in STEM flipped learning activities: A pilot study. Innovative Technologies and Learning.Xia, L., Shen, K., Sun, H., An, X., & Dong, Y. (2025). Developing and validating the student learning agency scale in generative artificial intelligence (AI)- supported contexts. Education and Information Technologies, 1–23. https://doi.org/10.1007/s10639- 024- 13137- 5Yin, J., Goh, T.- T., Yang, B., & Xiaobin, Y. (2021). Conversation technology with micro- learning: The Impact of chatbot- based learning on students' learning motivation and performance. Journal of Educational Computing Research, 59(1), 154–177. https://doi.org/10.1177/0735633120952067Zhu, M., Bonk, C. J., & Doo, M. Y. (2020). Self- directed learning in MOOCs: Exploring the relationships among motivation, self- monitoring, and self- management. Educational Technology Research and Development, 68(5), 2073–2093. https://doi.org/10.1007/s11423- 020- 09747- 8