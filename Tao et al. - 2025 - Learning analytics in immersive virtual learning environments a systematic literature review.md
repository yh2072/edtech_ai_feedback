# Learning analytics in immersive virtual learning environments: a systematic literature review

Lei Tao<sup>1</sup>, Mutlu Cukurova<sup>2</sup> and Yanjie Song<sup>1*</sup>

*Correspondence: ysong@eduhk.hk

<sup>1</sup> Department of Mathematics and Information Technology, The Education University of Hong Kong, Hong Kong SAR, China  <sup>2</sup> UCL Institute of Education, University College London, London, UK

# Abstract

Research on learning analytics (LA) in various educational contexts is extensive, but research specifically on LA in immersive virtual learning environments (immersive VLEs) remains underexplored in terms of theoretical integration, methodological diversity, and multimodal data utilisation. This study reviews applications of learning analytics in immersive VLEs following the Preferred Reporting Items for Systematic Reviews and Meta- Analyses guidelines. The paper presents the findings from 34 peer- reviewed journal articles and conference proceedings, describing their research purposes, learning environments, subjects, theoretical frameworks, data types, data analysis techniques, and challenges. Findings show that (1) the application of LA in immersive VLEs has expanded, shifting from an initial focus on learning outcomes and behavioural analysis to include performance prediction, self- regulation, social interaction, and affective states. However, these areas remain unevenly explored; (2) research has predominantly examined desktop- based immersive VLEs, while fewer studies have explored immersive virtual reality settings such as head- mounted displays and cave automatic virtual environments; (3) higher education students have been the most frequently studied participants, with fewer studies involving K- 12 students and adult learners; (4) most studies have employed data- driven approaches to identify behavioural patterns, but explicit theoretical frameworks have been used less frequently to guide analysis and interpretation; (5) behaviour data remains the most commonly used data type; (6) statistical methods such as regression and ANOVA dominate the analytical approaches, with machine learning and deep learning techniques remaining underutilised; and (7) challenges including technical complexity, data interpretability, privacy concerns, and adoption barriers impact the effectiveness and scalability of LA applications in immersive VLEs. These findings provide a comprehensive synthesis of current research trends, methodological limitations, and key challenges in LA applications within immersive VLEs, offering insights to guide future research and practice.

Keywords: Learning analytics, Multimodal learning analytics, Virtual learning environment, Systematic review

# Introduction

Learning analytics (LA) has emerged as a powerful tool for enhancing student learning in digital educational settings. LA involves measuring, collecting, analysing, and interpreting data about learners and their contexts to optimise learning processes and environments (Siemens & Long, 2011). By leveraging diverse data sources, LA enables educators to track engagement, predict academic performance, and develop data- driven instructional strategies (Susnjak et al., 2022). The increasing adoption of digital learning environments has further expanded the role of LA, particularly in virtual learning environments (VLEs), where interactions between learners, content, and instructors occur in digital spaces (Dalinger et al., 2020; Hari Rajan et al., 2025).

VLEs encompass a range of learning environments that vary in their levels of interaction, sensory immersion, and spatial engagement. Some non- immersive VLEs, such as learning management systems (LMS) and web- based educational platforms (e.g., Moodle, Blackboard), primarily facilitate content delivery, assessments, and discussion forums (Pinto & Leite, 2020). In these settings, LA techniques typically rely on structured data sources such as clickstream logs, quiz performance, and forum participation to analyse student behaviour and learning patterns (Baker et al., 2020; Dobashi et al., 2022). However, with the growing adoption of technology- enhanced educational experiences, VLEs have expanded beyond traditional online platforms to incorporate more interactive and spatially immersive learning environments. These include 2D and 3D interactive learning spaces, such as desktop virtual reality (desktop VR), mobile VR, immersive VR, and mixed reality (MR) (Al- Mugheed et al., 2022; Dalinger et al., 2020; Shadiev & Li, 2023). These immersive VLEs enable learners to engage in real- time collaboration, embodied interactions, and experiential learning, making them fundamentally different from non- immersive VLEs in terms of user engagement and data complexity (Dalinger et al., 2020).

Despite the increasing integration of LA in immersive VLEs, traditional analytics techniques face significant challenges in these settings. While interaction logs and assessment scores are effective for analysing student behaviour in non- immersive VLEs, they are insufficient for capturing the complex, multimodal interactions present in immersive learning spaces (Charitopoulos et al., 2020). Immersive VLEs generate diverse data streams, including movement tracking, spatial interactions, gaze behaviour, and affective states (Shadiev & Li, 2023). These new data sources require more advanced analytical techniques capable of processing multimodal information in real time. Additionally, the complexity and volume of data generated in immersive environments introduce challenges related to data fusion, noise reduction, and the scalability of machine learning models for educational insights (Dalinger et al., 2020). To address these challenges, multimodal learning analytics (MMLA) has emerged as a promising approach for analysing learning behaviours in immersive environments (Giannakos et al., 2022). Unlike traditional LA methods, which rely primarily on single data sources, MMLA integrates multiple modalities, such as gaze tracking, speech recognition, gesture analysis, and biometric feedback, to provide a more comprehensive understanding of learners' cognitive and affective states (Sharma & Giannakos, 2020).

MMLA is particularly relevant for immersive VLEs because it enables real- time tracking of learner engagement, allowing for adaptive feedback and personalized learning

experiences (Shadiev & Li, 2023). By fusing multimodal data, MMLA enhances the ability to detect cognitive overload (Mangaroska et al., 2020), track engagement (Sharma & Giannakos, 2020), and refine instructional strategies based on learner behaviours (Yan et al., 2024). However, despite its potential, MMLA implementation in immersive VLEs remains fragmented, with limited empirical studies systematically evaluating its effectiveness across different virtual learning settings.

In addition, while numerous studies have explored LA applications in non- immersive VLEs, research focusing on immersive VLEs remains fragmented and lacks a systematic synthesis of methodologies and challenges. For instance, Elmoazen et al. (2023) examined LA applications in virtual laboratories, which represent a narrower subset of immersive environments, while Sakr and Abdullah (2024) investigated LA in VR/AR settings but did not systematically analyse methodological approaches. Much of the existing literature focuses on specific technologies or pedagogical applications rather than providing a comprehensive review of how LA methodologies are applied across different immersive learning contexts.

To bridge this gap, this study systematically synthesises empirical studies on the application of LA in immersive VLEs, specifically focusing on desktop VR, mobile VR, immersive VR, and mixed reality (Al- Mugheed et al., 2022; Dalinger et al., 2020; Shadiev & Li, 2023). By synthesising these studies, this review identifies current applications, theoretical frameworks, data types, analytical methods, and key challenges associated with LA in immersive learning environments. We explicitly define immersive VLEs as digital learning environments that enable spatial interaction and multimodal engagement beyond traditional non- immersive VLEs. In our selection criteria, we included studies that examined the use of LA within immersive VLEs, excluding those focusing solely on traditional non- immersive VLEs (LMS or web- based learning platforms). We adopted the research framework proposed by Vieira et al. (2018) to categorize LA's research purposes within immersive VLEs. Additionally, we drew upon Wang et al. (2022) and Khalil et al. (2023), both of which are systematic reviews that provided foundational insights into the theories, models, and frameworks commonly used in LA research. Furthermore, we utilized the data analysis methods framework proposed by Alonso- Fernandez et al. (2019) to systematically analyse and classify the data types and analysis techniques employed in LA studies within immersive VLEs. The following research questions (RQs) guide this systematic literature review:

1. What are the research purposes, learning environments, and participants and disciplinary areas of the reviewed studies?  
2. What theories, models, or frameworks do the reviewed studies refer to?  
3. What are the data types and data analysis techniques used in the reviewed studies?  
4. What are the challenges in learning analytics within virtual learning environments?

To better illustrate the structure and interconnections of our research questions. Specifically, RQ1 provides the foundational scope of the review, while RQ2 and RQ3 operate as parallel analytical dimensions, reflecting theory- driven and data- driven perspectives in existing research. RQ4 synthesises the challenges reported across the reviewed studies, identifying key obstacles to the effective application of LA in immersive VLEs.

By answering these research questions, this systematic literature review aims to deepen the current understanding of learning analytics in immersive VLEs and provide a comprehensive overview of its applications. The findings from this review will not only inform researchers and practitioners about the effective integration of learning analytics in virtual settings but also examine the challenges and opportunities encountered in empirical studies to acknowledge research boundaries and guide future directions.

# Methods

We adhered to the procedures outlined in the Preferred Reporting Items for Systematic Reviews and Meta- Analyses (PRISMA) guidelines (Page et al., 2021). PRISMA provides detailed reporting standards for systematic reviews and meta- analyses, which have been widely applied to educational research (e.g., Ba & Hu, 2023; Crompton & Burke, 2018; Crompton et al., 2021). The systematic literature review procedure (see Fig. 1) consists of five main steps. First, the purposes and research questions (RQs) identified in this research. Second, we searched multiple digital databases with predefined search terms for relevant studies. Third, a selection of papers was performed to build the paper dataset according to the inclusion and exclusion criteria. Fourth, we coded the paper dataset and extracted information relevant to the RQs. In the final step, the extracted information was compared, synthesised, and discussed in response to the RQs. Step 1 was identified in the previous section. The following sections will elaborate on the processes of Steps 2, 3, and 4. The final step will be presented in the Results section.

# Searching papers

The literature (from journal and conference articles) was gathered by searching several well- known online databases and publishers for academic research, including ACM Digital Library, Scopus, Web of Science, and ERIC. These databases were selected to ensure comprehensive coverage of educational technology and learning analytics research (Du

![](images/7d5eb9dd19d794a428b942e5c8a83ba9c4f5b54ecb9ae3a84aac545f828d88fd.jpg)  
Fig.1 The systematic literature review procedure

et al., 2023). Additionally, we specifically included the Proceedings of the Learning Analytics and Knowledge (LAK) Conference and the Journal of Learning Analytics (JLA). These two outlets are recognised as central to the learning analytics research community, providing a dedicated space for methodological advancements and theoretical discussions in the field (Khalil et al., 2023; Samuelsen et al., 2019). While they do not represent the entirety of learning analytics research, their prominence within the Society of Learning Analytics Research (SoLAR) and their broad shared understanding of LA's claims and contributions (Khalil et al., 2023) justify their inclusion in this review. This selection strategy ensures a balance between breadth and depth—capturing both general educational research and highly specialised LA studies, while avoiding the omission of foundational contributions. Moreover, our selection process was not based on journal or conference names but was guided by a keyword- driven search, ensuring that relevant studies from broader educational technology and learning sciences domains were included.

The search keywords used were "learning analytics" and ("virtual environment" OR "virtual reality" OR "3D learning environment" OR "2D learning environment" OR "mixed reality" OR "MR" OR "VR" OR "virtual world" OR "metaverse" OR immers\*). These keywords were selected to comprehensively cover the various forms of VLEs in which LA can be applied. Given that the article's theme is LA in VLEs, these terms ensure that the search includes studies exploring different dimensions and technologies of VLEs relevant to LA. In addition, to ensure comprehensive coverage, we included the keyword "metaverse" in our literature search. However, our study does not classify the metaverse as a distinct category of VLE in the subsequent results section due to the inconsistent standards in its definition.

The search process was not limited to a specific starting period, ending in January 2025. However, all of the literature retrieved was published in 2011 or later. The reason for this could be that LA began to receive attention in 2011 (Banihashem et al., 2018), generating a large number of articles and starting its first conference dedicated to LA, the International Conference on Learning Analytics and Knowledge (LAK).

# Reviewing and excluding papers

This systematic literature review developed several criteria for selecting and screening research papers. First, we considered studies that explicitly focused on the application of LA techniques and methodologies in immersive VLEs. These environments include, but are not limited to, virtual reality (VR), mixed reality (MR), 3D learning environments, and other immersive virtual spaces. Second, we ensured that the studies covered the generation and analysis of data during learner interactions within these immersive VLEs. This data could include log data (behavioural tracking data), facial expression data, or data from other external devices used in the virtual learning process. Third, the studies had to be empirical in nature, including empirical studies, case studies, and comparative studies, aimed at evaluating or exploring the understanding, monitoring, assessment, or optimization of the learning process. Lastly, we focused on papers written in English to maintain consistency and comprehensibility.

Consequently, studies that did not satisfy the above criteria were excluded, including those that were (1) not focused on immersive VLEs, (2) theoretical or opinion- based

without empirical data, (3) mere technical reports, (4) non- English, or (5) conference abstracts, posters, book reviews, and letters to the editor.

The initial search yielded 1047 publications. After removing duplicate records, 369 unique publications remained. Next, a screening process of the titles and abstracts was carried out, excluding 678 articles based on irrelevance. This reduced the number of articles to 132 for full- text review. During the full- text assessment, 97 articles were excluded for the following reasons: non- virtual environment applications  $(n = 38)$ , lack of empirical data  $(n = 31)$ , mere technical reports or theoretical articles  $(n = 21)$ , and inappropriate types of papers  $(n = 7)$ . Finally, 34 studies were included in our review from 2013 to 2024. The literature search and screening process is illustrated in Fig. 2.

# Coding and extracting information

Following the search and screening procedures, two authors (the first author and the second author) reviewed and coded the paper dataset. We designed a coding scheme (Appendix A) based on the five RQs. Initially, both authors collaboratively worked on two sample papers to establish a consistent understanding of the codes. They then

![](images/7fb9bbbd5b81425bcb9069cf2fb6feafd73cfed83e44d2d4556b3998ed62c33e.jpg)  
Fig. 2 Literature searching and screening process

independently coded  $25\%$  of the studies, measuring inter- rater reliability with Cohen's kappa (Cohen, 1960). Cohen's kappa values were calculated for each coding field, ranging from 0.79 for "Research purposes" to 0.96 for "Disciplinary areas," indicating substantial to near- perfect agreement across all fields (McHugh, 2012). After achieving this acceptable level of reliability  $(0.61 < \text{kappa} < 0.80)$ , one author continued coding the remaining papers. Disagreements were resolved through extensive discussions to ensure consistency and accuracy.

# Results

The studies included in this review span a variety of publication outlets, consisting of both journal articles and conference papers. Specifically, 17 of the studies were reported in journal articles, while another 17 were published in conference proceedings. Most conference papers  $(84.2\%)$  were published in the Association for Computing Machinery (ACM) International Conference on Multimodal Interaction, the International Conference on Learning Analytics & Knowledge (LAK), the IEEE International Conference on Advanced Learning Technologies (ICALT), the International Conference on Information Technology and Education (ICITED), ACM International Conference Proceeding Series, and the IEEE International Conference on Serious Games and Applications for Health. As for the journal papers, the publications are diverse and spread across various journals, such as "IEEE Transactions on Learning Technologies", "Journal of Computer Assisted Learning", "Educational Technology and Society", "Australasian Journal of Educational Technology", "Interactive Learning Environments", "Wireless Communications and Mobile Computing", "Journal of Information Technology Research", "BMC Medical Education", "Computers and Graphics", and "Journal of Autism and Developmental Disorders". The variety of journals highlights the multidisciplinary nature of research in LA within immersive VLEs, incorporating perspectives from education, computer science, and cognitive science.

The studies were published between 2013 and 2024 (See Fig. 3). Following a steady increase in publications from 2018 to 2022, the number of studies peaked in 2022  $(19\%)$ . However, a decline occurred in 2023  $(10\%)$ , followed by a stabilisation in 2024  $(10\%)$ . This trend suggests that, while initial research enthusiasm—likely influenced by pandemic- driven shifts to virtual learning—led to a surge in studies, the field is now entering a phase of more stable but sustained interest. This may reflect a shift towards more refined, methodologically rigorous investigations rather than exploratory studies.

# RQ1 research purposes, types of learning environments, and participants and disciplinary areas

# Research purposes

The purposes of the reviewed studies were categorised into seven main themes: [A1] Enhancing learning outcomes, [A2] Evaluating learning behaviours, [A3] Predicting performance, [A4] Increasing reflection and awareness, [A5] Improving assessment and feedback, [A6] Enhancing social interaction, and [A7] Understanding affective states. Figure 4 presents the distribution of the reviewed studies across these research purposes and publication years. The diameter of each circle indicates the number of

![](images/a9d026c5a662f016d9b5eaca83bbd91d5ae5aa9280b34783dd0401f61b19e4b9.jpg)  
Fig. 3 Number of studies published by year (2013-2024)

![](images/5ad82316e198d9edccedb30ba842c5dd31c6c378d4c8b845a8aa7fdcbb413854.jpg)  
Fig. 4 Distribution of reviewed studies across research purposes and publication years

studies, and a study may encompass multiple purposes. Citations of the studies are listed in Appendix B.

From 2013 to 2019, research in LA for immersive VLEs primarily focused on [A1] Enhancing learning outcomes and [A2] Evaluating learning behaviours. These studies emphasised the use of data- driven techniques to improve student learning and analyse behavioural patterns. Since 2020, research purposes have become more diversified, with an increasing number of studies investigating [A3] Predicting performance and [A4] Increasing reflection and awareness. This trend reflects a growing interest in personalised LA and real- time feedback mechanisms. More recently, research has expanded into affective and social dimensions of immersive learning. Studies addressing [A5] Improving assessment and feedback have remained steady, while [A6] Enhancing social interaction and [A7] Understanding affective states have gained prominence from 2022 onward. This shift indicates a rising focus on collaborative and

emotional aspects of learning in immersive virtual environments, reinforcing the role of multimodal analytics in capturing richer student experiences.

# Types of learning environments

The types of immersive VLEs utilised in the reviewed studies are presented in Table 1. These environments were categorized into four distinct types based on their technological setups and user experiences: Desktop VR, Mobile VR, Immersive VR, and Mixed Reality (MR).

First, Desktop VR environments, which involve using desktop computers to access VLEs and peripherals like joysticks or mouse(s) to control movement, were the most frequently employed, with a total of 19 studies  $(55.88\%)$ . Among these, four studies  $(11.76\%)$  did not specify the exact environment used. The remaining 15 studies  $(44.12\%)$  explored specific platforms such as Future Worlds (2 studies,  $5.88\%$ ), Crystal Island (2 studies,  $5.88\%$ ), and Second Life (2 studies,  $5.88\%$ ). Other platforms mentioned include OpenSim (1 study,  $2.94\%$ ), TeachLive (1 study,  $2.94\%$ ), CASUS (1 study,  $2.94\%$ ), Conectado (1 study,  $2.94\%$ ), AvayaLive Engage (1 study,  $2.94\%$ ), Learning Analytics for

Table 1 Types of virtual learning environments used in the reviewed studies  

<table><tr><td colspan="2">Types of virtual learning environments</td><td>Number of studies</td></tr><tr><td rowspan="13">Desktop VR (19)</td><td>Not mentioned</td><td>4</td></tr><tr><td>Future worlds</td><td>2</td></tr><tr><td>Crystal Island</td><td>2</td></tr><tr><td>Second life</td><td>2</td></tr><tr><td>OpenSim</td><td>1</td></tr><tr><td>TeachLive</td><td>1</td></tr><tr><td>CASUS</td><td>1</td></tr><tr><td>Conectado</td><td>1</td></tr><tr><td>AvayaLive engage</td><td>1</td></tr><tr><td>Learning analytics for VR</td><td>1</td></tr><tr><td>CLONE</td><td>1</td></tr><tr><td>EcoXPT</td><td>1</td></tr><tr><td>iSocial</td><td>1</td></tr><tr><td>Mobile VR (1)</td><td>Android-based teacher orchestration system</td><td>1</td></tr><tr><td rowspan="7">Immersive VR (8)</td><td>Unity-based VR application</td><td>2</td></tr><tr><td>MIT app inventor</td><td>1</td></tr><tr><td>Virtual performance assessment</td><td>1</td></tr><tr><td>RePiX VR</td><td>1</td></tr><tr><td>HTC vive pro</td><td>1</td></tr><tr><td>CLEVR</td><td>1</td></tr><tr><td>Not mentioned</td><td>1</td></tr><tr><td rowspan="5">Mixed Reality (6)</td><td>OpenSimulator</td><td>2</td></tr><tr><td>Microsoft HoloLens VR/MR</td><td>1</td></tr><tr><td>HeartMR</td><td>1</td></tr><tr><td>Temporal bone surgical simulator</td><td>1</td></tr><tr><td>Squad advanced marksmanship trainer</td><td>1</td></tr></table>

VR (1 study,  $2.94\%$ ), CLONE (1 study,  $2.94\%$ ), EcoXPT (1 study,  $2.94\%$ ), and iSocial (1 study,  $2.94\%$ ), each appearing in one study.

Second, Mobile VR environments, involving the use of smartphones or smartwatches to access virtual learning environments, were utilised in one study  $(3.23\%)$ , which focused on an Android- based teacher orchestration system.

Third, immersive VR environments, involving Head- Mounted Displays (HMD) or Cave Automatic Virtual Environments (CAVEs) systems, were used in eight studies  $(23.53\%)$ . Among these, Unity- based VR applications were mentioned in two studies  $(5.88\%)$ , while MIT App Inventor (1 study,  $2.94\%$ ), Virtual Performance Assessment (1 study,  $2.94\%$ ), RePiX VR (1 study,  $2.94\%$ ), HTC Vive Pro (1 study,  $2.94\%$ ), and CLEVR (1 study,  $2.94\%$ ) were each used in one study. One study  $(2.94\%)$  did not specify the particular Immersive VR environment utilised.

Lastly, mixed reality (MR) environments, which involve immersive experiences composed of both virtual and physical elements, were explored in six studies  $(17.65\%)$ . OpenSimulator was employed in two studies  $(5.88\%)$ , indicating its versatility in mixed reality applications. Other MR environments included Microsoft HoloLens VR/MR (1 study,  $2.94\%$ ), HeartMR (1 study,  $2.94\%$ ), Temporal Bone Surgical Simulator (1 study,  $2.94\%$ ), and Squad Advanced Marksmanship Trainer (1 study,  $2.94\%$ ).

# Participants and disciplinary areas

The participants and disciplinary areas involved in the reviewed studies are presented in Fig. 5. The participants were primarily college students  $(50\%)$ , followed by K- 12 students  $(24\%)$ , and adult education participants  $(18\%)$ .

Regarding the disciplinary areas, the studies involving K- 12 students were distributed across various subjects. Science was the most common subject area with three studies. Language learning had two studies. technology, mathematics, history, sociology,

![](images/cb5d744fc895b9e2866fb95d861aa4f62baca1bb4bc618724a449e54e4c71b82.jpg)  
Fig. 5 Distribution of participants and disciplinary areas

education, medicine, public health, medical education, and literature each had one study. For college students, the most frequently studied disciplinary areas were Technology, Education, Language Learning and Medical Education, each with three studies. Sociology, history, mathematics, science, and literature were each represented by one study. In the context of adult education, the studies were concentrated in medical education, with two studies. Public health, Psychology, Literature, and Education were each represented by one study.

# RQ2: theories, models, or frameworks

Out of the 34 reviewed studies, 11 explicitly mentioned their theoretical grounding or had theories that could be inferred from the described methodologies and approaches. These studies were based on various theories, models, or frameworks that can be grouped into several main categories as shown in Table 2. They are: constructivism, situated learning, self- regulated learning (SRL), competence- based knowledge space theory, vocabulary learning strategies, cognitive load theory, student approaches to learning (SAL), motivation theory, self- efficacy theory, value- control theory, arousal- valence model and Bloom's taxonomy. These theories helped contextualise and interpret the results, ensuring that the findings were grounded in established educational paradigms. Each study could adopt multiple theories. However, the remaining 23 studies did not specify any theoretical frameworks, nor could such frameworks be reasonably inferred from the methodologies or approaches described.

# RQ 3: data types and data analysis techniques

Figure 6 presents the relationship between the reviewed articles and the data types they utilized. We grouped data types based on their nature and the kind of information they provide. Some studies collected multiple data types. Behaviour data stands out as the most frequently used, being employed in 26 studies, accounting for  $76.47\%$  of the reviewed studies. Eye tracking data is the second most commonly used, featured in 7 studies  $(20.59\%)$ . Facial expression data is utilized in 4 studies  $(11.76\%)$ . Speech data appears in 5 studies  $(14.71\%)$ . Physiological data is used in 3 studies  $(9.68\%)$ . Video data

Table 2 Articles mentioning each theory/model/framework  

<table><tr><td>Theories/Models/Frameworks</td><td>References</td></tr><tr><td>Constructivism</td><td>Ng et al., (2022a), (b)</td></tr><tr><td>Situated learning</td><td>Carpenter et al., (2021), Vatral, et al., (2022)</td></tr><tr><td>Self-regulated learning (SRL)</td><td>Carpenter et al., (2021), Wang and et al., (2022)</td></tr><tr><td>Competence-based knowledge Space theory</td><td>Kickmeier-Rust, et al., (2014)</td></tr><tr><td>Vocabulary learning strategies</td><td>Indy et al., (2017)</td></tr><tr><td>Cognitive load theory</td><td>Birt, et al., (2019)</td></tr><tr><td>Student approaches to learning (SAL)</td><td>Berman and Artino, (2018)</td></tr><tr><td>Motivation theory</td><td>Berman and Artino, (2018)</td></tr><tr><td>Self-efficacy theory</td><td>Berman and Artino, (2018)</td></tr><tr><td>Value-control theory</td><td>Baena-Perez et al., (2024)</td></tr><tr><td>Bloom&#x27;s taxonomy</td><td>Antoniou et al., (2020)</td></tr><tr><td>Arousal-Valence model</td><td>Li and Shen, (2024)</td></tr><tr><td>Situated learning</td><td>Carpenter et al., (2021)</td></tr></table>

![](images/b20e6d979432ba1c91ff94c8a8bd3c6d345663054c68e1a20f755b5620fa5ce1.jpg)  
Fig. 6 Relationship between articles and data types

![](images/f12e400ae635c00375785c56cc3b14a42c80fbcc4cc63a0b2c74b7af398641f5.jpg)  
Fig. 7 Matrix of articles and data analysis techniques

is present in 5 studies  $(14.71\%)$ . Questionnaire data is featured in 7 studies  $(20.59\%)$ . Spatial data is found in 1 study  $(2.94\%)$ . Learning path data is used in 1 study  $(2.94\%)$ . Simulator data appears in 1 study  $(2.94\%)$ . Interview data is used in 1 study  $(2.94\%)$ , and text data was included in 1 study  $(2.94\%)$ . The increasing diversity of data types—ranging from behavioural and physiological data to multimodal interactions—indicates a growing interest in multimodal learning analytics (MMLA). However, our review shows that most studies continue to rely on single- modal data analysis, limiting the full potential of integrating multiple data sources for a holistic understanding of learning in immersive VLEs.

Moreover, Fig. 7 demonstrates the relationships between articles and data analysis techniques. The columns represent different data analysis techniques, categorized into statistical analysis (red), machine learning (blue), data mining (green), and qualitative analysis (orange). The rows list the articles reviewed, and the shaded cells indicate which

methods were used in each study. Statistical analysis is the most frequently mentioned technique, appearing 24 times across the studies. This category includes methods such as linear/logistic regression, ANOVA, correlation, and time series analysis. Machine learning techniques are divided into traditional machine learning and deep learning methods. Traditional machine learning techniques, including supervised learning (e.g., Bayesian networks, support vector machines, random forests) and unsupervised learning, are mentioned 21 times across the 34 studies. No studies employed deep learning methods like neural networks, convolutional neural networks (CNN), or recurrent neural networks (RNN). Data mining methods focusing on processing and interpreting large datasets are used 19 times. These methods include pattern recognition and various visualisation techniques. Qualitative analysis is mentioned three times, providing in- depth insights into learners' video recordings and interviews.

# RQ 4: challenges

In Table 3, we summarised the challenges and limitations discussed in the reviewed studies into four main categories. Each study could propose multiple challenges.

Table 3 Challenges proposed in the reviewed studies  

<table><tr><td>Categories</td><td>Challenges</td><td>Number of studies</td></tr><tr><td rowspan="7">Technical complexity</td><td>Data processing and algorithm complexity, including integration, han-dling, bias, transparency, and trade-offs between accuracy and fairness</td><td>15</td></tr><tr><td>Complexity of real-time data collection and processing using off-the-shelf devices like smartphones and smartwatches</td><td>3</td></tr><tr><td>Time and economic constraints in building personalized immersive scenarios</td><td>4</td></tr><tr><td>Technical challenges, including the use of highly complex electronic devices and equipment in virtual environments</td><td>5</td></tr><tr><td>Complexity in assessing student engagement in virtual environments, particularly in developing and validating dynamic engagement scoring algorithms</td><td>3</td></tr><tr><td>Design issues of user interfaces and operability in mixed reality technology, such as handling 3D models and touchscreens simultaneously on smartphones</td><td>2</td></tr><tr><td>Preprocessing physiological data is technically complex</td><td>1</td></tr><tr><td rowspan="2">Data privacy and security</td><td>Limitations due to small sample sizes and diverse participant groups, leading to challenges in personalization and statistical validation</td><td>4</td></tr><tr><td>Data privacy and security issues, including anonymization and access control challenges</td><td>4</td></tr><tr><td>Data interpretability</td><td>Data interpretability issues, including model transparency and result visualization</td><td>8</td></tr><tr><td rowspan="4">Implementation and adoption barriers</td><td>Resource constraints: Significant increase in response time with a growing number of variables to analyse</td><td>3</td></tr><tr><td>Teacher training and technical challenges, including difficulties in access-ing and analysing student log data and lack of necessary technical skills among teachers</td><td>5</td></tr><tr><td>Complexity in creating and managing virtual learning environments, especially integrating VR and chatbots, and reducing the number of programming blocks required for non-expert users</td><td>4</td></tr><tr><td>Ensuring that user interaction data is effectively captured and analysed to support learning analytics</td><td>2</td></tr></table>

First, technical complexity was discussed in 15 studies. These studies highlighted issues related to data processing and algorithm complexity, including integration, handling, bias, transparency, and trade- offs between accuracy and fairness. Three studies mentioned the complexity of real- time data collection and processing using off- the- shelf devices like smartphones and VR headsets. Four studies pointed out time and economic constraints in building personalized immersive scenarios. Additionally, five studies discussed technical challenges related to the use of highly complex electronic devices and equipment in virtual environments. Three studies focused on the complexity of assessing student engagement in virtual environments, particularly in developing and validating dynamic engagement scoring algorithms. Two studies addressed design issues of user interfaces and operability in mixed reality technology, such as handling 3D models and touchscreens simultaneously. One study highlighted the technical complexity of preprocessing physiological data, particularly in ensuring accurate signal extraction and reducing noise interference.

Second, data interpretability issues were discussed in eight studies. These studies highlighted challenges related to model transparency and the visualization of results, making it difficult for educators to interpret and action the findings.

Third, data privacy and security issues were raised in four studies. These challenges included anonymization and access control difficulties. Four studies also mentioned limitations due to small sample sizes and diverse participant groups, leading to challenges in personalization and statistical validation.

Finally, implementation and adoption barriers were noted in 14 studies. Three studies pointed out resource constraints, such as a significant increase in response time with a growing number of variables to analyse. Five studies mentioned teacher training and technical challenges, including difficulties in accessing and analysing student log data and a lack of necessary technical skills among teachers. Four studies highlighted the complexity in creating and managing virtual learning environments, especially in integrating VR and chatbots, and reducing the number of programming blocks required for non- expert users. Lastly, two studies emphasised the importance of ensuring that user interaction data is effectively captured and analysed to support LA.

# Discussion

The review emphasises the evolution of LA into multimodal learning analytics (MMLA), the theoretical gaps in the research, the changing purposes and participant groups of LA, and the practical challenges associated with its implementation. In the following sections, we will elaborate on these findings and provide in- depth discussions on how they can guide future research and practice.

# Strengthening research on multimodal learning analytics in immersive virtual learning environments

Multimodal learning analytics (MMLA) has emerged as a critical direction in LA research, offering deeper insights into students' cognitive and emotional states in immersive virtual learning environments (VLEs). While prior studies have highlighted MMLA's potential to improve learning outcomes (Azevedo & Gašević, 2019; Cukurova, 2019), our review suggests that its implementation in immersive VLEs remains limited,

with many studies still relying on single- modal data analysis (Fig. 6). The majority of studies continue to focus on behavioural data  $(76.47\%)$  (e.g., Carpenter et al., 2021; Heinemann et al., 2023; Moon & Ke, 2023), followed by questionnaire- based self- reports  $(20.59\%)$  (e.g., Chen et al., 2021; Li & Shen, 2024). This indicates a strong preference for observable behavioural interactions, yet a lack of integration with physiological, affective, and multimodal indicators that could provide a more comprehensive picture of learning experiences (Cosentino & Giannakos, 2023). Despite the fact that immersive VR  $(19.35\%)$  and mixed reality (MR)  $(19.35\%)$  offer built- in capabilities for capturing multimodal data through eye- tracking, physiological sensors, and spatial tracking (Halbig & Latoschik, 2021), few studies have fully leveraged these affordances.

The underutilization of multimodal data in immersive VLEs may stem from both methodological and technical challenges. Studies such as Vatral et al. (2022) have demonstrated the feasibility of integrating behavioural, eye- tracking, speech, and physiological data to assess collaborative learning processes. Similarly, Ahmad et al. (2022) combined facial expressions, speech analysis, and physiological indicators to evaluate engagement levels. However, our results reveal that most studies still rely on unimodal or loosely integrated multimodal approaches, limiting the potential to derive richer insights from real- time student interactions. A key issue here is data redundancy and noise, as highlighted by Giannakos et al. (2019), where more data does not always translate to better insights. Instead, the inclusion of excessive multimodal data can introduce confounding variables and increase computational complexity, making analysis less interpretable.

A related challenge lies in the choice of analytical methods. Our review shows that statistical analysis techniques, such as ANOVA and regression, remain the predominant approach  $(70.6\%)$  (e.g., Ng et al., 2023; Stefan et al., 2016), while machine learning methods remain underutilized, and deep learning techniques are absent from MMLA research in immersive VLEs (Fig. 7). Given the high- dimensional and nonlinear nature of multimodal data, traditional statistical methods may not be well- suited to capture complex patterns in learning behaviour (Hilbert et al., 2021). Although deep learning models, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have demonstrated effectiveness in processing time- series and multimodal data, our review found no studies that have employed them in the context of immersive VLEs. This suggests a methodological gap, where the lack of deep learning adoption may hinder the ability to identify intricate relationships between different data sources, such as how students' physiological responses correspond to their in- VR interactions and cognitive states.

Another concern is the interpretability of complex MMLA models in immersive VLEs. While machine learning and deep learning approaches have the potential to uncover hidden patterns, their "black box" nature limits their applicability in educational contexts, where transparency is critical (Pedrycz, 2021). This challenge aligns with findings in our review, where researchers favour explainable techniques such as regression models over deep learning, despite the latter's potential to capture complex relationships in multimodal data. Future research should consider integrating explainable AI (XAI) approaches (machine learning techniques that provide human- interpretable explanations for model predictions, enhancing transparency and trust in AI- driven analytics) to enhance the interpretability of MMLA insights (Susnjak, 2024; Tiukhova et al., 2024).

For example, attention- based models and visualization- based techniques could be used to provide transparent justifications for predictions, allowing educators to better understand and act upon LA findings.

A critical aspect of MMLA in immersive VLEs is the relationship between data modality selection and research objectives. Many reviewed studies applied multimodal techniques to examine cognitive engagement and behavioural patterns, but rarely explored the affective and metacognitive dimensions of learning, which are increasingly recognized as essential in immersive environments (Nguyen et al., 2023). Situated learning theory, for example, posits that learning occurs within authentic contexts and is deeply influenced by the learner's interaction with the environment (Carpenter et al., 2021). However, our review suggests that many studies primarily analyse behavioural logs, such as interaction counts, navigation patterns, and completion times, without integrating real- time cognitive and affective indicators (e.g., Baena- Perez et al., 2024; Novoseltseva et al., 2022). These traditional approaches may overlook how learners' engagement, emotional states, and cognitive regulation evolve dynamically in immersive VLEs. While some studies have already incorporated physiological data (Diederich et al., 2021; Heinemann et al., 2023), eye- tracking data (Acosta et al., 2021), and speech analysis (Ahmad et al., 2022), these modalities were often used in isolation rather than as part of a fully integrated multimodal framework. Future research should expand beyond interaction logs to incorporate physiological responses, eye- tracking, and speech analysis, allowing for a more holistic understanding of how students regulate their learning processes within immersive environments.

The findings of our review highlight the need for a paradigm shift in MMLA research within immersive VLEs, where the focus moves from collecting isolated multimodal data streams to developing integrated, theoretically grounded analytical frameworks. By systematically combining eye- tracking, speech, physiological responses, and behavioural data, researchers can better capture the dynamic and interactive nature of learning in immersive settings. Additionally, the field must advance beyond traditional statistical methods to embrace machine learning and deep learning approaches, while ensuring interpretability through explainable AI techniques. Addressing these challenges will allow MMLA to fully leverage the affordances of immersive VLEs, enabling real- time, data- driven feedback that can optimize virtual learning experiences and instructional design.

# Augmenting the theoretical foundations of learning analytic research in virtual learning environments

Augmenting the theoretical foundations of learning analytic research in virtual learning environmentsResearch on LA in immersive VLEs has predominantly employed data- driven approaches, focusing on the extraction of patterns through clustering, classification, and statistical inference. While these techniques offer valuable insights into student behaviours, they often operate in isolation from well- established educational theories. Our results indicate that out of the 34 reviewed studies, only 11 explicitly referenced theoretical frameworks or had theories that could be inferred from their methodologies. The most commonly mentioned theories include constructivism, situated learning, self- regulated learning (SRL), cognitive load theory, and Bloom's taxonomy. However, the remaining 23 studies did not specify any theoretical grounding, reflecting a broader

trend in immersive VLEs research, where data- driven methods frequently take precedence over theoretically informed analyses.

A key limitation of existing research is the fragmented and inconsistent application of theories, where theoretical concepts are often cited post hoc to explain findings, rather than guiding study design, data collection, or interpretation. For instance, constructivism, referenced in  $\mathrm{Ng}$  et al. (2022a, b), was primarily used to rationalise learning interactions in immersive environments but was not systematically integrated into the data analysis framework. Similarly, situated learning theory (Carpenter et al., 2021; Vatral et al., 2022) was applied in studies focusing on collaborative learning and immersive engagement but was seldom operationalised through specific LA methodologies. This suggests that while researchers acknowledge the relevance of these theories, their incorporation remains largely descriptive rather than analytical.

Another issue is the mismatch between traditional educational theories and the complex, multimodal nature of immersive VLEs. Many of the identified studies rely on theories originally developed in face- to- face or traditional online learning settings, which may not fully capture immersive, multimodal learning experiences. For example, cognitive load theory (Birt et al., 2019) has been employed to explain cognitive processes in immersive environments, yet it does not inherently account for dynamic affective and physiological responses that immersive VLEs can capture through multimodal learning analytics. Similarly, competence- based knowledge space theory (Kickmeier- Rust et al., 2014) has been applied in structured learning scenarios but may not be well- suited to open- ended, exploratory learning experiences that immersive VLEs facilitate. These misalignments highlight the need for either adapting existing theories or developing new theoretical models tailored to immersive, multimodal, and interactive learning environments.

The absence of theoretical grounding in many studies also has methodological implications. Our review suggests that studies relying solely on pattern recognition, statistical correlation, or unsupervised clustering may lack explanatory depth, as they do not explicitly define learning mechanisms or cognitive processes. Without a strong theoretical foundation, findings risk being overly descriptive, making it difficult to generalise results across different immersive learning contexts. For instance, studies employing SRL theory (Carpenter et al., 2021; Ng et al. 2022b) could provide more structured interpretations of how learners regulate their actions within immersive spaces, particularly when combined with multimodal data streams capturing real- time interactions, speech, and physiological indicators. However, most existing research does not integrate SRL or SSRL models with data- driven insights, limiting the potential to explain why certain learning patterns emerge in immersive VLEs.

To address these gaps, future immersive VLE research should prioritise theory- driven LA that explicitly connects data types, analytical methods, and theoretical constructs. One potential approach is interdisciplinary theoretical integration, where models from cognitive science, social psychology, and artificial intelligence are combined to provide a more holistic understanding of immersive learning experiences. Ouyang et al. (2023), for instance, applied complex adaptive systems (CAS) theory to analyse collaborative learning, viewing student interactions as self- organising, evolving processes rather than static behaviours. Similarly, the community of inquiry (Col) framework Song et al.

(2023a) offers a visual approach to analysing the cognitive, social, and teaching presence in immersive VLEs, which could enhance interpretability in MMLA.

Future research should also develop theoretically grounded MMLA models that explicitly operationalise learning theories in data- driven analysis. For example, deep learning models trained on eye- tracking, speech, and physiological signals could be aligned with SRL or cognitive load theory to examine how cognitive and affective regulation unfolds in immersive environments. Additionally, situated learning theory could inform spatial movement tracking and collaborative analytics, linking learner engagement in immersive VLEs to real- world problem- solving and authentic learning contexts. By integrating theoretical insights into analytical models, researchers can move beyond descriptive trends and establish explanatory frameworks that enhance the generalisability and educational relevance of LA in immersive VLEs.

This paradigm shift towards theory- driven MMLA is essential to fully leverage the affordances of immersive VLEs, ensuring that research not only captures observable behaviours but also interprets learning processes through theoretically sound methodologies. By systematically combining constructivist, cognitive, and sociocultural theories with multimodal data analytics, future studies can provide a more nuanced and interpretable understanding of how learning unfolds in immersive, data- rich environments.

# Expanding the purposes and participant groups of learning analytics in virtual learning environments

The focus of LA in immersive VLEs has evolved significantly over time, reflecting broader shifts in educational research priorities. Initially, LA studies in immersive VLEs primarily sought to enhance learning outcomes and evaluate student behaviours, with most studies before 2019 focusing on these areas. However, as our results indicate, research has since expanded into new domains, with increasing emphasis on predicting student performance, fostering self- reflection and awareness, and optimising assessment and feedback. More recently, studies have prioritised social interaction and affective states, suggesting a growing recognition of the importance of collaborative and emotional dimensions in immersive learning (Fig. 4). This diversification highlights the increasing integration of multimodal analytics, which allows for a richer understanding of student engagement by combining behavioural, physiological, and cognitive data.

Despite this progress, a key limitation in current research is the uneven development of these new research directions. While studies on learning outcomes and behaviour evaluation remain dominant, research into affective and social aspects of learning in immersive VLEs has only gained traction in recent years. The role of self- reflection and awareness in immersive learning environments, for instance, has been investigated in some studies (e.g., Vatral et al., 2022), but its application remains largely underexplored. Moreover, predictive LA, which has been used to anticipate student performance based on behavioural patterns (Ahmad et al., 2022), has rarely incorporated multimodal indicators such as eye- tracking, speech analysis, or physiological responses. This suggests that while research purposes are expanding, data collection strategies and analytical methods have not yet fully adapted to these new areas of interest. Future studies should address this gap by systematically integrating MMLA into predictive models, self- regulation research, and real- time assessment techniques.

A related issue concerns the impact of immersion and multitasking on cognitive load. Our review highlights that high- immersion environments often introduce new challenges, such as cognitive overload, increased multitasking demands, and difficulties in maintaining focus (Huang et al., 2019). However, research investigating how students regulate their cognitive and emotional states in immersive VLEs remains limited. While some studies have explored cognitive load theory (Birt et al., 2019) in immersive learning contexts, they have often relied on self- report data rather than objective physiological or interaction- based measures. Given the dynamic nature of learning in immersive VLEs, future research should explore real- time LA approaches, integrating multimodal data such as gaze patterns, pupil dilation, and speech sentiment analysis to capture cognitive and affective states as they evolve.

Another critical area requiring further investigation is collaborative learning in immersive VLEs. While collaboration is a key affordance of these environments, the complexity of virtual teamwork and real- time communication introduces new challenges. Existing studies on collaborative learning in immersive VLEs (e.g., Chen et al., 2021; Diederich et al., 2021; Novoseltseva et al., 2022) tend to focus on team- level dynamics, such as group cohesion and participation balance, but pay less attention to individual differences in self- regulation, communication styles, and learning needs. The heterogeneity of learners, particularly in terms of prior knowledge, cognitive abilities, and preferred interaction styles, means that one- size- fits- all collaborative models may be ineffective. Future research should explore personalised collaborative analytics, leveraging LA techniques to adapt group roles, learning tasks, and support mechanisms based on real- time student performance and engagement levels.

In addition to collaborative challenges, our review reveals a participant bias in existing research, with a disproportionate focus on university students. Studies involving higher education learners account for a majority of the reviewed papers (e.g., Ahmad et al., 2022; Baena- Perez et al., 2024; Heinemann et al., 2023), whereas K- 12 students and adult learners remain significantly underrepresented. This imbalance likely stems from practical constraints, as universities provide more accessible research settings, enabling easier implementation of immersive learning studies. However, immersive VLEs hold substantial educational potential beyond university settings, particularly in K- 12 and lifelong learning contexts.

For K- 12 learners, immersive VLEs can support experiential learning by simulating scientific experiments, historical events, and complex problem- solving scenarios. However, younger students face distinct cognitive and developmental challenges, such as shorter attention spans and varying levels of digital literacy. Current research on LA in K- 12 immersive VLEs remains limited, with only a handful of studies examining subject- specific learning outcomes (Fig. 5). The dominant focus on science and language learning suggests that LA applications have not yet fully explored cross- disciplinary opportunities, such as mathematics, history, or social sciences. Moreover, LA techniques used in higher education may not directly translate to K- 12 learning environments, where students require greater scaffolding, adaptive interventions, and teacher support (Zhang et al., 2024). Future research should investigate how LA tools can be designed for younger learners, ensuring that feedback mechanisms are developmentally appropriate and that engagement metrics account for cognitive differences across age

groups. Similarly, adult learners represent another understudied population in immersive VLEs. While these environments hold significant potential for career training, professional development, and workplace simulations, studies on adult LA remain scarce. The challenges faced by adult learners differ markedly from those of younger students, as they often struggle with motivation, time constraints, and balancing learning with work responsibilities (Poquet et al., 2021). While immersive VLEs can enhance engagement through experiential learning and skill- based simulations, they also introduce barriers, such as technological accessibility and digital literacy gaps. Research should therefore explore how LA can be adapted to adult learners, investigating adaptive learning pathways, real- time performance analytics, and personalised feedback mechanisms tailored to self- paced, flexible learning scenarios.

Beyond broadening participant groups, future research should also address equity and accessibility concerns in immersive VLEs. While these environments offer new opportunities for personalised and engaging learning, their effectiveness is often contingent on access to high- quality hardware, stable internet connections, and institutional support. Our review found that students in special education (Chan et al., 2023) and resource- limited settings (Prinsloo & Kaliisa, 2022) are largely underrepresented in immersive LA research. Given the potential of immersive VLEs to support diverse learners, including students with disabilities (Chan et al., 2023) and those in low- resource environments (Prinsloo & Kaliisa, 2022), future studies should investigate scalable, cost- effective approaches to ensuring inclusive participation. This could include leveraging mobile- based VR solutions to provide immersive experiences at a lower cost, and cloud- based LA tools, which enable real- time data processing and analytics without requiring high- end local hardware (Morye et al., 2023; Shamir- Inbal & Blau, 2021), thereby reducing hardware dependency and expanding access. Additionally, adaptive user interfaces, which adjust their layout and complexity based on user needs, and explainable analytics techniques, which make AI- driven learning insights more interpretable for educators and students (Rodriguez- Garcia et al., 2021; Susnjak, 2024; Tiukhova et al., 2024), can enhance usability, ensuring that students with different levels of technological proficiency can effectively engage with immersive VLEs.

# Enhancing the usability, interpretability, security, and teacher support of LA in VLEs

The practical application of LA in immersive VLEs presents multiple challenges, as highlighted in Sect. "RQ 4: challenges". These challenges span technical complexity, data interpretability, privacy and security, and implementation barriers. Addressing these issues requires both technological and pedagogical solutions that enhance usability, interpretability, security, and teacher support.

Usability remains a major concern in immersive VLEs due to the complexity of handling multimodal data, integrating diverse analysis techniques, and managing real- time data collection (Table 3). Our review found that 15 studies discussed issues related to data processing complexity, including concerns over bias, transparency, and algorithmic trade- offs. Additionally, studies identified the technical challenges associated with using advanced VR/MR devices for data collection, particularly in processing real- time multimodal inputs (e.g., smartphones, VR headsets, physiological sensors). Given these complexities, adopting modular and scalable architectures has

been proposed as a solution to streamline data integration and processing (Morye et al., 2023). Our results show that four studies highlighted time and economic constraints in building personalised immersive learning scenarios, further indicating the need for cost- effective solutions. Edge computing has been suggested as a potential approach to reduce computational latency by processing data closer to the source, enhancing real- time analytics for immersive VLEs (Shamir- Inbal & Blau, 2021). However, few reviewed studies have explicitly tested the impact of edge computing on immersive VLEs, highlighting an avenue for future research. These limitations suggest that researchers should explore scalable architectures that reduce resource- intensive computation and dependency on high- end hardware, ensuring that immersive VLE- based LA can be deployed in diverse educational contexts (Luckin et al., 2022).

Interpretability remains a significant challenge, particularly for complex machine learning models applied in immersive VLEs. Eight studies in our review explicitly discussed difficulties in model transparency and result visualisation, reinforcing concerns about the accessibility of analytics insights for educators. While statistical models such as regression and ANOVA remain widely used (Fig. 7), they struggle to capture high- dimensional relationships between multimodal data types (e.g., behavioural, physiological, and cognitive indicators). Although machine learning methods have been introduced, deep learning remains underutilised (Hilbert et al., 2021), and its black- box nature further limits interpretability. However, the potential of Explainable AI (XAI) techniques in improving interpretability has been recognised (Susnjak, 2024; Tiukhova et al., 2024). These methods enable the visualisation of decision- making pathways in multimodal analytics, providing educators with more transparent justifications for predictions. While XAI was previously discussed in Sect. "Strengthening research on multimodal learning analytics in immersive virtual learning environments" regarding its potential benefits for MMLA, its relevance in model interpretability within immersive VLEs requires further exploration. Existing studies on LA dashboards and real- time interaction visualisations (Song et al., 2023b) suggest that holistic approaches, such as heatmaps and dynamic data representations, can improve accessibility for educators. However, there remains a lack of empirical studies examining how these solutions influence educators' decision- making in immersive VLEs, reinforcing the need for further research into user- centred visualisation approaches.

Data privacy and security pose additional barriers to the widespread adoption of LA in immersive VLEs. Four studies in our review raised concerns about data anonymisation and access control, while an equal number highlighted sample size limitations that impact personalisation and statistical validation. The integration of real- time biometric and physiological data in immersive VLEs further complicates security considerations, as these data types are more sensitive and difficult to anonymise than traditional behavioural logs (Baena- Perez et al., 2024). Federated learning and blockchain technologies have been proposed as potential solutions to enhance data security while allowing for decentralised data processing (Unal et al., 2021). However, no reviewed studies have implemented these techniques in immersive VLE settings, indicating a gap between theoretical proposals and practical applications. Additionally, immersive environments introduce unique security risks, such as identity authentication for avatars, potential data breaches in shared virtual spaces, and ethical concerns regarding

continuous biometric monitoring (Ng et al. 2022b). Future research should investigate privacy- preserving analytics methods, such as differential privacy, which ensures that individual learner data remains protected while still allowing for meaningful aggregate insights (Berman & Artino, 2018). These methods could address concerns over the ethical use of biometric data in immersive learning environments, particularly as emerging legislative frameworks place stricter requirements on the processing of personal data in education (Nguyen et al., 2023).

Teacher support remains critical for the effective implementation of LA in immersive VLEs, yet our review found that five studies explicitly noted barriers related to teacher training and technical literacy. The increasing complexity of LA models and immersive learning environments means that educators require specialised training to effectively interpret and apply analytics insights (Luckin et al., 2022). Cloud- based solutions, as previously discussed in Sect. "Expanding the purposes and participant groups of learning analytics in virtual learning environments", offer a scalable means of reducing hardware dependencies (Shamir- Inbal & Blau, 2021). However, technical complexity and lack of pedagogical alignment remain major barriers to adoption. Our review also found that four studies identified challenges in integrating VR and chatbots within immersive learning environments, particularly for non- expert users. This suggests that teacher- friendly interfaces, adaptive analytics recommendations, and streamlined user interaction designs are necessary for supporting educators in effectively utilising immersive LA tools. Future research should focus on developing educator- centred dashboards that provide actionable, context- aware recommendations, rather than overwhelming teachers with raw, uninterpretable data. As AI- driven learning companions become increasingly integrated into immersive VLEs (Cukurova, 2019, 2024), ensuring that educators are equipped to interpret student analytics and apply insights effectively will be essential to bridging the gap between technology and pedagogical practice.

# Limitations

While this review offers valuable insights into the current state of LA in immersive VLEs, certain limitations must be acknowledged. The scope of this study was restricted to peer- reviewed journal articles and influential conference proceedings, which may have excluded relevant studies. Additionally, some articles were excluded because they did not specify the data analysis techniques used, potentially overlooking significant contributions. The retrospective nature of the review may also be subject to publication bias, favouring studies with statistically significant results. Future research should consider these limitations and aim to include a broader range of studies to provide a more comprehensive understanding of LA in immersive VLEs.

# Conclusion

This systematic review examined the application of learning analytics (LA) across various virtual learning environments (VLEs) from 2013 to 2024, describing the current state of the field and providing recommendations for future research. These insights serve as a foundation for enhancing the use of LA tools in immersive VLEs to improve educational outcomes.

# Appendix A

Scheme for coding and data extraction.

<table><tr><td colspan="2">Extracted data</td><td>Description/Example codes</td></tr><tr><td rowspan="4">RQ 1</td><td>Publication distribution (journals, years, authors)</td><td>Basic information of the reviewed articles</td></tr><tr><td>Research purposes (Vieira et al., 2018)</td><td>research purposes stated</td></tr><tr><td>Learning environments</td><td>e.g., desktop VR, mobile VR, immersive VR (HMD or CAVE), or mixed reality</td></tr><tr><td>Subjects &amp;amp; Disciplinary areas</td><td>Subjects: e.g., K-12 students, college students, or adult education
Disciplinary areas: e.g., science, language, or medicine</td></tr><tr><td>RQ 2</td><td>Theories/Models/Frameworks used to ana-lyse or interpret data (Khalil et al., 2023; Wang et al., 2022)</td><td>Theories that guide the studies&#x27; interpretation of learning analytics data (e.g., constructivism, self-regulated learning, and situated learning)</td></tr><tr><td rowspan="2">RQ 3</td><td>Data types</td><td>Data types for learning analytics (e.g., behav-iour data, facial expression data, and speech data)</td></tr><tr><td>Data analysis techniques (Alonso-Fernández et al., 2019)</td><td>Data analysis techniques for learning analytics (e.g., linear/logistic regression, Bayesian net-works, and clustering)</td></tr><tr><td rowspan="3">RQ 4</td><td>Technical challenges</td><td rowspan="3">Challenges or limitations stated</td></tr><tr><td>Design challenges</td></tr><tr><td>Challenges of interpretation of data</td></tr></table>

# Appendix B

Research purposes mentioned in the reviewed studies.

# Research purposes

<table><tr><td>Enhancing learning outcomes</td><td>(Ahmad et al., 2022); (Aldana-Burgos et al., 2022); (Baena-Perez et al., 2024); (Baker et al., 2016); (Balderas et al., 2017); (Barmaki &amp;amp; Hughes, 2015); (Ber-man &amp;amp; Artino, 2018); (Birt et al., 2019); (Calvo-Morata et al., 2020); (Camilleri et al., 2013); (Carpenter et al., 2021); (Chen et al., 2021); (Cruz-Benito et al., 2014); (Diederich et al., 2021); (Emerson et al., 2020); (Heinemann et al., 2023); (Indy et al., 2017); (Kennedy et al., 2013); (Kickmeier-Rust et al., 2014); (Moon &amp;amp; Ke, 2023); (Ng et al., 2022a)</td></tr><tr><td>Evaluating learning behaviours</td><td>(Acosta et al., 2021); (Ahmad et al., 2022); (Aldana-Burgos et al., 2022); (Baena-Perez et al., 2024); (Baker et al., 2016); (Balderas et al., 2017); (Barmaki &amp;amp; Hughes, 2015); (Berman &amp;amp; Artino, 2018); (Birt et al., 2019); (Calvo-Morata et al., 2020); (Camilleri et al., 2013); (Carpenter et al., 2021); (Chen et al., 2021); (Cruz-Benito et al., 2014); (Diederich et al., 
2021); (Emerson et al., 2020); (Fahid et al., 2023); (Heinemann et al., 2023); (Indy et al., 2017); (Moon &amp;amp; Ke, 2023); (Ng et al., 2022a, b); (Novoseltseva et al., 2022); (Stefan et al., 2016); (Wang &amp;amp; Xing, 2022); (Vittal et al., 2023); (Ng et al., 2023)</td></tr><tr><td>Predicting performance</td><td>(Acosta et al., 2021); (Ahmad et al., 2022); (Baker et al., 2016); (Balderas et al., 2017); (Camilleri et al., 2013); (Carpenter et al., 2021); (Novoseltseva et al., 2022); (Reilly &amp;amp; Dede, 2019)</td></tr><tr><td>Increasing reflection and awareness</td><td>(Cruz-Benito et al., 2014); (Diederich et al., 2021); (Ng et al., 2022a); (Ng et al., 2022b); (Vittal et al., 2022)</td></tr><tr><td>Improving assessment and feedback</td><td>(Ahmad et al., 2022); (Baena-Perez et al., 2024); (Baker et al., 2016); (Balderas et al., 2017); (Barmaki &amp;amp; Hughes, 2015); (Berman &amp;amp; Artino, 2018); (Birt et al., 2019); (Camilleri et al., 2013); (Carpenter et al., 2021); (Moon &amp;amp; Ke, 2023)</td></tr><tr><td>Enhancing social interaction</td><td>(Ahmad et al., 2022); (Baena-Perez et al., 2024); (Chen et al., 2021); (Novoseltseva et al., 2022); (Wang et al., 2024)</td></tr><tr><td>Understanding affective states</td><td>(Antoniou et al., 2020); (Li &amp;amp; Shen, 2024)</td></tr></table>

# Acknowledgements

Not applicable.

# Author contributions

All authors contributed to the study's conception and design. Lei Tao was responsible for outlining the manuscript, collecting and coding the review articles, drafting the initial manuscript, and making subsequent revisions. Mutlu Cukurova contributed to the editing and revision process, providing input on the manuscript's structure and content throughout. Yanjie Song provided overall supervision, guiding the development of the manuscript and reviewing the paper. All authors discussed the results and provided critical feedback on the manuscript at all stages. All authors have read and approved the final manuscript.

# Funding

Not applicable.

# Availability of data and materials

The datasets used and/or analysed during the current study are available from the corresponding author on reasonable request.

# Declarations

# Competing interests

Not applicable.

Received: 14 November 2024 Accepted: 24 March 2025 Published online: 22 July 2025

# References

Acosta, H., Henderson, N., Rowe, J., Min, W., Minogue, J., & Lester, J. (2021). What's fair is fair: Detecting and mitigating encoded bias in multimodal models of museum visitor attention. In Proceedings of the 2021 international conference on multimodal interaction, https://doi.org/10.1145/3462244.3479943. Ahmad, I., Khusro, S., Alam, I., Khan, I., & Niazi, B. (2022). Towards a low- cost teacher orchestration using ubiquitous computing devices for detecting student's engagement. Wireless Communications and Mobile Computing, https://doi.org/10.1155/2022/77979766Aldana- Burgos, L. M., Gaona- Garcia, P. A., & Montenegro- Marn, C. E. (2022). A fuzzy logic implementation to support second language learning through 3D immersive scenarios. In International conference on information technology and education (ICITED).Al- Mughed, K., Bayraktar, N., Al- Bsheish, M., AlSyouf, A., Aldhimi, B. K., Jarrar, M. T., & Alkhazali, M. (2022). Effectiveness of game- based virtual reality phone application and online education on knowledge, attitude and compliance of standard precautions among nursing students. PLoS ONE, 17(11), e0275130. https://doi.org/10.1371/journal.pone.0275130Alonso- Fernandez, C., Calvo- Morata, A., Freire, M., Martinez- Ortiz, I., & Fernandez- Manjon, B. (2019). Applications of data science to game learning analytics data: A systematic literature review. Computers & Education, 141, 103612. https://doi.org/10.1016/j.compedu.2019.103612Antoniou, P. E., Arfaras, G., Pandria, N., Athanasiou, A., Ntakakis, G., Babatsikos, E., Nigdelis, V., & Bamidis, P. (2020). Biosensor real- time affective analytics in virtual and mixed reality medical education serious games: Cohort study. JMIR Serious Games, 8(3), e17823. https://doi.org/10.2196/17823Azevedo, R., & GaSevic, D. (2019). Analyzing multimodal multichannel data about self- regulated learning with advanced learning technologies: Issues and challenges. Computers in Human Behavior, 96, 207–210. https://doi.org/10.1016/j.chb.2019.03.025Ba, S., & Hu, X. (2023). Measuring emotions in education using wearable devices: A systematic review. Computers & Education, 202, 104797. https://doi.org/10.1016/j.compedu.2023.104797Baena- Perez, R., Ruiz- Rube, I., Mota, J. M., Berns, A., & Balceras, A. (2024). Visual authoring of virtual reality conversational scenarios for e- learning. Universal Access in the Information Society, 23(1), 227–244. https://doi.org/10.1007/s10209- 023- 0093- 4Baker, R. S., Clarke- Midura, J., & Oumpaugh, J. (2016). Towards general models of effective science inquiry in virtual performance assessments. Journal of Computer Assisted Learning, 32(3), 267–280. https://doi.org/10.1111/jcal.12128Baker, R., Xu, D., Park, J., Yu, R., Li, Q., Cung, B., Fischer, C., Rodriguez, F., Warschauer, M., & Smyth, P. (2020). The benefits and caveats of using clickstream data to understand student self- regulatory behaviors: Opening the black box of learning processes. International Journal of Educational Technology in Higher Education, 17(1), 13. https://doi.org/10.1186/s41239- 020- 00187- 1Balderas, A., Berns, A., Palomo- Duarte, M., Dodero, J. M., & Ruiz- Rube, I. (2017). Retrieving objective indicators from student logs in virtual worlds. Journal of Information Technology Research, 10(3), 69–83. https://doi.org/10.4018/JITR.2017070105Banihashem, S. K., Aliabadi, K., Pourroostaei Ardakani, S., Delaver, A., & Nili Ahmadabadi, M. (2018). Learning analytics: A systematic literature review. Interdisciplinary Journal of Virtual Learning in Medical Sciences. https://doi.org/10.5812/ijvmx.63024Barmaki, R., & Hughes, C. E. (2015). Providing real- time feedback for student teachers in a virtual rehearsal environment. In ICMI 2015—Proceedings of the 2015 ACM international conference on multimodal interaction.

Berman, N. B., & Artino, A. R. (2018). Development and initial validation of an online engagement metric using virtual patients. *BMC Medical Education*, 18(1), 213. https://doi.org/10.1186/s12909- 018- 1322- zBirt, J., Clave, D., & Cowling, M. (2019). Piloting multimodal learning analytics using mobile mixed reality in health education. In *2019 IEEE 7th international conference on serious games and applications for health*, SeGAH 2019. Calvo- Morata, A., Rotaru, D. C., Alonso- Fernandez, C., Freire- Moran, M., Martinez- Ortiz, I., & Fernandez- Manjon, B. (2020). Validation of a cyberbullying serious game using game analytics. *IEEE Transactions on Learning Technologies*, 13(1), 186–197. https://doi.org/10.1109/TLT.2018.2879354Camilleri, V., Pertas, S. d., Montebello, M., & McDonagh- Smith, P. (2013). A case study inside virtual worlds: use of analytics for immersive spaces. In *Proceedings of the third international conference on learning analytics and knowledge*, https://doi.org/10.1145/2460296.2460341. Carpenter, D., Cloude, E., Rowe, J., Azevedo, R., & Lester, J. (2021). Investigating student reflection during game- based learning in middle grades science LAK21: 11th international learning analytics and knowledge conference. https://doi.org/10.1145/3448139.3448166. Chan, R. Y. Y., Wong, C. M. V., & Yum, Y. N. (2023). Predicting behavior change in students with special education needs using multimodal learning analytics. *IEEE Access*, 11, 63238–63251. https://doi.org/10.1109/ACCESS.2023.3288695Charitopoulos, A., Rangoussi, M., & Koulouriotis, D. (2020). On the use of soft computing methods in educational data mining and learning analytics research: A review of years 2010–2018. *International Journal of Artificial Intelligence in Education*, 30(3), 371–430. https://doi.org/10.1007/s4093- 09- 00200- 8Chen, L., Liang, H. N., Lu, F., Wang, J., Chen, W., & Yue, Y. (2021). Effect of collaboration mode and position arrangement on immersive analytics tasks in virtual reality: A pilot study. *Applied Sciences (Switzerland)*, 11(21), 10473. https://doi.org/10.3390/app112110473Cohen, J. (1960). Applicieficient of agreement for nominal scales. *Educational and Psychological Measurement*, 20(1), 37–46. https://doi.org/10.1177/001316466002000104Cosentino, G., & Giannakos, M. (2023). Multisensory interaction and analytics to enhance smart learning environments: A systematic literature review. *IEEE Transactions on Learning Technologies*, 16(3), 414–430. https://doi.org/10.1109/TLT.2023.3243210Crompton, H., & Burke, D. (2018). The use of mobile learning in higher education: A systematic review. *Computers & Education*, 123, 53–64. https://doi.org/10.1016/j.compedu.2018.04.007Crompton, H., Burke, D., Jordan, K., & Wilson, S. W. G. (2021). Learning with technology during emergencies: A systematic review of K- 12 education. *British Journal of Educational Technology*, 52(4), 1554–1575. https://doi.org/10.1111/bjet.13114Cruz- Benito, J., Therón, R., García- Peñalvo, F. J., Maderuelo, C., Pérez- Blanco, J. S., Zazo, H., & Martín- Suárez, A. (2014). Monitoring and feedback of learning processes in virtual worlds through analytics architectures: A real case. *Iberian Conference on Information Systems and Technologies*, 5(3).Cukurova, M. (2019). Learning analytics as AI extenders in education: Multimodal machine learning versus multimodal learning analytics. In *Artificial intelligence and adaptive education*.Cukurova, M. (2024). The interplay of learning, analytics and artificial intelligence in education: A vision for hybrid intelligence. *British Journal of Educational Technology*. https://doi.org/10.1111/bjet.13514Dalinger, T., Thomas, K. B., Stansberry, S., & Xiu, Y. (2020). A mixed reality simulation offers strategic practice for pre- service teachers. *Computers & Education*, 144, 103696. https://doi.org/10.1016/j.compedu.2019.103696Diederich, M., Kang, J., Kim, T., & Lindgren, R. (2021). Developing an in- application shared view metric to capture collaborative learning in a multi- platform astronomy simulation LAK21. 11th international learning analytics and knowledge conference. https://doi.org/10.1145/3448139.3448156. Dobashi, K., Ho, C. P., Fulford, C. P., Grace Lin, M. F., & Higa, C. (2022). Learning pattern classification using moodle logs and the visualization of browsing processes by time- series cross- section. *Computers and Education: Artificial Intelligence*, 3, 100105. https://doi.org/10.1016/j.caeai.2022.100105Du, J., Hew, K. F., & Liu, L. (2023). What can online traces tell us about students' self- regulated learning? *A systematic review of online trace data analysis*. *Online Traces & Education*, 201, 104828. https://doi.org/10.1016/j.compedu.2023.104828Elmoazen, R., Saq, M., Khalil, M., & Wasson, B. (2023). Learning analytics in virtual laboratories: A systematic literature review of empirical research. *Smart Learning Environments*, 11(1), 23. https://doi.org/10.1186/s40561- 023- 0024- 0 Emerson, A., Henderson, N., Rowe, J., Min, W., Lee, S., Minogue, L., & Lester, J. (2020). Early prediction of visitor engagement in science museums with multimodal learning analytics: proceedings of the 2020 international conference on multimodal interaction, https://doi.org/10.1145/3382507.3418890. Fahid, F. M., Lee, S., Mott, B., Vandenberg, J., Acosta, H., Brush, T., Glazewski, K., Hmelo- Silver, C., & Lester, J. (2023). Effects of modalities in detecting behavioral engagement in collaborative game- based learning. In *ACM international conference proceeding series*.Giannakos, M., Cukurova, M., & Papavlasopoulou, S. (2022). Sensor- based analytics in education: Lessons learned from research in multimodal learning analytics. In M. Giannakos, D. Spikol, D. Di Mitri, K. Sharma, X. Ochoa, & R. Hammad (Eds.), *The multimodal learning analytics handbook (pp. 329–358)*. Springer International Publishing. https://doi.org/10.1007/978- 3- 031- 08076- 0_13Giannakos, M. N., Sharma, K., Pappas, I. O., Kostakos, V., & Velloso, E. (2019). Multimodal data as a means to understand the learning experience. *International Journal of Information Management*, 48, 108–119. https://doi.org/10.1016/j.ijinf.0mg.2019.02.003Halbig, A., & Latoschik, M. E. (2021). A systematic review of physiological measurements, factors, methods, and applications in virtual reality [systematic review]. *Frontiers in Virtual Reality*. https://doi.org/10.3389/fvr.2021.694567Hari Rajan, M., Herbert, C., & Polly, P. (2025). A synthetic review of learning theories, elements and virtual environment simulation types to improve learning within higher education. *Thinking Skills and Creativity*, 56, 101732. https://doi.org/10.1016/j.tsc.2024.101732Heinemann, B., Görzen, S., & Schroeder, U. (2023). Teaching the basics of computer graphics in virtual reality. *Computers and Graphics (Pergamon)*, 112, 1–12. https://doi.org/10.1016/j.cag.2023.03.001

Hilbert, S., Coors, S., Kraus, E., Bischl, B., Lindl, A., Frei, M., Wild, J., Krauss, S., Goretzko, D., & Stachl, C. (2021). Machine learning for the educational sciences. Review of Education, 9(3), e3310. https://doi.org/10.1002/rev3.3310Huang, C. L., Luo, Y. F., Yang, S. C., Lu, C. M., & Chen, A.- S. (2019). Influence of students' learning style, sense of presence, and cognitive load on learning outcomes in an immersive virtual reality learning environment. Journal of Educational Computing Research, 58(3), 596–615. https://doi.org/10.1177/0735633119867422Indy, Y. T. H., Yu- Ju, L., Chia- Ling, K., & Ping, L. (2017). Visualization analytics for second language vocabulary learning in virtual worlds. Journal of Educational Technology & Society, 28(2), 161–175. Kennedy, G., Kornou, I., Zhou, Y., Bailey, J., & O'Leary, S. (2013). Mixing interactions in immersive learning environments for real- time student feedback. Australasian Journal of Educational Technology, 29(2), 172–183. https://doi.org/10.14742/ajet.700Khalil, M., Prinsloo, P., & Slade, S. (2023). The use and application of learning theory in learning analytics: A scoping review. Journal of Computing in Higher Education, 35(3), 573–594. https://doi.org/10.1007/s12528- 022- 09340- 3Kickmeier, Rust, M. D., Bull, S., & Meissl- Egghart, G. (2014). Collaborative language learning in immersive virtual worlds: Competence- based formative feedback and open learner modeling. International Journal of Serious Games, 1(2), 67–74. https://doi.org/10.17083/ijsg.v1i2.5Li, Y., & Shen, Y. (2024). Multimodal physiological analysis of cognitive affective effect of immersive learning in virtual reality proceedings of the 2023 4th international conference on computer science and management technology, Xi'an, China. https://doi.org/10.1145/3644523.3644549. Luckin, R., Cukurova, M., Kent, C., & du Boulay, B. (2022). Empowering educators to be AI- ready. Computers and Education: Artificial Intelligence, 3, 100076. https://doi.org/10.1016/j.caeai.2022.100076Mangaroska, K., Sharma, K., Gaševic, D., & Giannakos, M. (2020). Multimodal learning analytics to inform learning design: Lessons learned from computing education. Journal of Learning Analytics, 7(3), 79–97. McHugh, M. L. (2012). Interrater reliability: The kappa statistic. Biochemia Medica, 22(3), 276–282. Moon, J., & Ke, F. (2023). Effects of adaptive prompts in virtual reality- based social skills training for children with autism. Journal of Autism and Developmental Disorders. https://doi.org/10.1007/s10803- 023- 06021- 7Morye, A., Dudheliya, N., Jain, A., Jha, J., Deshpande, K. B., & Pangarkar, P. (2023). Developing data analytics support for creative learning web framework. In 2023 international conference on sustainable computing and smart systems (ICCSS).Ng, J. T. D., Wang, Z., Hu, X., & Assoc Comp, M. (2022b). Needs analysis and prototype evaluation of student- facing LA dashboards for virtual reality content creation. In 12th annual international conference on learning analytics and knowledge (LAK).Ng, J. T. D., Hu, X., Que, Y., & Assoc Comp, M. (2022a). Towards multi- modal evaluation of eye- tracked virtual heritage environment. In 12th annual international conference on learning analytics and knowledge (LAK).Ng, J. T. D., Liu, R. L., Wang, Z., & Hu, X. (2023). Automated analysis of text in student- created virtual reality content. In IEEE international conference on advanced learning technologies (2023 ieee international conference on advanced learning technologies, icalt). 23rd IEEE International conference on advanced learning technologies (ICALT), Orem, UT.Nguyen, A., Järvelä, S., Rosé, C., Järvenoja, H., & Malmberg, J. (2023). Examining socially shared regulation and shared physiological arousal events with multimodal learning analytics. British Journal of Educational Technology, 54(1), 293–312. https://doi.org/10.1111/bjet.13280Novoselteva, D., Lelardeux, C. P., & Jessel, N. (2022). Examining students' behavior in a digital simulation game for nurse training. International Journal of Serious Games, 9(4), 3–24. https://doi.org/10.17083/ijsg.v9i4.543Ouyang, P., Xu, W., & Cukurova, M. (2023). An artificial intelligence- driven learning analytics method to examine the collaborative problem- solving process from the complex adaptive systems perspective. International Journal of Computer- Supported Collaborative Learning, 18(1), 39–66. https://doi.org/10.1007/s11412- 023- 09387- zPage, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffman, T. C., Mulrow, C. D., Shamseer, L., Tetzlaff, J. M., Akil, E. A., Brennan, S. E., Chou, R., Glanville, J., Grimshaw, J. M., Hróbjartsson, A., Lalu, M. M., Li, T., Loder, E. W., Mayo- Wilson, E., McDonald, S., ... Moher, D. (2021). The PRISMA 2020 statement: an updated guideline for reporting systematic reviews. JMJ, 372, n71. https://doi.org/10.1136/bmj.n71. Pedrycz, W. (2021). Design, interpretability, and explainability of models in the framework of granular computing and federated learning. In 2021 IEEE Conference on Norbert Wiener in the 21st Century (21CW).Pinto, M., & Leis, C. (2020). Digital technologies in support of students learning in Higher Education: literature review. Digital Education Review, 37, 343–360. Poquet, O., Kitto, K., Jovanovic, J., Dawson, S., Siemens, G., & Markauskaite, L. (2021). Transitions through lifelong learning: Implications for learning analytics. Computers and Education: Artificial Intelligence, 2, 100039. https://doi.org/10.1016/j.caeai.2021.100039Prinsloo, P., & Kalisa, R. (2022). Learning analytics on the african continent: An emerging research focus and practice. Journal of Learning Analytics, 9(2), 218–235. https://doi.org/10.18608/jla.2022.7539Reilly, J. M., & Dede, C. (2019). Differences in student trajectories via filtered time series analysis in an immersive virtual world. In ACM international conference proceeding series.Rodriguez- Garcia, M., Balderas, A., & Dodero, J. M. (2021). Privacy preservation and analytical utility of e- learning data mashups in the web of data. Applied Sciences, 11(18), 8506. Sakr, A., & Abdullah, T. (2024). Virtual, augmented reality and learning analytics impact on learners, and educators: A systematic review. Education and Information Technologies. https://doi.org/10.1007/s10639- 024- 12602- 5Samuelson, J., Chen, W., & Wasson, B. (2019). Integrating multiple data sources for learning analytics—review of literature. Research and Practice in Technology Enhanced Learning, 14(1), 11. https://doi.org/10.1186/s41039- 019- 0105- 4Shadiev, R., & Li, D. (2023). A review study on eye- tracking technology usage in immersive virtual reality learning environments. Computers & Education, 196, 104681. https://doi.org/10.1016/j.compedu.2022.104681Shamir- Inbal, T., & Blau, I. (2021). Facilitating emergency remote K- 12 teaching in computing- enhanced virtual learning environments during COVID- 19 pandemic—blessing or curse? Journal of Educational Computing Research, 59(7), 1243–1271. https://doi.org/10.1177/073563312199278

Sharma, K., & Giannakos, M. (2020). Multimodal data capabilities for learning: What can multimodal data tell us about learning? British Journal of Educational Technology, 51(5), 1450- 1484. https://doi.org/10.1111/bjet.12993Siemens, G., & Long, P. (2011). Penetrating the fog: Analytics in learning and education. EDUCAUSE Review, 46(5), 30. Song, Cao, J., Tao, L., & Gašević, D. (2023a). A holistic visualisation solution to understanding multimodal data in an educational metaverse platform—Learningverse. In International conference on computers in education 2023. Song, Y., Cao, J., Wu, K., Yu, P. L., & Lee, J. C. (2023b). Developing "Learningverse"—A 3- D metaverse platform to support teaching, social, and cognitive presences. IEEE Transactions on Learning Technologies, 16(6), 1165- 1178. https://doi.org/10.1109/TLT.2023.3276574Stefan, L., Moldoveanu, F., & Gheorghiu, D. (2016). Evaluating a mixed- reality 3d virtual campus with big data and learning analytics: A transversal study. Journal of E- Learning and Knowledge Society, 12(2), 41- 54. Susnjak, T. (2024). Beyond predictive learning analytics modelling and onto explainable artificial intelligence with descriptive analytics and ChatGPT. International Journal of Artificial Intelligence in Education, 34(2), 452- 482. https://doi.org/10.1007/s40593- 023- 00336- 3Susnjak, T., Ramaswami, G. S., & Mathrani, A. (2022). Learning analytics dashboard: A tool for providing actionable insights to learners. International Journal of Educational Technology in Higher Education, 19(1), 12. https://doi.org/10.1186/s41239- 021- 00313- 7Tiukhova, E., Vemuri, P., Flores, N. L., Islind, A. S., Őskarsdóttir, M., Poelmans, S., Baesens, B., & Snoeck, M. (2024). Explainable learning analytics: Assessing the stability of student success prediction models by means of explainable AI. Decision Support Systems, 182, 114229. https://doi.org/10.1016/j.dss.2024.114229Unal, D., Hammoudeh, M., Khan, M. A., Abuarqoub, A., Epiphaniou, G., & Hamila, R. (2021). Integration of federated machine learning and blockchain for the provision of secure big data analytics for internet of things. Computers & Security, 109, 102393. https://doi.org/10.1016/j.cose.2021.102393Vatral, C., Biswas, G., & Goldberg, B. S. (2022). Multimodal learning analytics using hierarchical models for analyzing team performance. In Proceedings of international conference of the learning sciences, ICLS.Vieira, C., Parsons, P., & Byrd, V. (2018). Visual learning analytics of educational data: A systematic literature review and research agenda. Computers & Education, 122, 119- 135. https://doi.org/10.1016/j.compedu.2018.03.018Wang, Z., Ng, J. T. D., & Hu, X. (2024). Learning analytics for collaboration quality assessment during virtual reality content creation. In IEEE international conference on advanced learning technologies [2024 ieee international conference on advanced learning technologies, icalt 2024]. 24th IEEE International Conference on Advanced Learning Technologies (ICALT), Kososia, CYPRUS.Wang, Q., Mousavi, A., & Lu, C. (2022). A scoping review of empirical studies on theory- driven learning analytics. Distance Education, 43(1), 6- 29. https://doi.org/10.1080/01587919.2021.2020621Wang, X., & Xing, W. (2022). Supporting youth with autism learning social competence: A comparison of games and nongame- based activities in 3D virtual world. Journal of Educational Computing Research, 60(1), 74- 103. https://doi.org/10.1177/0735633121102203Yan, L., Echeverria, V., Jin, Y., Fernandez- Nieto, G., Zhao, L., Li, X., Alfredo, R., Swiecki, Z., Gašević, D., & Martinez- Maldonado, R. (2024). Evidence- based multimodal learning analytics for feedback and reflection in collaborative learning. British Journal of Educational Technology, 55(5), 1900- 1925. https://doi.org/10.1111/bjet.13498Zhang, J., Huang, Y., & Yu, B. (2024). Using learning analytics to understand the learning design patterns of K12 synchronous language teaching. Interactive Learning Environments, 32(10), 6928- 6948. https://doi.org/10.1080/10494820.2023.2294773

# Publisher's Note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

Lei Tao is a PhD student in the Department of Mathematics and Information Technology at the Education University of Hong Kong. She holds a B.Eng. in Software Engineering, a B.A. in English Studies, and an M.A. in Education from University College London. Her research interests include generative AI and multimodal learning analytics in education.

Mutlu Cukurova received his B.Sc., M.Sc., and Ph.D. degrees in Learning Sciences from the University of York, England, in 2008, 2010, and 2014, respectively. He is currently a Professor of Learning and Artificial Intelligence at University College London (UCL), London, UK. He has authored or co- authored extensively in top- tier journals and conferences in the fields of AI in education and learning analytics, providing significant theoretical and methodological contributions. Additionally, he leads the UCLAFT team at UCL and serves as an external expert for UNESCO's Unit for Technology and AI in Education. Prof. Cukurova was the Programme Co- Chair of the International Conference on AI in Education (2020) and the International Conference on Computer- Supported Education (2022). He is a Salzburg Global Seminar fellow and currently serves as the Editor- in- Chief of the British Journal of Educational Technology and an Associate Editor of the International Journal of Child- Computer Interaction.

Yanjie Song is a Professor in the Department of Mathematics and Information Technology at the Education University of Hong Kong. She obtained her M.Ed. at the University of Leeds, UK, and her Ph.D. at the University of Hong Kong. Her research interests include artificial intelligence (AI), metaverse, augmented reality (AR), virtual reality (VR) in education, multimodal learning analytics, and innovative pedagogical designs.